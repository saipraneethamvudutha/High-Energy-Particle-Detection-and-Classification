{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\vudut\\OneDrive\\Desktop\\Python\\MINI Project\n",
      "Files in Directory: ['.git', 'CNN.ipynb', 'Data Sets', 'FINAL_1.ipynb', 'logs', 'particle_images', 'PPT & Images', 'preprocessed_data.csv', 'README.md', 'Simulation.ipynb', 'wandb', 'xgboost_model.onnx', 'xgboost_optimized.onnx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())  # Prints the directory where Python is looking for the file\n",
    "print(\"Files in Directory:\", os.listdir())  # Lists all files in the current directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lep_pt   lep_eta   lep_phi     lep_E  lep_charge  lep_type  jet_n  \\\n",
      "0 -0.646637 -0.958065  0.381154 -0.477948         1.0      11.0      1   \n",
      "1  0.377964 -0.059720  0.108998 -0.612058         0.0      11.0      0   \n",
      "2  0.132456  0.360554 -0.531584 -0.627914         1.0      11.0      1   \n",
      "3 -0.646720  0.312437  0.869416 -0.844918        -1.0      11.0      0   \n",
      "4 -0.261201  0.822651 -0.918316 -0.429899         1.0      11.0      1   \n",
      "\n",
      "     jet_pt    met_et   met_phi  \n",
      "0 -0.331582 -1.246566  0.771644  \n",
      "1       NaN -0.872589 -2.589168  \n",
      "2 -0.722571  0.418665 -0.035447  \n",
      "3 -0.859866 -0.008696  1.533058  \n",
      "4  1.252879  1.282319  2.545199  \n",
      "Dataset shape: (14945674, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "df_combined = pd.read_csv(\"preprocessed_data.csv\")\n",
    "\n",
    "# Verify the data\n",
    "print(df_combined.head())  # Check the first few rows\n",
    "print(f\"Dataset shape: {df_combined.shape}\")  # Print dataset size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Using TensorFlow DirectML with GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check available GPUs (should list DirectML GPU)\n",
    "print(\"Available Devices:\", tf.config.list_physical_devices())\n",
    "\n",
    "# Force TensorFlow to use DirectML\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices(\"GPU\")[1], True)\n",
    "print(\"Using TensorFlow DirectML with GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lep_pt   lep_eta   lep_phi     lep_E  lep_charge  lep_type  jet_n  \\\n",
      "0 -0.646637 -0.958065  0.381154 -0.477948         1.0      11.0      1   \n",
      "1  0.377964 -0.059720  0.108998 -0.612058         0.0      11.0      0   \n",
      "2  0.132456  0.360554 -0.531584 -0.627914         1.0      11.0      1   \n",
      "3 -0.646720  0.312437  0.869416 -0.844918        -1.0      11.0      0   \n",
      "4 -0.261201  0.822651 -0.918316 -0.429899         1.0      11.0      1   \n",
      "\n",
      "     jet_pt    met_et   met_phi  \n",
      "0 -0.331582 -1.246566  0.771644  \n",
      "1       NaN -0.872589 -2.589168  \n",
      "2 -0.722571  0.418665 -0.035447  \n",
      "3 -0.859866 -0.008696  1.533058  \n",
      "4  1.252879  1.282319  2.545199  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "df_combined = pd.read_csv(\"preprocessed_data.csv\")\n",
    "\n",
    "# Verify data\n",
    "print(df_combined.head())  # Check the first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Create a directory to store generated images\n",
    "os.makedirs(\"particle_images\", exist_ok=True)\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "df_combined = pd.read_csv(\"preprocessed_data.csv\")\n",
    "\n",
    "# Convert Pandas DataFrame to NumPy arrays (DirectML-compatible)\n",
    "lep_eta = df_combined[\"lep_eta\"].values.astype(np.float32)\n",
    "lep_phi = df_combined[\"lep_phi\"].values.astype(np.float32)\n",
    "lep_pt = df_combined[\"lep_pt\"].values.astype(np.float32)\n",
    "\n",
    "# Function to generate images\n",
    "def generate_image(args):\n",
    "    idx, eta, phi, pt = args\n",
    "    fig, ax = plt.subplots(figsize=(2, 2))\n",
    "    scatter = ax.scatter(eta, phi, c=pt, cmap=\"inferno\")\n",
    "\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-np.pi, np.pi)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    plt.savefig(f\"particle_images/{idx}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "# **Use multiprocessing to speed up image generation**\n",
    "if __name__ == '__main__':\n",
    "    with Pool(processes=os.cpu_count()) as pool:\n",
    "        pool.map(generate_image, zip(range(len(lep_eta)), lep_eta, lep_phi, lep_pt))\n",
    "\n",
    "print(\"✅ Image generation completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Error setting memory growth: Physical devices cannot be modified after being initialized\n",
      "Error setting memory growth: Physical devices cannot be modified after being initialized\n",
      "Processed images 0 to 99\n",
      "Processed images 100 to 199\n",
      "Processed images 200 to 299\n",
      "Processed images 300 to 399\n",
      "Processed images 400 to 499\n",
      "Processed images 500 to 599\n",
      "Processed images 600 to 699\n",
      "Processed images 700 to 799\n",
      "Processed images 800 to 899\n",
      "Processed images 900 to 999\n",
      "Processed images 1000 to 1099\n",
      "Processed images 1100 to 1199\n",
      "Processed images 1200 to 1299\n",
      "Processed images 1300 to 1399\n",
      "Processed images 1400 to 1499\n",
      "Processed images 1500 to 1599\n",
      "Processed images 1600 to 1699\n",
      "Processed images 1700 to 1799\n",
      "Processed images 1800 to 1899\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set necessary environment variables\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "# Disable eager execution to avoid early initialization\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "\n",
    "# Only then import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Make sure TF doesn't eagerly initialize the context\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Configure memory growth\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(f\"Found GPU devices: {physical_devices}\")\n",
    "    for device in physical_devices:\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "            print(f\"Memory growth enabled for {device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting memory growth: {e}\")\n",
    "\n",
    "# Your remaining imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load preprocessed dataset\n",
    "df_combined = pd.read_csv(\"preprocessed_data.csv\")\n",
    "\n",
    "# Reduce dataset: Sample 50,000 images\n",
    "df_sampled = df_combined.sample(n=50000, random_state=42)\n",
    "\n",
    "# Convert to NumPy arrays - don't use TensorFlow tensors for the matplotlib workflow\n",
    "lep_eta = df_sampled[\"lep_eta\"].values\n",
    "lep_phi = df_sampled[\"lep_phi\"].values\n",
    "lep_pt = df_sampled[\"lep_pt\"].values\n",
    "\n",
    "# Create directory for images\n",
    "os.makedirs(\"particle_images\", exist_ok=True)\n",
    "\n",
    "# Batch size for processing\n",
    "batch_size = 100\n",
    "\n",
    "# Process in batches without TensorFlow\n",
    "for i in range(0, len(lep_eta), batch_size):\n",
    "    end_idx = min(i + batch_size, len(lep_eta))\n",
    "    \n",
    "    for j in range(i, end_idx):\n",
    "        # Generate and save image using matplotlib directly\n",
    "        fig, ax = plt.subplots(figsize=(2, 2))\n",
    "        scatter = ax.scatter(lep_eta[j], lep_phi[j], c=lep_pt[j], cmap=\"inferno\")\n",
    "        \n",
    "        ax.set_xlim(-3, 3)\n",
    "        ax.set_ylim(-np.pi, np.pi)\n",
    "        ax.axis(\"off\")\n",
    "        \n",
    "        plt.savefig(f\"particle_images/{j}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"Processed images {i} to {end_idx-1}\")\n",
    "\n",
    "print(\"✅ Image generation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfamd",
   "language": "python",
   "name": "tfamd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
