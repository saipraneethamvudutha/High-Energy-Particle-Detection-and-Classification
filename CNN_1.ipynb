{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the requried libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the image directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = r\"C:\\Users\\vudut\\OneDrive\\Desktop\\Python\\MINI Project\\Data Sets\\jet-images_Mass60-100_pT250-300_R1.25_Pix25.hdf5\"  # Change to your actual file\n",
    "output_dir = \"higgs_images\"\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "val_dir = os.path.join(output_dir, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [train_dir, val_dir]:\n",
    "    os.makedirs(os.path.join(path, \"signal\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, \"background\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'jet_delta_R', 'jet_eta', 'jet_mass', 'jet_phi', 'jet_pt', 'signal', 'tau_1', 'tau_2', 'tau_21', 'tau_3', 'tau_32']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(hdf5_file, \"r\") as f:\n",
    "    print(list(f.keys()))  # Lists all available keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_file, \"r\") as f:\n",
    "    features = np.array(f[\"image\"])  # Corrected key\n",
    "    labels = np.array(f[\"signal\"])  # Corrected key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure image dimensions are valid\n",
    "num_samples, img_height, img_width = features.shape\n",
    "assert img_height == img_width, \"Images must be square\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving images: 100%|██████████| 872666/872666 [28:30<00:00, 510.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversion complete! Images saved in: higgs_images\n"
     ]
    }
   ],
   "source": [
    "# Save images\n",
    "train_split = int(0.8 * num_samples)\n",
    "for i in tqdm(range(num_samples), desc=\"Saving images\"):\n",
    "    img = features[i]\n",
    "    label = \"signal\" if labels[i] == 1 else \"background\"\n",
    "    \n",
    "    folder = train_dir if i < train_split else val_dir\n",
    "    filename = os.path.join(folder, label, f\"{i}.png\")\n",
    "    \n",
    "    plt.imsave(filename, img, cmap=\"gray\")  # Save as grayscale image\n",
    "\n",
    "print(\"✅ Conversion complete! Images saved in:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths\n",
    "train_signal_dir = \"higgs_images/train/signal\"\n",
    "train_background_dir = \"higgs_images/train/background\"\n",
    "\n",
    "# Select random images from each category\n",
    "signal_images = random.sample(os.listdir(train_signal_dir), 5)\n",
    "background_images = random.sample(os.listdir(train_background_dir), 5)\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, img_name in enumerate(signal_images):\n",
    "    img_path = os.path.join(train_signal_dir, img_name)\n",
    "    img = Image.open(img_path)\n",
    "    axes[0, i].imshow(img, cmap=\"gray\")\n",
    "    axes[0, i].set_title(\"Signal\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "for i, img_name in enumerate(background_images):\n",
    "    img_path = os.path.join(train_background_dir, img_name)\n",
    "    img = Image.open(img_path)\n",
    "    axes[1, i].imshow(img, cmap=\"gray\")\n",
    "    axes[1, i].set_title(\"Background\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 698132 files belonging to 2 classes.\n",
      "Found 174534 files belonging to 2 classes.\n",
      "✅ Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Dataset Paths\n",
    "train_dir = \"higgs_images/train\"\n",
    "val_dir = \"higgs_images/val\"\n",
    "batch_size = 4  # Reduce batch size to prevent kernel crashes\n",
    "img_size = (32, 32)  # Match generated image size\n",
    "\n",
    "# Load datasets\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"binary\",  # Binary classification (signal vs background)\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"binary\"\n",
    ")\n",
    "\n",
    "# Optimize dataset performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"✅ Dataset loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvuduthasaipraneetham\u001b[0m (\u001b[33mpraneetham\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\vudut\\OneDrive\\Desktop\\Python\\MINI Project\\wandb\\run-20250321_231424-dgcjmdqb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/praneetham/higgs_boson_cnn/runs/dgcjmdqb' target=\"_blank\">project_cnn1</a></strong> to <a href='https://wandb.ai/praneetham/higgs_boson_cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/praneetham/higgs_boson_cnn' target=\"_blank\">https://wandb.ai/praneetham/higgs_boson_cnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/praneetham/higgs_boson_cnn/runs/dgcjmdqb' target=\"_blank\">https://wandb.ai/praneetham/higgs_boson_cnn/runs/dgcjmdqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ✅ Initialize Weights & Biases (W&B)\n",
    "wandb.init(project=\"higgs_boson_cnn\", name=\"project_cnn1\")\n",
    "\n",
    "# ✅ Define CNN Architecture\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(32, 32, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation=\"sigmoid\")  # Binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# ✅ Create and Compile Model\n",
    "model = create_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  3469/174533 [..............................] - ETA: 24:54 - loss: 0.4957 - accuracy: 0.7668"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ✅ Train Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# ✅ Evaluate Model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(val_ds, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vudut\\anaconda3\\envs\\tfamd\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\vudut\\anaconda3\\envs\\tfamd\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\vudut\\anaconda3\\envs\\tfamd\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\vudut\\anaconda3\\envs\\tfamd\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\vudut\\anaconda3\\envs\\tfamd\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\vudut\\anaconda3\\envs\\tfamd\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vudut\\anaconda3\\envs\\tfamd\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\vudut\\anaconda3\\envs\\tfamd\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\vudut\\anaconda3\\envs\\tfamd\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ✅ Train Model\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "# ✅ Evaluate Model\n",
    "test_loss, test_acc = model.evaluate(val_ds, verbose=2)\n",
    "print(f\"\\n🎯 Final Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfamd",
   "language": "python",
   "name": "tfamd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
