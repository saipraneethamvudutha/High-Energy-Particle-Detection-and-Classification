{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: privateuseone:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Graphs: 100%|██████████| 872666/872666 [00:46<00:00, 18712.51it/s]\n",
      "c:\\Users\\vudut\\anaconda3\\envs\\pytorchamd\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100: Loss = 0.6793, Accuracy = 0.6875\n",
      "Epoch 1, Batch 200: Loss = 0.7024, Accuracy = 0.5625\n",
      "Epoch 1, Batch 300: Loss = 0.6968, Accuracy = 0.5625\n",
      "Epoch 1, Batch 400: Loss = 0.6698, Accuracy = 0.5938\n",
      "Epoch 1, Batch 500: Loss = 0.6246, Accuracy = 0.6562\n",
      "Epoch 1, Batch 600: Loss = 0.6981, Accuracy = 0.5000\n",
      "Epoch 1, Batch 700: Loss = 0.6163, Accuracy = 0.6875\n",
      "Epoch 1, Batch 800: Loss = 0.7367, Accuracy = 0.5312\n",
      "Epoch 1, Batch 900: Loss = 0.5997, Accuracy = 0.6250\n",
      "Epoch 1, Batch 1000: Loss = 0.6382, Accuracy = 0.6250\n",
      "Epoch 1, Batch 1100: Loss = 0.6256, Accuracy = 0.6250\n",
      "Epoch 1, Batch 1200: Loss = 0.5501, Accuracy = 0.7812\n",
      "Epoch 1, Batch 1300: Loss = 0.6225, Accuracy = 0.6875\n",
      "Epoch 1, Batch 1400: Loss = 0.6035, Accuracy = 0.6875\n",
      "Epoch 1, Batch 1500: Loss = 0.5577, Accuracy = 0.7500\n",
      "Epoch 1, Batch 1600: Loss = 0.5302, Accuracy = 0.7188\n",
      "Epoch 1, Batch 1700: Loss = 0.6545, Accuracy = 0.7500\n",
      "Epoch 1, Batch 1800: Loss = 0.6947, Accuracy = 0.5938\n",
      "Epoch 1, Batch 1900: Loss = 0.6130, Accuracy = 0.6562\n",
      "Epoch 1, Batch 2000: Loss = 0.5512, Accuracy = 0.7500\n",
      "Epoch 1, Batch 2100: Loss = 0.6623, Accuracy = 0.6875\n",
      "Epoch 1, Batch 2200: Loss = 0.5808, Accuracy = 0.7188\n",
      "Epoch 1, Batch 2300: Loss = 0.5295, Accuracy = 0.7500\n",
      "Epoch 1, Batch 2400: Loss = 0.6293, Accuracy = 0.6562\n",
      "Epoch 1, Batch 2500: Loss = 0.6749, Accuracy = 0.5312\n",
      "Epoch 1, Batch 2600: Loss = 0.5608, Accuracy = 0.7500\n",
      "Epoch 1, Batch 2700: Loss = 0.6203, Accuracy = 0.6875\n",
      "Epoch 1, Batch 2800: Loss = 0.6028, Accuracy = 0.6562\n",
      "Epoch 1, Batch 2900: Loss = 0.6890, Accuracy = 0.6562\n",
      "Epoch 1, Batch 3000: Loss = 0.6010, Accuracy = 0.6562\n",
      "Epoch 1, Batch 3100: Loss = 0.6584, Accuracy = 0.6250\n",
      "Epoch 1, Batch 3200: Loss = 0.6010, Accuracy = 0.6562\n",
      "Epoch 1, Batch 3300: Loss = 0.5745, Accuracy = 0.6875\n",
      "Epoch 1, Batch 3400: Loss = 0.5996, Accuracy = 0.7812\n",
      "Epoch 1, Batch 3500: Loss = 0.6334, Accuracy = 0.6875\n",
      "Epoch 1, Batch 3600: Loss = 0.6867, Accuracy = 0.6875\n",
      "Epoch 1, Batch 3700: Loss = 0.6794, Accuracy = 0.7188\n",
      "Epoch 1, Batch 3800: Loss = 0.5999, Accuracy = 0.6250\n",
      "Epoch 1, Batch 3900: Loss = 0.6241, Accuracy = 0.5938\n",
      "Epoch 1, Batch 4000: Loss = 0.6774, Accuracy = 0.6875\n",
      "Epoch 1, Batch 4100: Loss = 0.4742, Accuracy = 0.8750\n",
      "Epoch 1, Batch 4200: Loss = 0.6050, Accuracy = 0.6875\n",
      "Epoch 1, Batch 4300: Loss = 0.7244, Accuracy = 0.6562\n",
      "Epoch 1, Batch 4400: Loss = 0.6655, Accuracy = 0.6875\n",
      "Epoch 1, Batch 4500: Loss = 0.5259, Accuracy = 0.7500\n",
      "Epoch 1, Batch 4600: Loss = 0.6053, Accuracy = 0.6875\n",
      "Epoch 1, Batch 4700: Loss = 0.5859, Accuracy = 0.6562\n",
      "Epoch 1, Batch 4800: Loss = 0.6004, Accuracy = 0.7188\n",
      "Epoch 1, Batch 4900: Loss = 0.6758, Accuracy = 0.5938\n",
      "Epoch 1, Batch 5000: Loss = 0.5827, Accuracy = 0.7188\n",
      "Epoch 1, Batch 5100: Loss = 0.5619, Accuracy = 0.7500\n",
      "Epoch 1, Batch 5200: Loss = 0.5276, Accuracy = 0.7812\n",
      "Epoch 1, Batch 5300: Loss = 0.5065, Accuracy = 0.7812\n",
      "Epoch 1, Batch 5400: Loss = 0.5925, Accuracy = 0.7500\n",
      "Epoch 1, Batch 5500: Loss = 0.6102, Accuracy = 0.6875\n",
      "Epoch 1, Batch 5600: Loss = 0.7101, Accuracy = 0.5938\n",
      "Epoch 1, Batch 5700: Loss = 0.5933, Accuracy = 0.7500\n",
      "Epoch 1, Batch 5800: Loss = 0.5993, Accuracy = 0.6875\n",
      "Epoch 1, Batch 5900: Loss = 0.4448, Accuracy = 0.7812\n",
      "Epoch 1, Batch 6000: Loss = 0.6327, Accuracy = 0.7188\n",
      "Epoch 1, Batch 6100: Loss = 0.6275, Accuracy = 0.7188\n",
      "Epoch 1, Batch 6200: Loss = 0.6273, Accuracy = 0.5938\n",
      "Epoch 1, Batch 6300: Loss = 0.6560, Accuracy = 0.6562\n",
      "Epoch 1, Batch 6400: Loss = 0.4889, Accuracy = 0.7812\n",
      "Epoch 1, Batch 6500: Loss = 0.6031, Accuracy = 0.6875\n",
      "Epoch 1, Batch 6600: Loss = 0.6476, Accuracy = 0.5938\n",
      "Epoch 1, Batch 6700: Loss = 0.5333, Accuracy = 0.6875\n",
      "Epoch 1, Batch 6800: Loss = 0.6924, Accuracy = 0.6250\n",
      "Epoch 1, Batch 6900: Loss = 0.6131, Accuracy = 0.7188\n",
      "Epoch 1, Batch 7000: Loss = 0.5121, Accuracy = 0.7500\n",
      "Epoch 1, Batch 7100: Loss = 0.5721, Accuracy = 0.7188\n",
      "Epoch 1, Batch 7200: Loss = 0.7723, Accuracy = 0.5938\n",
      "Epoch 1, Batch 7300: Loss = 0.5585, Accuracy = 0.7500\n",
      "Epoch 1, Batch 7400: Loss = 0.6142, Accuracy = 0.6250\n",
      "Epoch 1, Batch 7500: Loss = 0.6633, Accuracy = 0.7188\n",
      "Epoch 1, Batch 7600: Loss = 0.5502, Accuracy = 0.8438\n",
      "Epoch 1, Batch 7700: Loss = 0.5984, Accuracy = 0.5938\n",
      "Epoch 1, Batch 7800: Loss = 0.6325, Accuracy = 0.6562\n",
      "Epoch 1, Batch 7900: Loss = 0.6438, Accuracy = 0.6250\n",
      "Epoch 1, Batch 8000: Loss = 0.6186, Accuracy = 0.5938\n",
      "Epoch 1, Batch 8100: Loss = 0.6119, Accuracy = 0.6875\n",
      "Epoch 1, Batch 8200: Loss = 0.4956, Accuracy = 0.7812\n",
      "Epoch 1, Batch 8300: Loss = 0.5133, Accuracy = 0.7500\n",
      "Epoch 1, Batch 8400: Loss = 0.5767, Accuracy = 0.6562\n",
      "Epoch 1, Batch 8500: Loss = 0.6498, Accuracy = 0.7500\n",
      "Epoch 1, Batch 8600: Loss = 0.4669, Accuracy = 0.8438\n",
      "Epoch 1, Batch 8700: Loss = 0.5381, Accuracy = 0.7812\n",
      "Epoch 1, Batch 8800: Loss = 0.6168, Accuracy = 0.6875\n",
      "Epoch 1, Batch 8900: Loss = 0.5589, Accuracy = 0.7812\n",
      "Epoch 1, Batch 9000: Loss = 0.4928, Accuracy = 0.7188\n",
      "Epoch 1, Batch 9100: Loss = 0.6939, Accuracy = 0.5938\n",
      "Epoch 1, Batch 9200: Loss = 0.5246, Accuracy = 0.7188\n",
      "Epoch 1, Batch 9300: Loss = 0.4819, Accuracy = 0.8125\n",
      "Epoch 1, Batch 9400: Loss = 0.5859, Accuracy = 0.6250\n",
      "Epoch 1, Batch 9500: Loss = 0.5197, Accuracy = 0.7812\n",
      "Epoch 1, Batch 9600: Loss = 0.5048, Accuracy = 0.7500\n",
      "Epoch 1, Batch 9700: Loss = 0.5588, Accuracy = 0.7500\n",
      "Epoch 1, Batch 9800: Loss = 0.5620, Accuracy = 0.6875\n",
      "Epoch 1, Batch 9900: Loss = 0.5725, Accuracy = 0.6875\n",
      "Epoch 1, Batch 10000: Loss = 0.5864, Accuracy = 0.7500\n",
      "Epoch 1, Batch 10100: Loss = 0.5566, Accuracy = 0.6875\n",
      "Epoch 1, Batch 10200: Loss = 0.4975, Accuracy = 0.7812\n",
      "Epoch 1, Batch 10300: Loss = 0.7836, Accuracy = 0.5312\n",
      "Epoch 1, Batch 10400: Loss = 0.5677, Accuracy = 0.7500\n",
      "Epoch 1, Batch 10500: Loss = 0.5653, Accuracy = 0.6562\n",
      "Epoch 1, Batch 10600: Loss = 0.6459, Accuracy = 0.6250\n",
      "Epoch 1, Batch 10700: Loss = 0.6619, Accuracy = 0.7188\n",
      "Epoch 1, Batch 10800: Loss = 0.6673, Accuracy = 0.6562\n",
      "Epoch 1, Batch 10900: Loss = 0.6143, Accuracy = 0.6875\n",
      "Epoch 1, Batch 11000: Loss = 0.5910, Accuracy = 0.6875\n",
      "Epoch 1, Batch 11100: Loss = 0.6426, Accuracy = 0.6562\n",
      "Epoch 1, Batch 11200: Loss = 0.6451, Accuracy = 0.6875\n",
      "Epoch 1, Batch 11300: Loss = 0.4749, Accuracy = 0.9062\n",
      "Epoch 1, Batch 11400: Loss = 0.4795, Accuracy = 0.8125\n",
      "Epoch 1, Batch 11500: Loss = 0.6037, Accuracy = 0.6875\n",
      "Epoch 1, Batch 11600: Loss = 0.6053, Accuracy = 0.7500\n",
      "Epoch 1, Batch 11700: Loss = 0.6193, Accuracy = 0.6250\n",
      "Epoch 1, Batch 11800: Loss = 0.5600, Accuracy = 0.7812\n",
      "Epoch 1, Batch 11900: Loss = 0.5970, Accuracy = 0.6875\n",
      "Epoch 1, Batch 12000: Loss = 0.7029, Accuracy = 0.5938\n",
      "Epoch 1, Batch 12100: Loss = 0.6453, Accuracy = 0.6875\n",
      "Epoch 1, Batch 12200: Loss = 0.7052, Accuracy = 0.6250\n",
      "Epoch 1, Batch 12300: Loss = 0.5420, Accuracy = 0.7188\n",
      "Epoch 1, Batch 12400: Loss = 0.6436, Accuracy = 0.7188\n",
      "Epoch 1, Batch 12500: Loss = 0.6270, Accuracy = 0.6562\n",
      "Epoch 1, Batch 12600: Loss = 0.5484, Accuracy = 0.7188\n",
      "Epoch 1, Batch 12700: Loss = 0.5107, Accuracy = 0.8125\n",
      "Epoch 1, Batch 12800: Loss = 0.5340, Accuracy = 0.7500\n",
      "Epoch 1, Batch 12900: Loss = 0.5157, Accuracy = 0.6875\n",
      "Epoch 1, Batch 13000: Loss = 0.5453, Accuracy = 0.8125\n",
      "Epoch 1, Batch 13100: Loss = 0.5691, Accuracy = 0.6250\n",
      "Epoch 1, Batch 13200: Loss = 0.6072, Accuracy = 0.7188\n",
      "Epoch 1, Batch 13300: Loss = 0.4602, Accuracy = 0.7812\n",
      "Epoch 1, Batch 13400: Loss = 0.5901, Accuracy = 0.8125\n",
      "Epoch 1, Batch 13500: Loss = 0.7173, Accuracy = 0.6562\n",
      "Epoch 1, Batch 13600: Loss = 0.4218, Accuracy = 0.8750\n",
      "Epoch 1, Batch 13700: Loss = 0.7284, Accuracy = 0.5312\n",
      "Epoch 1, Batch 13800: Loss = 0.5780, Accuracy = 0.6250\n",
      "Epoch 1, Batch 13900: Loss = 0.5966, Accuracy = 0.6875\n",
      "Epoch 1, Batch 14000: Loss = 0.5766, Accuracy = 0.6875\n",
      "Epoch 1, Batch 14100: Loss = 0.8346, Accuracy = 0.5000\n",
      "Epoch 1, Batch 14200: Loss = 0.6220, Accuracy = 0.6562\n",
      "Epoch 1, Batch 14300: Loss = 0.6712, Accuracy = 0.6562\n",
      "Epoch 1, Batch 14400: Loss = 0.6246, Accuracy = 0.6875\n",
      "Epoch 1, Batch 14500: Loss = 0.7149, Accuracy = 0.6250\n",
      "Epoch 1, Batch 14600: Loss = 0.5458, Accuracy = 0.7188\n",
      "Epoch 1, Batch 14700: Loss = 0.6378, Accuracy = 0.6250\n",
      "Epoch 1, Batch 14800: Loss = 0.6049, Accuracy = 0.7500\n",
      "Epoch 1, Batch 14900: Loss = 0.6910, Accuracy = 0.6250\n",
      "Epoch 1, Batch 15000: Loss = 0.6726, Accuracy = 0.6562\n",
      "Epoch 1, Batch 15100: Loss = 0.5932, Accuracy = 0.7188\n",
      "Epoch 1, Batch 15200: Loss = 0.5596, Accuracy = 0.7500\n",
      "Epoch 1, Batch 15300: Loss = 0.6259, Accuracy = 0.7188\n",
      "Epoch 1, Batch 15400: Loss = 0.5973, Accuracy = 0.7188\n",
      "Epoch 1, Batch 15500: Loss = 0.6638, Accuracy = 0.5938\n",
      "Epoch 1, Batch 15600: Loss = 0.6667, Accuracy = 0.6562\n",
      "Epoch 1, Batch 15700: Loss = 0.5997, Accuracy = 0.6875\n",
      "Epoch 1, Batch 15800: Loss = 0.5193, Accuracy = 0.7812\n",
      "Epoch 1, Batch 15900: Loss = 0.6301, Accuracy = 0.6250\n",
      "Epoch 1, Batch 16000: Loss = 0.4962, Accuracy = 0.8750\n",
      "Epoch 1, Batch 16100: Loss = 0.6394, Accuracy = 0.6250\n",
      "Epoch 1, Batch 16200: Loss = 0.6908, Accuracy = 0.6250\n",
      "Epoch 1, Batch 16300: Loss = 0.6175, Accuracy = 0.7188\n",
      "Epoch 1, Batch 16400: Loss = 0.6419, Accuracy = 0.6562\n",
      "Epoch 1, Batch 16500: Loss = 0.6492, Accuracy = 0.6250\n",
      "Epoch 1, Batch 16600: Loss = 0.6442, Accuracy = 0.6875\n",
      "Epoch 1, Batch 16700: Loss = 0.5504, Accuracy = 0.6875\n",
      "Epoch 1, Batch 16800: Loss = 0.6818, Accuracy = 0.6562\n",
      "Epoch 1, Batch 16900: Loss = 0.6368, Accuracy = 0.6562\n",
      "Epoch 1, Batch 17000: Loss = 0.5519, Accuracy = 0.7812\n",
      "Epoch 1, Batch 17100: Loss = 0.6012, Accuracy = 0.6875\n",
      "Epoch 1, Batch 17200: Loss = 0.5642, Accuracy = 0.7812\n",
      "Epoch 1, Batch 17300: Loss = 0.6129, Accuracy = 0.6562\n",
      "Epoch 1, Batch 17400: Loss = 0.5059, Accuracy = 0.6875\n",
      "Epoch 1, Batch 17500: Loss = 0.5543, Accuracy = 0.7812\n",
      "Epoch 1, Batch 17600: Loss = 0.6171, Accuracy = 0.6562\n",
      "Epoch 1, Batch 17700: Loss = 0.5642, Accuracy = 0.7188\n",
      "Epoch 1, Batch 17800: Loss = 0.5930, Accuracy = 0.7500\n",
      "Epoch 1, Batch 17900: Loss = 0.7333, Accuracy = 0.5625\n",
      "Epoch 1, Batch 18000: Loss = 0.7032, Accuracy = 0.5625\n",
      "Epoch 1, Batch 18100: Loss = 0.5801, Accuracy = 0.5938\n",
      "Epoch 1, Batch 18200: Loss = 0.4837, Accuracy = 0.8750\n",
      "Epoch 1, Batch 18300: Loss = 0.5994, Accuracy = 0.7188\n",
      "Epoch 1, Batch 18400: Loss = 0.5409, Accuracy = 0.7188\n",
      "Epoch 1, Batch 18500: Loss = 0.6067, Accuracy = 0.6562\n",
      "Epoch 1, Batch 18600: Loss = 0.6765, Accuracy = 0.6562\n",
      "Epoch 1, Batch 18700: Loss = 0.6455, Accuracy = 0.7188\n",
      "Epoch 1, Batch 18800: Loss = 0.5186, Accuracy = 0.8750\n",
      "Epoch 1, Batch 18900: Loss = 0.5421, Accuracy = 0.7188\n",
      "Epoch 1, Batch 19000: Loss = 0.5773, Accuracy = 0.7188\n",
      "Epoch 1, Batch 19100: Loss = 0.5061, Accuracy = 0.7812\n",
      "Epoch 1, Batch 19200: Loss = 0.5064, Accuracy = 0.7500\n",
      "Epoch 1, Batch 19300: Loss = 0.5629, Accuracy = 0.6562\n",
      "Epoch 1, Batch 19400: Loss = 0.5992, Accuracy = 0.7500\n",
      "Epoch 1, Batch 19500: Loss = 0.5772, Accuracy = 0.7188\n",
      "Epoch 1, Batch 19600: Loss = 0.5391, Accuracy = 0.8438\n",
      "Epoch 1, Batch 19700: Loss = 0.5771, Accuracy = 0.6875\n",
      "Epoch 1, Batch 19800: Loss = 0.6715, Accuracy = 0.5938\n",
      "Epoch 1, Batch 19900: Loss = 0.5681, Accuracy = 0.7188\n",
      "Epoch 1, Batch 20000: Loss = 0.5311, Accuracy = 0.7188\n",
      "Epoch 1, Batch 20100: Loss = 0.5590, Accuracy = 0.7188\n",
      "Epoch 1, Batch 20200: Loss = 0.5888, Accuracy = 0.6875\n",
      "Epoch 1, Batch 20300: Loss = 0.6255, Accuracy = 0.7188\n",
      "Epoch 1, Batch 20400: Loss = 0.4636, Accuracy = 0.8750\n",
      "Epoch 1, Batch 20500: Loss = 0.7007, Accuracy = 0.5625\n",
      "Epoch 1, Batch 20600: Loss = 0.6553, Accuracy = 0.6875\n",
      "Epoch 1, Batch 20700: Loss = 0.5767, Accuracy = 0.7812\n",
      "Epoch 1, Batch 20800: Loss = 0.5608, Accuracy = 0.8125\n",
      "Epoch 1, Batch 20900: Loss = 0.5176, Accuracy = 0.8438\n",
      "Epoch 1, Batch 21000: Loss = 0.5146, Accuracy = 0.7188\n",
      "Epoch 1, Batch 21100: Loss = 0.5027, Accuracy = 0.7812\n",
      "Epoch 1, Batch 21200: Loss = 0.5832, Accuracy = 0.8125\n",
      "Epoch 1, Batch 21300: Loss = 0.5918, Accuracy = 0.6875\n",
      "Epoch 1, Batch 21400: Loss = 0.5753, Accuracy = 0.7188\n",
      "Epoch 1, Batch 21500: Loss = 0.5819, Accuracy = 0.7188\n",
      "Epoch 1, Batch 21600: Loss = 0.7367, Accuracy = 0.5625\n",
      "Epoch 1, Batch 21700: Loss = 0.6167, Accuracy = 0.6875\n",
      "Epoch 1, Batch 21800: Loss = 0.6163, Accuracy = 0.7188\n",
      "Epoch 1: Train Loss = 0.6042, Train Accuracy = 0.6905, Time = 477.82s\n",
      "Validation Accuracy: 0.7024\n",
      "Epoch 2, Batch 100: Loss = 0.5843, Accuracy = 0.7500\n",
      "Epoch 2, Batch 200: Loss = 0.5957, Accuracy = 0.6875\n",
      "Epoch 2, Batch 300: Loss = 0.7745, Accuracy = 0.5000\n",
      "Epoch 2, Batch 400: Loss = 0.5079, Accuracy = 0.7812\n",
      "Epoch 2, Batch 500: Loss = 0.7147, Accuracy = 0.5625\n",
      "Epoch 2, Batch 600: Loss = 0.5281, Accuracy = 0.7188\n",
      "Epoch 2, Batch 700: Loss = 0.5999, Accuracy = 0.6250\n",
      "Epoch 2, Batch 800: Loss = 0.7341, Accuracy = 0.5625\n",
      "Epoch 2, Batch 900: Loss = 0.5540, Accuracy = 0.7812\n",
      "Epoch 2, Batch 1000: Loss = 0.5812, Accuracy = 0.7812\n",
      "Epoch 2, Batch 1100: Loss = 0.6428, Accuracy = 0.5938\n",
      "Epoch 2, Batch 1200: Loss = 0.5937, Accuracy = 0.7188\n",
      "Epoch 2, Batch 1300: Loss = 0.4955, Accuracy = 0.8125\n",
      "Epoch 2, Batch 1400: Loss = 0.6352, Accuracy = 0.6250\n",
      "Epoch 2, Batch 1500: Loss = 0.4695, Accuracy = 0.7812\n",
      "Epoch 2, Batch 1600: Loss = 0.5433, Accuracy = 0.8125\n",
      "Epoch 2, Batch 1700: Loss = 0.6892, Accuracy = 0.6562\n",
      "Epoch 2, Batch 1800: Loss = 0.4428, Accuracy = 0.8438\n",
      "Epoch 2, Batch 1900: Loss = 0.5449, Accuracy = 0.7812\n",
      "Epoch 2, Batch 2000: Loss = 0.6318, Accuracy = 0.7188\n",
      "Epoch 2, Batch 2100: Loss = 0.5740, Accuracy = 0.7812\n",
      "Epoch 2, Batch 2200: Loss = 0.5270, Accuracy = 0.8125\n",
      "Epoch 2, Batch 2300: Loss = 0.6033, Accuracy = 0.7188\n",
      "Epoch 2, Batch 2400: Loss = 0.6676, Accuracy = 0.5625\n",
      "Epoch 2, Batch 2500: Loss = 0.6549, Accuracy = 0.5938\n",
      "Epoch 2, Batch 2600: Loss = 0.5401, Accuracy = 0.7812\n",
      "Epoch 2, Batch 2700: Loss = 0.6753, Accuracy = 0.5000\n",
      "Epoch 2, Batch 2800: Loss = 0.5869, Accuracy = 0.7188\n",
      "Epoch 2, Batch 2900: Loss = 0.5370, Accuracy = 0.7188\n",
      "Epoch 2, Batch 3000: Loss = 0.5724, Accuracy = 0.7500\n",
      "Epoch 2, Batch 3100: Loss = 0.6111, Accuracy = 0.7188\n",
      "Epoch 2, Batch 3200: Loss = 0.6585, Accuracy = 0.5625\n",
      "Epoch 2, Batch 3300: Loss = 0.5910, Accuracy = 0.6250\n",
      "Epoch 2, Batch 3400: Loss = 0.5943, Accuracy = 0.7812\n",
      "Epoch 2, Batch 3500: Loss = 0.7007, Accuracy = 0.6250\n",
      "Epoch 2, Batch 3600: Loss = 0.5649, Accuracy = 0.7188\n",
      "Epoch 2, Batch 3700: Loss = 0.6728, Accuracy = 0.6875\n",
      "Epoch 2, Batch 3800: Loss = 0.6232, Accuracy = 0.6562\n",
      "Epoch 2, Batch 3900: Loss = 0.5981, Accuracy = 0.7812\n",
      "Epoch 2, Batch 4000: Loss = 0.6196, Accuracy = 0.7812\n",
      "Epoch 2, Batch 4100: Loss = 0.5266, Accuracy = 0.7500\n",
      "Epoch 2, Batch 4200: Loss = 0.6532, Accuracy = 0.6562\n",
      "Epoch 2, Batch 4300: Loss = 0.6012, Accuracy = 0.7188\n",
      "Epoch 2, Batch 4400: Loss = 0.6137, Accuracy = 0.6250\n",
      "Epoch 2, Batch 4500: Loss = 0.6064, Accuracy = 0.6562\n",
      "Epoch 2, Batch 4600: Loss = 0.5105, Accuracy = 0.7500\n",
      "Epoch 2, Batch 4700: Loss = 0.6403, Accuracy = 0.7500\n",
      "Epoch 2, Batch 4800: Loss = 0.5488, Accuracy = 0.6875\n",
      "Epoch 2, Batch 4900: Loss = 0.4352, Accuracy = 0.9062\n",
      "Epoch 2, Batch 5000: Loss = 0.6100, Accuracy = 0.6250\n",
      "Epoch 2, Batch 5100: Loss = 0.5417, Accuracy = 0.7188\n",
      "Epoch 2, Batch 5200: Loss = 0.5981, Accuracy = 0.7188\n",
      "Epoch 2, Batch 5300: Loss = 0.6210, Accuracy = 0.6875\n",
      "Epoch 2, Batch 5400: Loss = 0.6819, Accuracy = 0.6562\n",
      "Epoch 2, Batch 5500: Loss = 0.6037, Accuracy = 0.7188\n",
      "Epoch 2, Batch 5600: Loss = 0.6598, Accuracy = 0.8125\n",
      "Epoch 2, Batch 5700: Loss = 0.5953, Accuracy = 0.7500\n",
      "Epoch 2, Batch 5800: Loss = 0.7115, Accuracy = 0.5938\n",
      "Epoch 2, Batch 5900: Loss = 0.6334, Accuracy = 0.6250\n",
      "Epoch 2, Batch 6000: Loss = 0.6719, Accuracy = 0.7500\n",
      "Epoch 2, Batch 6100: Loss = 0.8425, Accuracy = 0.5312\n",
      "Epoch 2, Batch 6200: Loss = 0.6936, Accuracy = 0.6562\n",
      "Epoch 2, Batch 6300: Loss = 0.5914, Accuracy = 0.6875\n",
      "Epoch 2, Batch 6400: Loss = 0.6235, Accuracy = 0.6875\n",
      "Epoch 2, Batch 6500: Loss = 0.5187, Accuracy = 0.7500\n",
      "Epoch 2, Batch 6600: Loss = 0.6394, Accuracy = 0.6875\n",
      "Epoch 2, Batch 6700: Loss = 0.5418, Accuracy = 0.7500\n",
      "Epoch 2, Batch 6800: Loss = 0.6426, Accuracy = 0.6562\n",
      "Epoch 2, Batch 6900: Loss = 0.5720, Accuracy = 0.7500\n",
      "Epoch 2, Batch 7000: Loss = 0.6394, Accuracy = 0.6562\n",
      "Epoch 2, Batch 7100: Loss = 0.6424, Accuracy = 0.7812\n",
      "Epoch 2, Batch 7200: Loss = 0.7197, Accuracy = 0.5938\n",
      "Epoch 2, Batch 7300: Loss = 0.6094, Accuracy = 0.6875\n",
      "Epoch 2, Batch 7400: Loss = 0.5249, Accuracy = 0.7188\n",
      "Epoch 2, Batch 7500: Loss = 0.5744, Accuracy = 0.6875\n",
      "Epoch 2, Batch 7600: Loss = 0.4419, Accuracy = 0.9062\n",
      "Epoch 2, Batch 7700: Loss = 0.5533, Accuracy = 0.7500\n",
      "Epoch 2, Batch 7800: Loss = 0.5017, Accuracy = 0.7188\n",
      "Epoch 2, Batch 7900: Loss = 0.7156, Accuracy = 0.5938\n",
      "Epoch 2, Batch 8000: Loss = 0.5417, Accuracy = 0.7500\n",
      "Epoch 2, Batch 8100: Loss = 0.5810, Accuracy = 0.7188\n",
      "Epoch 2, Batch 8200: Loss = 0.4845, Accuracy = 0.8125\n",
      "Epoch 2, Batch 8300: Loss = 0.6346, Accuracy = 0.6562\n",
      "Epoch 2, Batch 8400: Loss = 0.6204, Accuracy = 0.6875\n",
      "Epoch 2, Batch 8500: Loss = 0.6594, Accuracy = 0.6875\n",
      "Epoch 2, Batch 8600: Loss = 0.5316, Accuracy = 0.7188\n",
      "Epoch 2, Batch 8700: Loss = 0.4819, Accuracy = 0.8750\n",
      "Epoch 2, Batch 8800: Loss = 0.5901, Accuracy = 0.8125\n",
      "Epoch 2, Batch 8900: Loss = 0.5503, Accuracy = 0.7500\n",
      "Epoch 2, Batch 9000: Loss = 0.4992, Accuracy = 0.8125\n",
      "Epoch 2, Batch 9100: Loss = 0.6065, Accuracy = 0.5938\n",
      "Epoch 2, Batch 9200: Loss = 0.6646, Accuracy = 0.5625\n",
      "Epoch 2, Batch 9300: Loss = 0.6226, Accuracy = 0.6562\n",
      "Epoch 2, Batch 9400: Loss = 0.5734, Accuracy = 0.7188\n",
      "Epoch 2, Batch 9500: Loss = 0.5515, Accuracy = 0.6875\n",
      "Epoch 2, Batch 9600: Loss = 0.5504, Accuracy = 0.7500\n",
      "Epoch 2, Batch 9700: Loss = 0.5500, Accuracy = 0.7188\n",
      "Epoch 2, Batch 9800: Loss = 0.5992, Accuracy = 0.6250\n",
      "Epoch 2, Batch 9900: Loss = 0.6019, Accuracy = 0.5938\n",
      "Epoch 2, Batch 10000: Loss = 0.5326, Accuracy = 0.7500\n",
      "Epoch 2, Batch 10100: Loss = 0.4049, Accuracy = 0.8750\n",
      "Epoch 2, Batch 10200: Loss = 0.6195, Accuracy = 0.7188\n",
      "Epoch 2, Batch 10300: Loss = 0.6094, Accuracy = 0.6875\n",
      "Epoch 2, Batch 10400: Loss = 0.6027, Accuracy = 0.6562\n",
      "Epoch 2, Batch 10500: Loss = 0.5761, Accuracy = 0.6875\n",
      "Epoch 2, Batch 10600: Loss = 0.6726, Accuracy = 0.6562\n",
      "Epoch 2, Batch 10700: Loss = 0.6844, Accuracy = 0.6562\n",
      "Epoch 2, Batch 10800: Loss = 0.6031, Accuracy = 0.6250\n",
      "Epoch 2, Batch 10900: Loss = 0.5751, Accuracy = 0.7188\n",
      "Epoch 2, Batch 11000: Loss = 0.7277, Accuracy = 0.5625\n",
      "Epoch 2, Batch 11100: Loss = 0.5994, Accuracy = 0.7188\n",
      "Epoch 2, Batch 11200: Loss = 0.6102, Accuracy = 0.7188\n",
      "Epoch 2, Batch 11300: Loss = 0.6838, Accuracy = 0.6875\n",
      "Epoch 2, Batch 11400: Loss = 0.6063, Accuracy = 0.6875\n",
      "Epoch 2, Batch 11500: Loss = 0.5939, Accuracy = 0.5938\n",
      "Epoch 2, Batch 11600: Loss = 0.7755, Accuracy = 0.5312\n",
      "Epoch 2, Batch 11700: Loss = 0.5676, Accuracy = 0.7188\n",
      "Epoch 2, Batch 11800: Loss = 0.5375, Accuracy = 0.7188\n",
      "Epoch 2, Batch 11900: Loss = 0.4708, Accuracy = 0.8438\n",
      "Epoch 2, Batch 12000: Loss = 0.7044, Accuracy = 0.5938\n",
      "Epoch 2, Batch 12100: Loss = 0.6150, Accuracy = 0.5938\n",
      "Epoch 2, Batch 12200: Loss = 0.5778, Accuracy = 0.7812\n",
      "Epoch 2, Batch 12300: Loss = 0.5846, Accuracy = 0.6562\n",
      "Epoch 2, Batch 12400: Loss = 0.5808, Accuracy = 0.6562\n",
      "Epoch 2, Batch 12500: Loss = 0.5481, Accuracy = 0.7500\n",
      "Epoch 2, Batch 12600: Loss = 0.5548, Accuracy = 0.7812\n",
      "Epoch 2, Batch 12700: Loss = 0.6528, Accuracy = 0.6250\n",
      "Epoch 2, Batch 12800: Loss = 0.5045, Accuracy = 0.7500\n",
      "Epoch 2, Batch 12900: Loss = 0.6036, Accuracy = 0.6562\n",
      "Epoch 2, Batch 13000: Loss = 0.5705, Accuracy = 0.7812\n",
      "Epoch 2, Batch 13100: Loss = 0.6252, Accuracy = 0.6875\n",
      "Epoch 2, Batch 13200: Loss = 0.4816, Accuracy = 0.8438\n",
      "Epoch 2, Batch 13300: Loss = 0.7728, Accuracy = 0.5000\n",
      "Epoch 2, Batch 13400: Loss = 0.6104, Accuracy = 0.7500\n",
      "Epoch 2, Batch 13500: Loss = 0.5652, Accuracy = 0.7188\n",
      "Epoch 2, Batch 13600: Loss = 0.6057, Accuracy = 0.7188\n",
      "Epoch 2, Batch 13700: Loss = 0.6158, Accuracy = 0.6562\n",
      "Epoch 2, Batch 13800: Loss = 0.6195, Accuracy = 0.6562\n",
      "Epoch 2, Batch 13900: Loss = 0.5112, Accuracy = 0.7812\n",
      "Epoch 2, Batch 14000: Loss = 0.4390, Accuracy = 0.9062\n",
      "Epoch 2, Batch 14100: Loss = 0.5851, Accuracy = 0.7812\n",
      "Epoch 2, Batch 14200: Loss = 0.5882, Accuracy = 0.6875\n",
      "Epoch 2, Batch 14300: Loss = 0.5317, Accuracy = 0.7188\n",
      "Epoch 2, Batch 14400: Loss = 0.6242, Accuracy = 0.6875\n",
      "Epoch 2, Batch 14500: Loss = 0.6289, Accuracy = 0.5938\n",
      "Epoch 2, Batch 14600: Loss = 0.6616, Accuracy = 0.5000\n",
      "Epoch 2, Batch 14700: Loss = 0.5676, Accuracy = 0.6562\n",
      "Epoch 2, Batch 14800: Loss = 0.5485, Accuracy = 0.8125\n",
      "Epoch 2, Batch 14900: Loss = 0.6460, Accuracy = 0.7188\n",
      "Epoch 2, Batch 15000: Loss = 0.5926, Accuracy = 0.7500\n",
      "Epoch 2, Batch 15100: Loss = 0.5887, Accuracy = 0.7812\n",
      "Epoch 2, Batch 15200: Loss = 0.6093, Accuracy = 0.7500\n",
      "Epoch 2, Batch 15300: Loss = 0.6092, Accuracy = 0.7500\n",
      "Epoch 2, Batch 15400: Loss = 0.5480, Accuracy = 0.7812\n",
      "Epoch 2, Batch 15500: Loss = 0.6026, Accuracy = 0.7188\n",
      "Epoch 2, Batch 15600: Loss = 0.6560, Accuracy = 0.6562\n",
      "Epoch 2, Batch 15700: Loss = 0.4810, Accuracy = 0.8125\n",
      "Epoch 2, Batch 15800: Loss = 0.5169, Accuracy = 0.7500\n",
      "Epoch 2, Batch 15900: Loss = 0.5714, Accuracy = 0.7188\n",
      "Epoch 2, Batch 16000: Loss = 0.6717, Accuracy = 0.7188\n",
      "Epoch 2, Batch 16100: Loss = 0.6151, Accuracy = 0.6875\n",
      "Epoch 2, Batch 16200: Loss = 0.5471, Accuracy = 0.6875\n",
      "Epoch 2, Batch 16300: Loss = 0.5508, Accuracy = 0.6875\n",
      "Epoch 2, Batch 16400: Loss = 0.5153, Accuracy = 0.7812\n",
      "Epoch 2, Batch 16500: Loss = 0.7244, Accuracy = 0.6562\n",
      "Epoch 2, Batch 16600: Loss = 0.5742, Accuracy = 0.7500\n",
      "Epoch 2, Batch 16700: Loss = 0.6306, Accuracy = 0.6875\n",
      "Epoch 2, Batch 16800: Loss = 0.6140, Accuracy = 0.7500\n",
      "Epoch 2, Batch 16900: Loss = 0.6928, Accuracy = 0.7188\n",
      "Epoch 2, Batch 17000: Loss = 0.5698, Accuracy = 0.6562\n",
      "Epoch 2, Batch 17100: Loss = 0.6186, Accuracy = 0.7500\n",
      "Epoch 2, Batch 17200: Loss = 0.6098, Accuracy = 0.7812\n",
      "Epoch 2, Batch 17300: Loss = 0.5255, Accuracy = 0.7812\n",
      "Epoch 2, Batch 17400: Loss = 0.5557, Accuracy = 0.6875\n",
      "Epoch 2, Batch 17500: Loss = 0.5909, Accuracy = 0.6875\n",
      "Epoch 2, Batch 17600: Loss = 0.5517, Accuracy = 0.7188\n",
      "Epoch 2, Batch 17700: Loss = 0.6791, Accuracy = 0.5938\n",
      "Epoch 2, Batch 17800: Loss = 0.5241, Accuracy = 0.7812\n",
      "Epoch 2, Batch 17900: Loss = 0.6180, Accuracy = 0.6250\n",
      "Epoch 2, Batch 18000: Loss = 0.5295, Accuracy = 0.8125\n",
      "Epoch 2, Batch 18100: Loss = 0.7044, Accuracy = 0.6562\n",
      "Epoch 2, Batch 18200: Loss = 0.5499, Accuracy = 0.7812\n",
      "Epoch 2, Batch 18300: Loss = 0.6316, Accuracy = 0.6250\n",
      "Epoch 2, Batch 18400: Loss = 0.6251, Accuracy = 0.6250\n",
      "Epoch 2, Batch 18500: Loss = 0.5951, Accuracy = 0.6250\n",
      "Epoch 2, Batch 18600: Loss = 0.6770, Accuracy = 0.5938\n",
      "Epoch 2, Batch 18700: Loss = 0.6172, Accuracy = 0.6875\n",
      "Epoch 2, Batch 18800: Loss = 0.7577, Accuracy = 0.6562\n",
      "Epoch 2, Batch 18900: Loss = 0.5184, Accuracy = 0.7500\n",
      "Epoch 2, Batch 19000: Loss = 0.6237, Accuracy = 0.6250\n",
      "Epoch 2, Batch 19100: Loss = 0.4441, Accuracy = 0.8750\n",
      "Epoch 2, Batch 19200: Loss = 0.6089, Accuracy = 0.5938\n",
      "Epoch 2, Batch 19300: Loss = 0.5615, Accuracy = 0.7812\n",
      "Epoch 2, Batch 19400: Loss = 0.5527, Accuracy = 0.7500\n",
      "Epoch 2, Batch 19500: Loss = 0.4952, Accuracy = 0.7188\n",
      "Epoch 2, Batch 19600: Loss = 0.6630, Accuracy = 0.5312\n",
      "Epoch 2, Batch 19700: Loss = 0.5297, Accuracy = 0.6875\n",
      "Epoch 2, Batch 19800: Loss = 0.5587, Accuracy = 0.6875\n",
      "Epoch 2, Batch 19900: Loss = 0.5511, Accuracy = 0.7500\n",
      "Epoch 2, Batch 20000: Loss = 0.6672, Accuracy = 0.6562\n",
      "Epoch 2, Batch 20100: Loss = 0.6828, Accuracy = 0.6250\n",
      "Epoch 2, Batch 20200: Loss = 0.4592, Accuracy = 0.7812\n",
      "Epoch 2, Batch 20300: Loss = 0.6741, Accuracy = 0.5625\n",
      "Epoch 2, Batch 20400: Loss = 0.5257, Accuracy = 0.7812\n",
      "Epoch 2, Batch 20500: Loss = 0.6748, Accuracy = 0.7812\n",
      "Epoch 2, Batch 20600: Loss = 0.5522, Accuracy = 0.7812\n",
      "Epoch 2, Batch 20700: Loss = 0.6236, Accuracy = 0.6562\n",
      "Epoch 2, Batch 20800: Loss = 0.5441, Accuracy = 0.7500\n",
      "Epoch 2, Batch 20900: Loss = 0.6020, Accuracy = 0.6875\n",
      "Epoch 2, Batch 21000: Loss = 0.6437, Accuracy = 0.6562\n",
      "Epoch 2, Batch 21100: Loss = 0.5647, Accuracy = 0.7500\n",
      "Epoch 2, Batch 21200: Loss = 0.5251, Accuracy = 0.7812\n",
      "Epoch 2, Batch 21300: Loss = 0.5788, Accuracy = 0.8125\n",
      "Epoch 2, Batch 21400: Loss = 0.5160, Accuracy = 0.8438\n",
      "Epoch 2, Batch 21500: Loss = 0.6386, Accuracy = 0.6250\n",
      "Epoch 2, Batch 21600: Loss = 0.5760, Accuracy = 0.6562\n",
      "Epoch 2, Batch 21700: Loss = 0.5484, Accuracy = 0.7188\n",
      "Epoch 2, Batch 21800: Loss = 0.5852, Accuracy = 0.7188\n",
      "Epoch 2: Train Loss = 0.5981, Train Accuracy = 0.6995, Time = 549.22s\n",
      "Validation Accuracy: 0.7018\n",
      "Epoch 3, Batch 100: Loss = 0.5706, Accuracy = 0.7188\n",
      "Epoch 3, Batch 200: Loss = 0.7129, Accuracy = 0.6562\n",
      "Epoch 3, Batch 300: Loss = 0.5989, Accuracy = 0.6250\n",
      "Epoch 3, Batch 400: Loss = 0.5528, Accuracy = 0.7188\n",
      "Epoch 3, Batch 500: Loss = 0.5341, Accuracy = 0.7812\n",
      "Epoch 3, Batch 600: Loss = 0.4564, Accuracy = 0.8125\n",
      "Epoch 3, Batch 700: Loss = 0.6306, Accuracy = 0.7500\n",
      "Epoch 3, Batch 800: Loss = 0.4780, Accuracy = 0.8125\n",
      "Epoch 3, Batch 900: Loss = 0.4116, Accuracy = 0.8438\n",
      "Epoch 3, Batch 1000: Loss = 0.4960, Accuracy = 0.7812\n",
      "Epoch 3, Batch 1100: Loss = 0.5692, Accuracy = 0.7812\n",
      "Epoch 3, Batch 1200: Loss = 0.5588, Accuracy = 0.7188\n",
      "Epoch 3, Batch 1300: Loss = 0.5280, Accuracy = 0.8125\n",
      "Epoch 3, Batch 1400: Loss = 0.5978, Accuracy = 0.6562\n",
      "Epoch 3, Batch 1500: Loss = 0.5459, Accuracy = 0.7500\n",
      "Epoch 3, Batch 1600: Loss = 0.4981, Accuracy = 0.7188\n",
      "Epoch 3, Batch 1700: Loss = 0.8349, Accuracy = 0.4375\n",
      "Epoch 3, Batch 1800: Loss = 0.7051, Accuracy = 0.6250\n",
      "Epoch 3, Batch 1900: Loss = 0.6191, Accuracy = 0.6562\n",
      "Epoch 3, Batch 2000: Loss = 0.8388, Accuracy = 0.4375\n",
      "Epoch 3, Batch 2100: Loss = 0.5080, Accuracy = 0.7812\n",
      "Epoch 3, Batch 2200: Loss = 0.5774, Accuracy = 0.7500\n",
      "Epoch 3, Batch 2300: Loss = 0.5736, Accuracy = 0.6562\n",
      "Epoch 3, Batch 2400: Loss = 0.8389, Accuracy = 0.5000\n",
      "Epoch 3, Batch 2500: Loss = 0.6018, Accuracy = 0.5938\n",
      "Epoch 3, Batch 2600: Loss = 0.6162, Accuracy = 0.7500\n",
      "Epoch 3, Batch 2700: Loss = 0.5481, Accuracy = 0.7188\n",
      "Epoch 3, Batch 2800: Loss = 0.6184, Accuracy = 0.6562\n",
      "Epoch 3, Batch 2900: Loss = 0.6758, Accuracy = 0.6250\n",
      "Epoch 3, Batch 3000: Loss = 0.5840, Accuracy = 0.6875\n",
      "Epoch 3, Batch 3100: Loss = 0.4988, Accuracy = 0.7812\n",
      "Epoch 3, Batch 3200: Loss = 0.6839, Accuracy = 0.6562\n",
      "Epoch 3, Batch 3300: Loss = 0.5814, Accuracy = 0.6562\n",
      "Epoch 3, Batch 3400: Loss = 0.7204, Accuracy = 0.7188\n",
      "Epoch 3, Batch 3500: Loss = 0.5939, Accuracy = 0.7188\n",
      "Epoch 3, Batch 3600: Loss = 0.6106, Accuracy = 0.6875\n",
      "Epoch 3, Batch 3700: Loss = 0.4926, Accuracy = 0.8125\n",
      "Epoch 3, Batch 3800: Loss = 0.4910, Accuracy = 0.8125\n",
      "Epoch 3, Batch 3900: Loss = 0.6688, Accuracy = 0.5312\n",
      "Epoch 3, Batch 4000: Loss = 0.5965, Accuracy = 0.6875\n",
      "Epoch 3, Batch 4100: Loss = 0.6775, Accuracy = 0.5938\n",
      "Epoch 3, Batch 4200: Loss = 0.7389, Accuracy = 0.5625\n",
      "Epoch 3, Batch 4300: Loss = 0.4800, Accuracy = 0.7500\n",
      "Epoch 3, Batch 4400: Loss = 0.5642, Accuracy = 0.6562\n",
      "Epoch 3, Batch 4500: Loss = 0.6322, Accuracy = 0.6562\n",
      "Epoch 3, Batch 4600: Loss = 0.6039, Accuracy = 0.7500\n",
      "Epoch 3, Batch 4700: Loss = 0.6591, Accuracy = 0.5938\n",
      "Epoch 3, Batch 4800: Loss = 0.6299, Accuracy = 0.6250\n",
      "Epoch 3, Batch 4900: Loss = 0.6294, Accuracy = 0.6562\n",
      "Epoch 3, Batch 5000: Loss = 0.6152, Accuracy = 0.6250\n",
      "Epoch 3, Batch 5100: Loss = 0.5859, Accuracy = 0.7188\n",
      "Epoch 3, Batch 5200: Loss = 0.5664, Accuracy = 0.7500\n",
      "Epoch 3, Batch 5300: Loss = 0.7801, Accuracy = 0.5000\n",
      "Epoch 3, Batch 5400: Loss = 0.6032, Accuracy = 0.5938\n",
      "Epoch 3, Batch 5500: Loss = 0.6378, Accuracy = 0.7188\n",
      "Epoch 3, Batch 5600: Loss = 0.5877, Accuracy = 0.6875\n",
      "Epoch 3, Batch 5700: Loss = 0.4463, Accuracy = 0.8438\n",
      "Epoch 3, Batch 5800: Loss = 0.4254, Accuracy = 0.8125\n",
      "Epoch 3, Batch 5900: Loss = 0.5523, Accuracy = 0.7812\n",
      "Epoch 3, Batch 6000: Loss = 0.7512, Accuracy = 0.5312\n",
      "Epoch 3, Batch 6100: Loss = 0.5680, Accuracy = 0.7500\n",
      "Epoch 3, Batch 6200: Loss = 0.5748, Accuracy = 0.7188\n",
      "Epoch 3, Batch 6300: Loss = 0.5664, Accuracy = 0.7188\n",
      "Epoch 3, Batch 6400: Loss = 0.7083, Accuracy = 0.5938\n",
      "Epoch 3, Batch 6500: Loss = 0.5980, Accuracy = 0.6875\n",
      "Epoch 3, Batch 6600: Loss = 0.6076, Accuracy = 0.6875\n",
      "Epoch 3, Batch 6700: Loss = 0.6175, Accuracy = 0.6875\n",
      "Epoch 3, Batch 6800: Loss = 0.5883, Accuracy = 0.7500\n",
      "Epoch 3, Batch 6900: Loss = 0.6416, Accuracy = 0.6562\n",
      "Epoch 3, Batch 7000: Loss = 0.5357, Accuracy = 0.6562\n",
      "Epoch 3, Batch 7100: Loss = 0.6830, Accuracy = 0.6250\n",
      "Epoch 3, Batch 7200: Loss = 0.5540, Accuracy = 0.7188\n",
      "Epoch 3, Batch 7300: Loss = 0.6726, Accuracy = 0.6250\n",
      "Epoch 3, Batch 7400: Loss = 0.6529, Accuracy = 0.6875\n",
      "Epoch 3, Batch 7500: Loss = 0.5978, Accuracy = 0.7188\n",
      "Epoch 3, Batch 7600: Loss = 0.6604, Accuracy = 0.6562\n",
      "Epoch 3, Batch 7700: Loss = 0.5459, Accuracy = 0.7500\n",
      "Epoch 3, Batch 7800: Loss = 0.7800, Accuracy = 0.5938\n",
      "Epoch 3, Batch 7900: Loss = 0.5979, Accuracy = 0.7188\n",
      "Epoch 3, Batch 8000: Loss = 0.5969, Accuracy = 0.6875\n",
      "Epoch 3, Batch 8100: Loss = 0.5478, Accuracy = 0.7812\n",
      "Epoch 3, Batch 8200: Loss = 0.5843, Accuracy = 0.7500\n",
      "Epoch 3, Batch 8300: Loss = 0.6008, Accuracy = 0.7188\n",
      "Epoch 3, Batch 8400: Loss = 0.5863, Accuracy = 0.7500\n",
      "Epoch 3, Batch 8500: Loss = 0.5977, Accuracy = 0.6250\n",
      "Epoch 3, Batch 8600: Loss = 0.5958, Accuracy = 0.7188\n",
      "Epoch 3, Batch 8700: Loss = 0.6667, Accuracy = 0.5625\n",
      "Epoch 3, Batch 8800: Loss = 0.5773, Accuracy = 0.7188\n",
      "Epoch 3, Batch 8900: Loss = 0.8063, Accuracy = 0.5625\n",
      "Epoch 3, Batch 9000: Loss = 0.6658, Accuracy = 0.5938\n",
      "Epoch 3, Batch 9100: Loss = 0.5949, Accuracy = 0.6875\n",
      "Epoch 3, Batch 9200: Loss = 0.6461, Accuracy = 0.5000\n",
      "Epoch 3, Batch 9300: Loss = 0.5119, Accuracy = 0.7188\n",
      "Epoch 3, Batch 9400: Loss = 0.5164, Accuracy = 0.7812\n",
      "Epoch 3, Batch 9500: Loss = 0.5765, Accuracy = 0.6562\n",
      "Epoch 3, Batch 9600: Loss = 0.5437, Accuracy = 0.7500\n",
      "Epoch 3, Batch 9700: Loss = 0.5856, Accuracy = 0.7500\n",
      "Epoch 3, Batch 9800: Loss = 0.6727, Accuracy = 0.6562\n",
      "Epoch 3, Batch 9900: Loss = 0.6889, Accuracy = 0.5938\n",
      "Epoch 3, Batch 10000: Loss = 0.5967, Accuracy = 0.7188\n",
      "Epoch 3, Batch 10100: Loss = 0.5857, Accuracy = 0.6875\n",
      "Epoch 3, Batch 10200: Loss = 0.5440, Accuracy = 0.7812\n",
      "Epoch 3, Batch 10300: Loss = 0.6104, Accuracy = 0.6562\n",
      "Epoch 3, Batch 10400: Loss = 0.6084, Accuracy = 0.6562\n",
      "Epoch 3, Batch 10500: Loss = 0.5374, Accuracy = 0.8125\n",
      "Epoch 3, Batch 10600: Loss = 0.6152, Accuracy = 0.6562\n",
      "Epoch 3, Batch 10700: Loss = 0.6033, Accuracy = 0.6875\n",
      "Epoch 3, Batch 10800: Loss = 0.7669, Accuracy = 0.5000\n",
      "Epoch 3, Batch 10900: Loss = 0.5210, Accuracy = 0.8125\n",
      "Epoch 3, Batch 11000: Loss = 0.6109, Accuracy = 0.6250\n",
      "Epoch 3, Batch 11100: Loss = 0.5335, Accuracy = 0.7188\n",
      "Epoch 3, Batch 11200: Loss = 0.5753, Accuracy = 0.7500\n",
      "Epoch 3, Batch 11300: Loss = 0.6388, Accuracy = 0.6562\n",
      "Epoch 3, Batch 11400: Loss = 0.6536, Accuracy = 0.6250\n",
      "Epoch 3, Batch 11500: Loss = 0.5876, Accuracy = 0.6875\n",
      "Epoch 3, Batch 11600: Loss = 0.5929, Accuracy = 0.7500\n",
      "Epoch 3, Batch 11700: Loss = 0.4966, Accuracy = 0.7812\n",
      "Epoch 3, Batch 11800: Loss = 0.6579, Accuracy = 0.6562\n",
      "Epoch 3, Batch 11900: Loss = 0.4959, Accuracy = 0.8125\n",
      "Epoch 3, Batch 12000: Loss = 0.5617, Accuracy = 0.6250\n",
      "Epoch 3, Batch 12100: Loss = 0.5414, Accuracy = 0.7188\n",
      "Epoch 3, Batch 12200: Loss = 0.6525, Accuracy = 0.6562\n",
      "Epoch 3, Batch 12300: Loss = 0.6177, Accuracy = 0.6875\n",
      "Epoch 3, Batch 12400: Loss = 0.4804, Accuracy = 0.8125\n",
      "Epoch 3, Batch 12500: Loss = 0.7163, Accuracy = 0.6562\n",
      "Epoch 3, Batch 12600: Loss = 0.6615, Accuracy = 0.6562\n",
      "Epoch 3, Batch 12700: Loss = 0.5139, Accuracy = 0.7188\n",
      "Epoch 3, Batch 12800: Loss = 0.6322, Accuracy = 0.6562\n",
      "Epoch 3, Batch 12900: Loss = 0.6384, Accuracy = 0.6875\n",
      "Epoch 3, Batch 13000: Loss = 0.6501, Accuracy = 0.6562\n",
      "Epoch 3, Batch 13100: Loss = 0.5348, Accuracy = 0.8438\n",
      "Epoch 3, Batch 13200: Loss = 0.5520, Accuracy = 0.7188\n",
      "Epoch 3, Batch 13300: Loss = 0.5782, Accuracy = 0.7188\n",
      "Epoch 3, Batch 13400: Loss = 0.6317, Accuracy = 0.7188\n",
      "Epoch 3, Batch 13500: Loss = 0.5926, Accuracy = 0.7188\n",
      "Epoch 3, Batch 13600: Loss = 0.7351, Accuracy = 0.5938\n",
      "Epoch 3, Batch 13700: Loss = 0.6300, Accuracy = 0.6562\n",
      "Epoch 3, Batch 13800: Loss = 0.6958, Accuracy = 0.5938\n",
      "Epoch 3, Batch 13900: Loss = 0.5988, Accuracy = 0.7188\n",
      "Epoch 3, Batch 14000: Loss = 0.5872, Accuracy = 0.7812\n",
      "Epoch 3, Batch 14100: Loss = 0.6063, Accuracy = 0.6562\n",
      "Epoch 3, Batch 14200: Loss = 0.5434, Accuracy = 0.8125\n",
      "Epoch 3, Batch 14300: Loss = 0.6126, Accuracy = 0.5938\n",
      "Epoch 3, Batch 14400: Loss = 0.5983, Accuracy = 0.6875\n",
      "Epoch 3, Batch 14500: Loss = 0.6860, Accuracy = 0.6250\n",
      "Epoch 3, Batch 14600: Loss = 0.6400, Accuracy = 0.6250\n",
      "Epoch 3, Batch 14700: Loss = 0.6661, Accuracy = 0.6875\n",
      "Epoch 3, Batch 14800: Loss = 0.6357, Accuracy = 0.7188\n",
      "Epoch 3, Batch 14900: Loss = 0.4497, Accuracy = 0.8125\n",
      "Epoch 3, Batch 15000: Loss = 0.6184, Accuracy = 0.6562\n",
      "Epoch 3, Batch 15100: Loss = 0.6029, Accuracy = 0.7188\n",
      "Epoch 3, Batch 15200: Loss = 0.7131, Accuracy = 0.5938\n",
      "Epoch 3, Batch 15300: Loss = 0.6939, Accuracy = 0.5938\n",
      "Epoch 3, Batch 15400: Loss = 0.5661, Accuracy = 0.6875\n",
      "Epoch 3, Batch 15500: Loss = 0.5404, Accuracy = 0.7500\n",
      "Epoch 3, Batch 15600: Loss = 0.6423, Accuracy = 0.6562\n",
      "Epoch 3, Batch 15700: Loss = 0.7206, Accuracy = 0.5938\n",
      "Epoch 3, Batch 15800: Loss = 0.6454, Accuracy = 0.5625\n",
      "Epoch 3, Batch 15900: Loss = 0.5136, Accuracy = 0.7812\n",
      "Epoch 3, Batch 16000: Loss = 0.5484, Accuracy = 0.7812\n",
      "Epoch 3, Batch 16100: Loss = 0.5735, Accuracy = 0.6875\n",
      "Epoch 3, Batch 16200: Loss = 0.4925, Accuracy = 0.8438\n",
      "Epoch 3, Batch 16300: Loss = 0.5616, Accuracy = 0.7500\n",
      "Epoch 3, Batch 16400: Loss = 0.5453, Accuracy = 0.6875\n",
      "Epoch 3, Batch 16500: Loss = 0.6400, Accuracy = 0.6562\n",
      "Epoch 3, Batch 16600: Loss = 0.5590, Accuracy = 0.6875\n",
      "Epoch 3, Batch 16700: Loss = 0.6644, Accuracy = 0.6562\n",
      "Epoch 3, Batch 16800: Loss = 0.5357, Accuracy = 0.7812\n",
      "Epoch 3, Batch 16900: Loss = 0.6378, Accuracy = 0.7500\n",
      "Epoch 3, Batch 17000: Loss = 0.5309, Accuracy = 0.7188\n",
      "Epoch 3, Batch 17100: Loss = 0.5627, Accuracy = 0.7500\n",
      "Epoch 3, Batch 17200: Loss = 0.5720, Accuracy = 0.7188\n",
      "Epoch 3, Batch 17300: Loss = 0.6086, Accuracy = 0.6875\n",
      "Epoch 3, Batch 17400: Loss = 0.6345, Accuracy = 0.7188\n",
      "Epoch 3, Batch 17500: Loss = 0.5895, Accuracy = 0.6875\n",
      "Epoch 3, Batch 17600: Loss = 0.6035, Accuracy = 0.6562\n",
      "Epoch 3, Batch 17700: Loss = 0.6453, Accuracy = 0.6875\n",
      "Epoch 3, Batch 17800: Loss = 0.5891, Accuracy = 0.5938\n",
      "Epoch 3, Batch 17900: Loss = 0.7305, Accuracy = 0.5625\n",
      "Epoch 3, Batch 18000: Loss = 0.4610, Accuracy = 0.8125\n",
      "Epoch 3, Batch 18100: Loss = 0.5870, Accuracy = 0.6875\n",
      "Epoch 3, Batch 18200: Loss = 0.6203, Accuracy = 0.6875\n",
      "Epoch 3, Batch 18300: Loss = 0.6161, Accuracy = 0.6875\n",
      "Epoch 3, Batch 18400: Loss = 0.6497, Accuracy = 0.5625\n",
      "Epoch 3, Batch 18500: Loss = 0.5290, Accuracy = 0.6875\n",
      "Epoch 3, Batch 18600: Loss = 0.5331, Accuracy = 0.7812\n",
      "Epoch 3, Batch 18700: Loss = 0.5160, Accuracy = 0.8125\n",
      "Epoch 3, Batch 18800: Loss = 0.6087, Accuracy = 0.7500\n",
      "Epoch 3, Batch 18900: Loss = 0.6306, Accuracy = 0.6875\n",
      "Epoch 3, Batch 19000: Loss = 0.6265, Accuracy = 0.7188\n",
      "Epoch 3, Batch 19100: Loss = 0.7395, Accuracy = 0.6250\n",
      "Epoch 3, Batch 19200: Loss = 0.6072, Accuracy = 0.6875\n",
      "Epoch 3, Batch 19300: Loss = 0.5657, Accuracy = 0.7188\n",
      "Epoch 3, Batch 19400: Loss = 0.5263, Accuracy = 0.7188\n",
      "Epoch 3, Batch 19500: Loss = 0.4971, Accuracy = 0.8125\n",
      "Epoch 3, Batch 19600: Loss = 0.5665, Accuracy = 0.7500\n",
      "Epoch 3, Batch 19700: Loss = 0.6044, Accuracy = 0.7500\n",
      "Epoch 3, Batch 19800: Loss = 0.5247, Accuracy = 0.7500\n",
      "Epoch 3, Batch 19900: Loss = 0.4749, Accuracy = 0.8438\n",
      "Epoch 3, Batch 20000: Loss = 0.5441, Accuracy = 0.7812\n",
      "Epoch 3, Batch 20100: Loss = 0.6075, Accuracy = 0.6875\n",
      "Epoch 3, Batch 20200: Loss = 0.5501, Accuracy = 0.6875\n",
      "Epoch 3, Batch 20300: Loss = 0.6169, Accuracy = 0.6875\n",
      "Epoch 3, Batch 20400: Loss = 0.6078, Accuracy = 0.6875\n",
      "Epoch 3, Batch 20500: Loss = 0.7002, Accuracy = 0.6250\n",
      "Epoch 3, Batch 20600: Loss = 0.6734, Accuracy = 0.6562\n",
      "Epoch 3, Batch 20700: Loss = 0.5818, Accuracy = 0.7500\n",
      "Epoch 3, Batch 20800: Loss = 0.6419, Accuracy = 0.6562\n",
      "Epoch 3, Batch 20900: Loss = 0.5260, Accuracy = 0.7500\n",
      "Epoch 3, Batch 21000: Loss = 0.6849, Accuracy = 0.5938\n",
      "Epoch 3, Batch 21100: Loss = 0.7803, Accuracy = 0.6250\n",
      "Epoch 3, Batch 21200: Loss = 0.6894, Accuracy = 0.5625\n",
      "Epoch 3, Batch 21300: Loss = 0.4634, Accuracy = 0.8750\n",
      "Epoch 3, Batch 21400: Loss = 0.5878, Accuracy = 0.7812\n",
      "Epoch 3, Batch 21500: Loss = 0.5385, Accuracy = 0.8125\n",
      "Epoch 3, Batch 21600: Loss = 0.5392, Accuracy = 0.7812\n",
      "Epoch 3, Batch 21700: Loss = 0.5547, Accuracy = 0.7188\n",
      "Epoch 3, Batch 21800: Loss = 0.5710, Accuracy = 0.7188\n",
      "Epoch 3: Train Loss = 0.5976, Train Accuracy = 0.6998, Time = 504.54s\n",
      "Validation Accuracy: 0.7035\n",
      "Epoch 4, Batch 100: Loss = 0.6851, Accuracy = 0.5938\n",
      "Epoch 4, Batch 200: Loss = 0.5709, Accuracy = 0.6875\n",
      "Epoch 4, Batch 300: Loss = 0.5494, Accuracy = 0.7500\n",
      "Epoch 4, Batch 400: Loss = 0.4840, Accuracy = 0.8750\n",
      "Epoch 4, Batch 500: Loss = 0.5967, Accuracy = 0.6562\n",
      "Epoch 4, Batch 600: Loss = 0.6868, Accuracy = 0.5625\n",
      "Epoch 4, Batch 700: Loss = 0.5229, Accuracy = 0.7812\n",
      "Epoch 4, Batch 800: Loss = 0.6863, Accuracy = 0.6250\n",
      "Epoch 4, Batch 900: Loss = 0.6807, Accuracy = 0.6875\n",
      "Epoch 4, Batch 1000: Loss = 0.6634, Accuracy = 0.6562\n",
      "Epoch 4, Batch 1100: Loss = 0.7016, Accuracy = 0.5312\n",
      "Epoch 4, Batch 1200: Loss = 0.5914, Accuracy = 0.6250\n",
      "Epoch 4, Batch 1300: Loss = 0.4928, Accuracy = 0.8125\n",
      "Epoch 4, Batch 1400: Loss = 0.5304, Accuracy = 0.6875\n",
      "Epoch 4, Batch 1500: Loss = 0.6420, Accuracy = 0.5938\n",
      "Epoch 4, Batch 1600: Loss = 0.5387, Accuracy = 0.6562\n",
      "Epoch 4, Batch 1700: Loss = 0.4888, Accuracy = 0.7812\n",
      "Epoch 4, Batch 1800: Loss = 0.5509, Accuracy = 0.7812\n",
      "Epoch 4, Batch 1900: Loss = 0.5201, Accuracy = 0.7812\n",
      "Epoch 4, Batch 2000: Loss = 0.5878, Accuracy = 0.6875\n",
      "Epoch 4, Batch 2100: Loss = 0.5834, Accuracy = 0.6250\n",
      "Epoch 4, Batch 2200: Loss = 0.5186, Accuracy = 0.8125\n",
      "Epoch 4, Batch 2300: Loss = 0.4683, Accuracy = 0.8125\n",
      "Epoch 4, Batch 2400: Loss = 0.4937, Accuracy = 0.8125\n",
      "Epoch 4, Batch 2500: Loss = 0.5222, Accuracy = 0.7500\n",
      "Epoch 4, Batch 2600: Loss = 0.5338, Accuracy = 0.7500\n",
      "Epoch 4, Batch 2700: Loss = 0.6930, Accuracy = 0.6875\n",
      "Epoch 4, Batch 2800: Loss = 0.5992, Accuracy = 0.7500\n",
      "Epoch 4, Batch 2900: Loss = 0.5823, Accuracy = 0.5938\n",
      "Epoch 4, Batch 3000: Loss = 0.5747, Accuracy = 0.7188\n",
      "Epoch 4, Batch 3100: Loss = 0.6101, Accuracy = 0.6250\n",
      "Epoch 4, Batch 3200: Loss = 0.5546, Accuracy = 0.7500\n",
      "Epoch 4, Batch 3300: Loss = 0.5923, Accuracy = 0.6875\n",
      "Epoch 4, Batch 3400: Loss = 0.6037, Accuracy = 0.6250\n",
      "Epoch 4, Batch 3500: Loss = 0.4903, Accuracy = 0.7812\n",
      "Epoch 4, Batch 3600: Loss = 0.6533, Accuracy = 0.6562\n",
      "Epoch 4, Batch 3700: Loss = 0.5481, Accuracy = 0.7500\n",
      "Epoch 4, Batch 3800: Loss = 0.6248, Accuracy = 0.6875\n",
      "Epoch 4, Batch 3900: Loss = 0.5370, Accuracy = 0.8125\n",
      "Epoch 4, Batch 4000: Loss = 0.5752, Accuracy = 0.7188\n",
      "Epoch 4, Batch 4100: Loss = 0.5103, Accuracy = 0.7812\n",
      "Epoch 4, Batch 4200: Loss = 0.5184, Accuracy = 0.7188\n",
      "Epoch 4, Batch 4300: Loss = 0.5540, Accuracy = 0.7812\n",
      "Epoch 4, Batch 4400: Loss = 0.4732, Accuracy = 0.7500\n",
      "Epoch 4, Batch 4500: Loss = 0.5448, Accuracy = 0.7500\n",
      "Epoch 4, Batch 4600: Loss = 0.5207, Accuracy = 0.8125\n",
      "Epoch 4, Batch 4700: Loss = 0.4917, Accuracy = 0.7812\n",
      "Epoch 4, Batch 4800: Loss = 0.5664, Accuracy = 0.7500\n",
      "Epoch 4, Batch 4900: Loss = 0.6078, Accuracy = 0.6875\n",
      "Epoch 4, Batch 5000: Loss = 0.7450, Accuracy = 0.5000\n",
      "Epoch 4, Batch 5100: Loss = 0.6893, Accuracy = 0.7188\n",
      "Epoch 4, Batch 5200: Loss = 0.6840, Accuracy = 0.5938\n",
      "Epoch 4, Batch 5300: Loss = 0.5707, Accuracy = 0.7812\n",
      "Epoch 4, Batch 5400: Loss = 0.5002, Accuracy = 0.8125\n",
      "Epoch 4, Batch 5500: Loss = 0.6018, Accuracy = 0.6562\n",
      "Epoch 4, Batch 5600: Loss = 0.5434, Accuracy = 0.7812\n",
      "Epoch 4, Batch 5700: Loss = 0.6600, Accuracy = 0.5938\n",
      "Epoch 4, Batch 5800: Loss = 0.6996, Accuracy = 0.5938\n",
      "Epoch 4, Batch 5900: Loss = 0.5511, Accuracy = 0.6875\n",
      "Epoch 4, Batch 6000: Loss = 0.5829, Accuracy = 0.7812\n",
      "Epoch 4, Batch 6100: Loss = 0.5416, Accuracy = 0.8125\n",
      "Epoch 4, Batch 6200: Loss = 0.4164, Accuracy = 0.8750\n",
      "Epoch 4, Batch 6300: Loss = 0.5145, Accuracy = 0.8438\n",
      "Epoch 4, Batch 6400: Loss = 0.6593, Accuracy = 0.6875\n",
      "Epoch 4, Batch 6500: Loss = 0.7054, Accuracy = 0.6250\n",
      "Epoch 4, Batch 6600: Loss = 0.5972, Accuracy = 0.6875\n",
      "Epoch 4, Batch 6700: Loss = 0.6220, Accuracy = 0.6875\n",
      "Epoch 4, Batch 6800: Loss = 0.5948, Accuracy = 0.7188\n",
      "Epoch 4, Batch 6900: Loss = 0.5998, Accuracy = 0.6875\n",
      "Epoch 4, Batch 7000: Loss = 0.6264, Accuracy = 0.6250\n",
      "Epoch 4, Batch 7100: Loss = 0.4689, Accuracy = 0.8438\n",
      "Epoch 4, Batch 7200: Loss = 0.6812, Accuracy = 0.6250\n",
      "Epoch 4, Batch 7300: Loss = 0.5713, Accuracy = 0.7188\n",
      "Epoch 4, Batch 7400: Loss = 0.8581, Accuracy = 0.4688\n",
      "Epoch 4, Batch 7500: Loss = 0.6399, Accuracy = 0.6562\n",
      "Epoch 4, Batch 7600: Loss = 0.5725, Accuracy = 0.6875\n",
      "Epoch 4, Batch 7700: Loss = 0.5843, Accuracy = 0.6562\n",
      "Epoch 4, Batch 7800: Loss = 0.5247, Accuracy = 0.7812\n",
      "Epoch 4, Batch 7900: Loss = 0.7154, Accuracy = 0.5312\n",
      "Epoch 4, Batch 8000: Loss = 0.6223, Accuracy = 0.8125\n",
      "Epoch 4, Batch 8100: Loss = 0.6262, Accuracy = 0.6562\n",
      "Epoch 4, Batch 8200: Loss = 0.4845, Accuracy = 0.7812\n",
      "Epoch 4, Batch 8300: Loss = 0.6410, Accuracy = 0.6562\n",
      "Epoch 4, Batch 8400: Loss = 0.7768, Accuracy = 0.5938\n",
      "Epoch 4, Batch 8500: Loss = 0.6481, Accuracy = 0.6875\n",
      "Epoch 4, Batch 8600: Loss = 0.5969, Accuracy = 0.7188\n",
      "Epoch 4, Batch 8700: Loss = 0.5433, Accuracy = 0.6875\n",
      "Epoch 4, Batch 8800: Loss = 0.6300, Accuracy = 0.6250\n",
      "Epoch 4, Batch 8900: Loss = 0.6719, Accuracy = 0.6562\n",
      "Epoch 4, Batch 9000: Loss = 0.6829, Accuracy = 0.6250\n",
      "Epoch 4, Batch 9100: Loss = 0.5928, Accuracy = 0.6562\n",
      "Epoch 4, Batch 9200: Loss = 0.6137, Accuracy = 0.7500\n",
      "Epoch 4, Batch 9300: Loss = 0.5717, Accuracy = 0.7812\n",
      "Epoch 4, Batch 9400: Loss = 0.5071, Accuracy = 0.7500\n",
      "Epoch 4, Batch 9500: Loss = 0.6530, Accuracy = 0.7188\n",
      "Epoch 4, Batch 9600: Loss = 0.6601, Accuracy = 0.6250\n",
      "Epoch 4, Batch 9700: Loss = 0.5634, Accuracy = 0.7188\n",
      "Epoch 4, Batch 9800: Loss = 0.6813, Accuracy = 0.5938\n",
      "Epoch 4, Batch 9900: Loss = 0.6186, Accuracy = 0.6875\n",
      "Epoch 4, Batch 10000: Loss = 0.5746, Accuracy = 0.7812\n",
      "Epoch 4, Batch 10100: Loss = 0.6012, Accuracy = 0.7500\n",
      "Epoch 4, Batch 10200: Loss = 0.4403, Accuracy = 0.8438\n",
      "Epoch 4, Batch 10300: Loss = 0.6097, Accuracy = 0.7188\n",
      "Epoch 4, Batch 10400: Loss = 0.6884, Accuracy = 0.5938\n",
      "Epoch 4, Batch 10500: Loss = 0.5592, Accuracy = 0.7500\n",
      "Epoch 4, Batch 10600: Loss = 0.4756, Accuracy = 0.9062\n",
      "Epoch 4, Batch 10700: Loss = 0.5574, Accuracy = 0.7500\n",
      "Epoch 4, Batch 10800: Loss = 0.4787, Accuracy = 0.8125\n",
      "Epoch 4, Batch 10900: Loss = 0.6221, Accuracy = 0.6562\n",
      "Epoch 4, Batch 11000: Loss = 0.6705, Accuracy = 0.5938\n",
      "Epoch 4, Batch 11100: Loss = 0.4581, Accuracy = 0.8750\n",
      "Epoch 4, Batch 11200: Loss = 0.5728, Accuracy = 0.7500\n",
      "Epoch 4, Batch 11300: Loss = 0.5904, Accuracy = 0.7188\n",
      "Epoch 4, Batch 11400: Loss = 0.5747, Accuracy = 0.7188\n",
      "Epoch 4, Batch 11500: Loss = 0.5769, Accuracy = 0.7500\n",
      "Epoch 4, Batch 11600: Loss = 0.5482, Accuracy = 0.7500\n",
      "Epoch 4, Batch 11700: Loss = 0.5228, Accuracy = 0.7500\n",
      "Epoch 4, Batch 11800: Loss = 0.5594, Accuracy = 0.6875\n",
      "Epoch 4, Batch 11900: Loss = 0.6987, Accuracy = 0.6250\n",
      "Epoch 4, Batch 12000: Loss = 0.5264, Accuracy = 0.7812\n",
      "Epoch 4, Batch 12100: Loss = 0.7630, Accuracy = 0.5312\n",
      "Epoch 4, Batch 12200: Loss = 0.6123, Accuracy = 0.7500\n",
      "Epoch 4, Batch 12300: Loss = 0.7244, Accuracy = 0.5312\n",
      "Epoch 4, Batch 12400: Loss = 0.5907, Accuracy = 0.7188\n",
      "Epoch 4, Batch 12500: Loss = 0.5963, Accuracy = 0.6875\n",
      "Epoch 4, Batch 12600: Loss = 0.5504, Accuracy = 0.7500\n",
      "Epoch 4, Batch 12700: Loss = 0.5739, Accuracy = 0.6562\n",
      "Epoch 4, Batch 12800: Loss = 0.6242, Accuracy = 0.7500\n",
      "Epoch 4, Batch 12900: Loss = 0.5272, Accuracy = 0.7500\n",
      "Epoch 4, Batch 13000: Loss = 0.6137, Accuracy = 0.7188\n",
      "Epoch 4, Batch 13100: Loss = 0.4844, Accuracy = 0.8125\n",
      "Epoch 4, Batch 13200: Loss = 0.5441, Accuracy = 0.8125\n",
      "Epoch 4, Batch 13300: Loss = 0.5654, Accuracy = 0.7188\n",
      "Epoch 4, Batch 13400: Loss = 0.4910, Accuracy = 0.8438\n",
      "Epoch 4, Batch 13500: Loss = 0.5432, Accuracy = 0.6562\n",
      "Epoch 4, Batch 13600: Loss = 0.5908, Accuracy = 0.6875\n",
      "Epoch 4, Batch 13700: Loss = 0.4815, Accuracy = 0.7812\n",
      "Epoch 4, Batch 13800: Loss = 0.5309, Accuracy = 0.7500\n",
      "Epoch 4, Batch 13900: Loss = 0.6284, Accuracy = 0.7188\n",
      "Epoch 4, Batch 14000: Loss = 0.6364, Accuracy = 0.6875\n",
      "Epoch 4, Batch 14100: Loss = 0.5404, Accuracy = 0.7812\n",
      "Epoch 4, Batch 14200: Loss = 0.6101, Accuracy = 0.7188\n",
      "Epoch 4, Batch 14300: Loss = 0.5761, Accuracy = 0.7812\n",
      "Epoch 4, Batch 14400: Loss = 0.5799, Accuracy = 0.6562\n",
      "Epoch 4, Batch 14500: Loss = 0.5290, Accuracy = 0.7812\n",
      "Epoch 4, Batch 14600: Loss = 0.5835, Accuracy = 0.7500\n",
      "Epoch 4, Batch 14700: Loss = 0.4968, Accuracy = 0.8125\n",
      "Epoch 4, Batch 14800: Loss = 0.5290, Accuracy = 0.7188\n",
      "Epoch 4, Batch 14900: Loss = 0.5326, Accuracy = 0.7812\n",
      "Epoch 4, Batch 15000: Loss = 0.5525, Accuracy = 0.7188\n",
      "Epoch 4, Batch 15100: Loss = 0.5201, Accuracy = 0.7812\n",
      "Epoch 4, Batch 15200: Loss = 0.5649, Accuracy = 0.7500\n",
      "Epoch 4, Batch 15300: Loss = 0.6781, Accuracy = 0.5312\n",
      "Epoch 4, Batch 15400: Loss = 0.7224, Accuracy = 0.5625\n",
      "Epoch 4, Batch 15500: Loss = 0.5361, Accuracy = 0.6875\n",
      "Epoch 4, Batch 15600: Loss = 0.6795, Accuracy = 0.5938\n",
      "Epoch 4, Batch 15700: Loss = 0.6884, Accuracy = 0.5938\n",
      "Epoch 4, Batch 15800: Loss = 0.7062, Accuracy = 0.5312\n",
      "Epoch 4, Batch 15900: Loss = 0.6670, Accuracy = 0.6250\n",
      "Epoch 4, Batch 16000: Loss = 0.4491, Accuracy = 0.8750\n",
      "Epoch 4, Batch 16100: Loss = 0.5725, Accuracy = 0.7188\n",
      "Epoch 4, Batch 16200: Loss = 0.6156, Accuracy = 0.6250\n",
      "Epoch 4, Batch 16300: Loss = 0.6777, Accuracy = 0.6875\n",
      "Epoch 4, Batch 16400: Loss = 0.5753, Accuracy = 0.6562\n",
      "Epoch 4, Batch 16500: Loss = 0.6370, Accuracy = 0.6875\n",
      "Epoch 4, Batch 16600: Loss = 0.5469, Accuracy = 0.7812\n",
      "Epoch 4, Batch 16700: Loss = 0.6326, Accuracy = 0.7188\n",
      "Epoch 4, Batch 16800: Loss = 0.6214, Accuracy = 0.6875\n",
      "Epoch 4, Batch 16900: Loss = 0.6333, Accuracy = 0.6875\n",
      "Epoch 4, Batch 17000: Loss = 0.4609, Accuracy = 0.8438\n",
      "Epoch 4, Batch 17100: Loss = 0.5371, Accuracy = 0.8438\n",
      "Epoch 4, Batch 17200: Loss = 0.5596, Accuracy = 0.7188\n",
      "Epoch 4, Batch 17300: Loss = 0.8089, Accuracy = 0.5938\n",
      "Epoch 4, Batch 17400: Loss = 0.5554, Accuracy = 0.6875\n",
      "Epoch 4, Batch 17500: Loss = 0.6457, Accuracy = 0.6875\n",
      "Epoch 4, Batch 17600: Loss = 0.5939, Accuracy = 0.7188\n",
      "Epoch 4, Batch 17700: Loss = 0.5805, Accuracy = 0.6562\n",
      "Epoch 4, Batch 17800: Loss = 0.6154, Accuracy = 0.7500\n",
      "Epoch 4, Batch 17900: Loss = 0.7490, Accuracy = 0.5312\n",
      "Epoch 4, Batch 18000: Loss = 0.6336, Accuracy = 0.5938\n",
      "Epoch 4, Batch 18100: Loss = 0.5605, Accuracy = 0.7188\n",
      "Epoch 4, Batch 18200: Loss = 0.7353, Accuracy = 0.6562\n",
      "Epoch 4, Batch 18300: Loss = 0.5425, Accuracy = 0.7812\n",
      "Epoch 4, Batch 18400: Loss = 0.5639, Accuracy = 0.7188\n",
      "Epoch 4, Batch 18500: Loss = 0.6308, Accuracy = 0.5938\n",
      "Epoch 4, Batch 18600: Loss = 0.5275, Accuracy = 0.7500\n",
      "Epoch 4, Batch 18700: Loss = 0.6406, Accuracy = 0.5625\n",
      "Epoch 4, Batch 18800: Loss = 0.6425, Accuracy = 0.6562\n",
      "Epoch 4, Batch 18900: Loss = 0.6882, Accuracy = 0.5000\n",
      "Epoch 4, Batch 19000: Loss = 0.7167, Accuracy = 0.6875\n",
      "Epoch 4, Batch 19100: Loss = 0.6201, Accuracy = 0.5938\n",
      "Epoch 4, Batch 19200: Loss = 0.4577, Accuracy = 0.8438\n",
      "Epoch 4, Batch 19300: Loss = 0.5822, Accuracy = 0.7188\n",
      "Epoch 4, Batch 19400: Loss = 0.5489, Accuracy = 0.7188\n",
      "Epoch 4, Batch 19500: Loss = 0.6546, Accuracy = 0.6875\n",
      "Epoch 4, Batch 19600: Loss = 0.6060, Accuracy = 0.7500\n",
      "Epoch 4, Batch 19700: Loss = 0.6461, Accuracy = 0.6562\n",
      "Epoch 4, Batch 19800: Loss = 0.5641, Accuracy = 0.6875\n",
      "Epoch 4, Batch 19900: Loss = 0.5906, Accuracy = 0.6562\n",
      "Epoch 4, Batch 20000: Loss = 0.5058, Accuracy = 0.7500\n",
      "Epoch 4, Batch 20100: Loss = 0.5780, Accuracy = 0.7188\n",
      "Epoch 4, Batch 20200: Loss = 0.4775, Accuracy = 0.7500\n",
      "Epoch 4, Batch 20300: Loss = 0.4833, Accuracy = 0.8438\n",
      "Epoch 4, Batch 20400: Loss = 0.7018, Accuracy = 0.5312\n",
      "Epoch 4, Batch 20500: Loss = 0.6418, Accuracy = 0.6250\n",
      "Epoch 4, Batch 20600: Loss = 0.5881, Accuracy = 0.6875\n",
      "Epoch 4, Batch 20700: Loss = 0.6242, Accuracy = 0.7500\n",
      "Epoch 4, Batch 20800: Loss = 0.6864, Accuracy = 0.7188\n",
      "Epoch 4, Batch 20900: Loss = 0.7124, Accuracy = 0.6875\n",
      "Epoch 4, Batch 21000: Loss = 0.7254, Accuracy = 0.5938\n",
      "Epoch 4, Batch 21100: Loss = 0.5092, Accuracy = 0.7500\n",
      "Epoch 4, Batch 21200: Loss = 0.5056, Accuracy = 0.8438\n",
      "Epoch 4, Batch 21300: Loss = 0.6782, Accuracy = 0.5625\n",
      "Epoch 4, Batch 21400: Loss = 0.6170, Accuracy = 0.6875\n",
      "Epoch 4, Batch 21500: Loss = 0.5896, Accuracy = 0.7500\n",
      "Epoch 4, Batch 21600: Loss = 0.6038, Accuracy = 0.7812\n",
      "Epoch 4, Batch 21700: Loss = 0.5821, Accuracy = 0.7500\n",
      "Epoch 4, Batch 21800: Loss = 0.5719, Accuracy = 0.7188\n",
      "Epoch 4: Train Loss = 0.5974, Train Accuracy = 0.7002, Time = 508.12s\n",
      "Validation Accuracy: 0.7034\n",
      "Epoch 5, Batch 100: Loss = 0.5426, Accuracy = 0.7812\n",
      "Epoch 5, Batch 200: Loss = 0.6467, Accuracy = 0.7188\n",
      "Epoch 5, Batch 300: Loss = 0.5868, Accuracy = 0.7188\n",
      "Epoch 5, Batch 400: Loss = 0.6946, Accuracy = 0.6562\n",
      "Epoch 5, Batch 500: Loss = 0.5642, Accuracy = 0.7812\n",
      "Epoch 5, Batch 600: Loss = 0.5871, Accuracy = 0.7500\n",
      "Epoch 5, Batch 700: Loss = 0.4262, Accuracy = 0.8438\n",
      "Epoch 5, Batch 800: Loss = 0.5247, Accuracy = 0.8438\n",
      "Epoch 5, Batch 900: Loss = 0.6067, Accuracy = 0.6562\n",
      "Epoch 5, Batch 1000: Loss = 0.5829, Accuracy = 0.6875\n",
      "Epoch 5, Batch 1100: Loss = 0.5758, Accuracy = 0.6875\n",
      "Epoch 5, Batch 1200: Loss = 0.5752, Accuracy = 0.7188\n",
      "Epoch 5, Batch 1300: Loss = 0.6623, Accuracy = 0.6250\n",
      "Epoch 5, Batch 1400: Loss = 0.7282, Accuracy = 0.6875\n",
      "Epoch 5, Batch 1500: Loss = 0.7183, Accuracy = 0.6562\n",
      "Epoch 5, Batch 1600: Loss = 0.4848, Accuracy = 0.8438\n",
      "Epoch 5, Batch 1700: Loss = 0.6534, Accuracy = 0.6562\n",
      "Epoch 5, Batch 1800: Loss = 0.6908, Accuracy = 0.5312\n",
      "Epoch 5, Batch 1900: Loss = 0.6424, Accuracy = 0.6875\n",
      "Epoch 5, Batch 2000: Loss = 0.6071, Accuracy = 0.7188\n",
      "Epoch 5, Batch 2100: Loss = 0.5495, Accuracy = 0.7188\n",
      "Epoch 5, Batch 2200: Loss = 0.4609, Accuracy = 0.8125\n",
      "Epoch 5, Batch 2300: Loss = 0.6381, Accuracy = 0.5625\n",
      "Epoch 5, Batch 2400: Loss = 0.5792, Accuracy = 0.6562\n",
      "Epoch 5, Batch 2500: Loss = 0.5347, Accuracy = 0.7500\n",
      "Epoch 5, Batch 2600: Loss = 0.5210, Accuracy = 0.7812\n",
      "Epoch 5, Batch 2700: Loss = 0.6899, Accuracy = 0.6562\n",
      "Epoch 5, Batch 2800: Loss = 0.5320, Accuracy = 0.7500\n",
      "Epoch 5, Batch 2900: Loss = 0.5606, Accuracy = 0.6875\n",
      "Epoch 5, Batch 3000: Loss = 0.7928, Accuracy = 0.6562\n",
      "Epoch 5, Batch 3100: Loss = 0.6096, Accuracy = 0.7500\n",
      "Epoch 5, Batch 3200: Loss = 0.5265, Accuracy = 0.7188\n",
      "Epoch 5, Batch 3300: Loss = 0.6302, Accuracy = 0.6562\n",
      "Epoch 5, Batch 3400: Loss = 0.6136, Accuracy = 0.6562\n",
      "Epoch 5, Batch 3500: Loss = 0.5870, Accuracy = 0.7188\n",
      "Epoch 5, Batch 3600: Loss = 0.6923, Accuracy = 0.6562\n",
      "Epoch 5, Batch 3700: Loss = 0.5464, Accuracy = 0.7812\n",
      "Epoch 5, Batch 3800: Loss = 0.6514, Accuracy = 0.6250\n",
      "Epoch 5, Batch 3900: Loss = 0.5731, Accuracy = 0.7188\n",
      "Epoch 5, Batch 4000: Loss = 0.5228, Accuracy = 0.7812\n",
      "Epoch 5, Batch 4100: Loss = 0.7402, Accuracy = 0.5938\n",
      "Epoch 5, Batch 4200: Loss = 0.5225, Accuracy = 0.8125\n",
      "Epoch 5, Batch 4300: Loss = 0.5329, Accuracy = 0.6875\n",
      "Epoch 5, Batch 4400: Loss = 0.5496, Accuracy = 0.8125\n",
      "Epoch 5, Batch 4500: Loss = 0.5718, Accuracy = 0.8438\n",
      "Epoch 5, Batch 4600: Loss = 0.6238, Accuracy = 0.7812\n",
      "Epoch 5, Batch 4700: Loss = 0.6735, Accuracy = 0.5938\n",
      "Epoch 5, Batch 4800: Loss = 0.5553, Accuracy = 0.7188\n",
      "Epoch 5, Batch 4900: Loss = 0.4381, Accuracy = 0.8438\n",
      "Epoch 5, Batch 5000: Loss = 0.5519, Accuracy = 0.6562\n",
      "Epoch 5, Batch 5100: Loss = 0.4501, Accuracy = 0.8750\n",
      "Epoch 5, Batch 5200: Loss = 0.4952, Accuracy = 0.8125\n",
      "Epoch 5, Batch 5300: Loss = 0.7520, Accuracy = 0.5938\n",
      "Epoch 5, Batch 5400: Loss = 0.4958, Accuracy = 0.7500\n",
      "Epoch 5, Batch 5500: Loss = 0.5859, Accuracy = 0.7188\n",
      "Epoch 5, Batch 5600: Loss = 0.6585, Accuracy = 0.6562\n",
      "Epoch 5, Batch 5700: Loss = 0.5118, Accuracy = 0.7500\n",
      "Epoch 5, Batch 5800: Loss = 0.6785, Accuracy = 0.7188\n",
      "Epoch 5, Batch 5900: Loss = 0.5476, Accuracy = 0.7188\n",
      "Epoch 5, Batch 6000: Loss = 0.6897, Accuracy = 0.6250\n",
      "Epoch 5, Batch 6100: Loss = 0.6817, Accuracy = 0.6250\n",
      "Epoch 5, Batch 6200: Loss = 0.6116, Accuracy = 0.6250\n",
      "Epoch 5, Batch 6300: Loss = 0.5910, Accuracy = 0.7188\n",
      "Epoch 5, Batch 6400: Loss = 0.5410, Accuracy = 0.6875\n",
      "Epoch 5, Batch 6500: Loss = 0.5657, Accuracy = 0.7500\n",
      "Epoch 5, Batch 6600: Loss = 0.6304, Accuracy = 0.6250\n",
      "Epoch 5, Batch 6700: Loss = 0.5788, Accuracy = 0.7188\n",
      "Epoch 5, Batch 6800: Loss = 0.6916, Accuracy = 0.5938\n",
      "Epoch 5, Batch 6900: Loss = 0.4668, Accuracy = 0.8125\n",
      "Epoch 5, Batch 7000: Loss = 0.6274, Accuracy = 0.7500\n",
      "Epoch 5, Batch 7100: Loss = 0.5899, Accuracy = 0.6562\n",
      "Epoch 5, Batch 7200: Loss = 0.5388, Accuracy = 0.7812\n",
      "Epoch 5, Batch 7300: Loss = 0.6127, Accuracy = 0.7188\n",
      "Epoch 5, Batch 7400: Loss = 0.5856, Accuracy = 0.6875\n",
      "Epoch 5, Batch 7500: Loss = 0.5900, Accuracy = 0.7500\n",
      "Epoch 5, Batch 7600: Loss = 0.6519, Accuracy = 0.6875\n",
      "Epoch 5, Batch 7700: Loss = 0.5537, Accuracy = 0.8125\n",
      "Epoch 5, Batch 7800: Loss = 0.6745, Accuracy = 0.5625\n",
      "Epoch 5, Batch 7900: Loss = 0.7136, Accuracy = 0.5312\n",
      "Epoch 5, Batch 8000: Loss = 0.5774, Accuracy = 0.6875\n",
      "Epoch 5, Batch 8100: Loss = 0.6101, Accuracy = 0.6562\n",
      "Epoch 5, Batch 8200: Loss = 0.5928, Accuracy = 0.6875\n",
      "Epoch 5, Batch 8300: Loss = 0.6504, Accuracy = 0.6562\n",
      "Epoch 5, Batch 8400: Loss = 0.5854, Accuracy = 0.6875\n",
      "Epoch 5, Batch 8500: Loss = 0.6189, Accuracy = 0.6875\n",
      "Epoch 5, Batch 8600: Loss = 0.6954, Accuracy = 0.6875\n",
      "Epoch 5, Batch 8700: Loss = 0.6136, Accuracy = 0.6562\n",
      "Epoch 5, Batch 8800: Loss = 0.6088, Accuracy = 0.6875\n",
      "Epoch 5, Batch 8900: Loss = 0.6337, Accuracy = 0.6562\n",
      "Epoch 5, Batch 9000: Loss = 0.5704, Accuracy = 0.6562\n",
      "Epoch 5, Batch 9100: Loss = 0.6150, Accuracy = 0.6250\n",
      "Epoch 5, Batch 9200: Loss = 0.4823, Accuracy = 0.8438\n",
      "Epoch 5, Batch 9300: Loss = 0.4580, Accuracy = 0.8125\n",
      "Epoch 5, Batch 9400: Loss = 0.5092, Accuracy = 0.6875\n",
      "Epoch 5, Batch 9500: Loss = 0.5372, Accuracy = 0.7188\n",
      "Epoch 5, Batch 9600: Loss = 0.6080, Accuracy = 0.6562\n",
      "Epoch 5, Batch 9700: Loss = 0.4981, Accuracy = 0.7812\n",
      "Epoch 5, Batch 9800: Loss = 0.5915, Accuracy = 0.6562\n",
      "Epoch 5, Batch 9900: Loss = 0.5162, Accuracy = 0.7812\n",
      "Epoch 5, Batch 10000: Loss = 0.5461, Accuracy = 0.7188\n",
      "Epoch 5, Batch 10100: Loss = 0.6369, Accuracy = 0.7188\n",
      "Epoch 5, Batch 10200: Loss = 0.5260, Accuracy = 0.8125\n",
      "Epoch 5, Batch 10300: Loss = 0.7863, Accuracy = 0.6875\n",
      "Epoch 5, Batch 10400: Loss = 0.6665, Accuracy = 0.6250\n",
      "Epoch 5, Batch 10500: Loss = 0.5106, Accuracy = 0.6875\n",
      "Epoch 5, Batch 10600: Loss = 0.7112, Accuracy = 0.5625\n",
      "Epoch 5, Batch 10700: Loss = 0.5555, Accuracy = 0.7188\n",
      "Epoch 5, Batch 10800: Loss = 0.5589, Accuracy = 0.6875\n",
      "Epoch 5, Batch 10900: Loss = 0.7313, Accuracy = 0.6875\n",
      "Epoch 5, Batch 11000: Loss = 0.5260, Accuracy = 0.7812\n",
      "Epoch 5, Batch 11100: Loss = 0.4370, Accuracy = 0.7500\n",
      "Epoch 5, Batch 11200: Loss = 0.6767, Accuracy = 0.6562\n",
      "Epoch 5, Batch 11300: Loss = 0.8013, Accuracy = 0.5938\n",
      "Epoch 5, Batch 11400: Loss = 0.5539, Accuracy = 0.7188\n",
      "Epoch 5, Batch 11500: Loss = 0.6779, Accuracy = 0.6562\n",
      "Epoch 5, Batch 11600: Loss = 0.6349, Accuracy = 0.7188\n",
      "Epoch 5, Batch 11700: Loss = 0.6722, Accuracy = 0.6875\n",
      "Epoch 5, Batch 11800: Loss = 0.6599, Accuracy = 0.6875\n",
      "Epoch 5, Batch 11900: Loss = 0.4592, Accuracy = 0.8750\n",
      "Epoch 5, Batch 12000: Loss = 0.4653, Accuracy = 0.9062\n",
      "Epoch 5, Batch 12100: Loss = 0.6551, Accuracy = 0.6562\n",
      "Epoch 5, Batch 12200: Loss = 0.6882, Accuracy = 0.5938\n",
      "Epoch 5, Batch 12300: Loss = 0.6023, Accuracy = 0.6875\n",
      "Epoch 5, Batch 12400: Loss = 0.5558, Accuracy = 0.7188\n",
      "Epoch 5, Batch 12500: Loss = 0.5522, Accuracy = 0.6875\n",
      "Epoch 5, Batch 12600: Loss = 0.5780, Accuracy = 0.7812\n",
      "Epoch 5, Batch 12700: Loss = 0.5443, Accuracy = 0.7500\n",
      "Epoch 5, Batch 12800: Loss = 0.6197, Accuracy = 0.7188\n",
      "Epoch 5, Batch 12900: Loss = 0.6895, Accuracy = 0.5625\n",
      "Epoch 5, Batch 13000: Loss = 0.7075, Accuracy = 0.6562\n",
      "Epoch 5, Batch 13100: Loss = 0.6874, Accuracy = 0.5938\n",
      "Epoch 5, Batch 13200: Loss = 0.5113, Accuracy = 0.7500\n",
      "Epoch 5, Batch 13300: Loss = 0.5025, Accuracy = 0.7812\n",
      "Epoch 5, Batch 13400: Loss = 0.6410, Accuracy = 0.6562\n",
      "Epoch 5, Batch 13500: Loss = 0.6368, Accuracy = 0.6250\n",
      "Epoch 5, Batch 13600: Loss = 0.4700, Accuracy = 0.7812\n",
      "Epoch 5, Batch 13700: Loss = 0.7140, Accuracy = 0.5000\n",
      "Epoch 5, Batch 13800: Loss = 0.6758, Accuracy = 0.5938\n",
      "Epoch 5, Batch 13900: Loss = 0.6202, Accuracy = 0.6875\n",
      "Epoch 5, Batch 14000: Loss = 0.5529, Accuracy = 0.6562\n",
      "Epoch 5, Batch 14100: Loss = 0.5853, Accuracy = 0.7500\n",
      "Epoch 5, Batch 14200: Loss = 0.6333, Accuracy = 0.6250\n",
      "Epoch 5, Batch 14300: Loss = 0.5497, Accuracy = 0.7500\n",
      "Epoch 5, Batch 14400: Loss = 0.6206, Accuracy = 0.6250\n",
      "Epoch 5, Batch 14500: Loss = 0.5457, Accuracy = 0.6875\n",
      "Epoch 5, Batch 14600: Loss = 0.6155, Accuracy = 0.6250\n",
      "Epoch 5, Batch 14700: Loss = 0.5505, Accuracy = 0.7812\n",
      "Epoch 5, Batch 14800: Loss = 0.5878, Accuracy = 0.6562\n",
      "Epoch 5, Batch 14900: Loss = 0.5953, Accuracy = 0.7812\n",
      "Epoch 5, Batch 15000: Loss = 0.5016, Accuracy = 0.7812\n",
      "Epoch 5, Batch 15100: Loss = 0.5678, Accuracy = 0.7188\n",
      "Epoch 5, Batch 15200: Loss = 0.6445, Accuracy = 0.7188\n",
      "Epoch 5, Batch 15300: Loss = 0.5523, Accuracy = 0.7188\n",
      "Epoch 5, Batch 15400: Loss = 0.5521, Accuracy = 0.6562\n",
      "Epoch 5, Batch 15500: Loss = 0.5780, Accuracy = 0.6875\n",
      "Epoch 5, Batch 15600: Loss = 0.6538, Accuracy = 0.6875\n",
      "Epoch 5, Batch 15700: Loss = 0.6290, Accuracy = 0.6875\n",
      "Epoch 5, Batch 15800: Loss = 0.6891, Accuracy = 0.5000\n",
      "Epoch 5, Batch 15900: Loss = 0.7281, Accuracy = 0.5938\n",
      "Epoch 5, Batch 16000: Loss = 0.6024, Accuracy = 0.6875\n",
      "Epoch 5, Batch 16100: Loss = 0.6500, Accuracy = 0.6250\n",
      "Epoch 5, Batch 16200: Loss = 0.5812, Accuracy = 0.7500\n",
      "Epoch 5, Batch 16300: Loss = 0.5012, Accuracy = 0.8125\n",
      "Epoch 5, Batch 16400: Loss = 0.5502, Accuracy = 0.6875\n",
      "Epoch 5, Batch 16500: Loss = 0.6125, Accuracy = 0.6562\n",
      "Epoch 5, Batch 16600: Loss = 0.5944, Accuracy = 0.7500\n",
      "Epoch 5, Batch 16700: Loss = 0.6914, Accuracy = 0.6250\n",
      "Epoch 5, Batch 16800: Loss = 0.5496, Accuracy = 0.7812\n",
      "Epoch 5, Batch 16900: Loss = 0.5967, Accuracy = 0.7500\n",
      "Epoch 5, Batch 17000: Loss = 0.7481, Accuracy = 0.6875\n",
      "Epoch 5, Batch 17100: Loss = 0.8203, Accuracy = 0.4688\n",
      "Epoch 5, Batch 17200: Loss = 0.5224, Accuracy = 0.8438\n",
      "Epoch 5, Batch 17300: Loss = 0.6219, Accuracy = 0.6250\n",
      "Epoch 5, Batch 17400: Loss = 0.6292, Accuracy = 0.6250\n",
      "Epoch 5, Batch 17500: Loss = 0.8216, Accuracy = 0.5000\n",
      "Epoch 5, Batch 17600: Loss = 0.6931, Accuracy = 0.5625\n",
      "Epoch 5, Batch 17700: Loss = 0.7363, Accuracy = 0.6250\n",
      "Epoch 5, Batch 17800: Loss = 0.6297, Accuracy = 0.6875\n",
      "Epoch 5, Batch 17900: Loss = 0.5825, Accuracy = 0.7500\n",
      "Epoch 5, Batch 18000: Loss = 0.6257, Accuracy = 0.5938\n",
      "Epoch 5, Batch 18100: Loss = 0.6566, Accuracy = 0.5625\n",
      "Epoch 5, Batch 18200: Loss = 0.7335, Accuracy = 0.5625\n",
      "Epoch 5, Batch 18300: Loss = 0.6001, Accuracy = 0.5938\n",
      "Epoch 5, Batch 18400: Loss = 0.5420, Accuracy = 0.7188\n",
      "Epoch 5, Batch 18500: Loss = 0.6607, Accuracy = 0.6875\n",
      "Epoch 5, Batch 18600: Loss = 0.6266, Accuracy = 0.6562\n",
      "Epoch 5, Batch 18700: Loss = 0.5253, Accuracy = 0.8125\n",
      "Epoch 5, Batch 18800: Loss = 0.5977, Accuracy = 0.5938\n",
      "Epoch 5, Batch 18900: Loss = 0.6140, Accuracy = 0.6875\n",
      "Epoch 5, Batch 19000: Loss = 0.5574, Accuracy = 0.7188\n",
      "Epoch 5, Batch 19100: Loss = 0.6853, Accuracy = 0.5938\n",
      "Epoch 5, Batch 19200: Loss = 0.6857, Accuracy = 0.6250\n",
      "Epoch 5, Batch 19300: Loss = 0.6627, Accuracy = 0.7188\n",
      "Epoch 5, Batch 19400: Loss = 0.6398, Accuracy = 0.6562\n",
      "Epoch 5, Batch 19500: Loss = 0.4816, Accuracy = 0.8125\n",
      "Epoch 5, Batch 19600: Loss = 0.5864, Accuracy = 0.6875\n",
      "Epoch 5, Batch 19700: Loss = 0.6934, Accuracy = 0.6562\n",
      "Epoch 5, Batch 19800: Loss = 0.5654, Accuracy = 0.7188\n",
      "Epoch 5, Batch 19900: Loss = 0.6161, Accuracy = 0.6562\n",
      "Epoch 5, Batch 20000: Loss = 0.5722, Accuracy = 0.6875\n",
      "Epoch 5, Batch 20100: Loss = 0.5008, Accuracy = 0.7500\n",
      "Epoch 5, Batch 20200: Loss = 0.5711, Accuracy = 0.8438\n",
      "Epoch 5, Batch 20300: Loss = 0.6125, Accuracy = 0.7812\n",
      "Epoch 5, Batch 20400: Loss = 0.5745, Accuracy = 0.8125\n",
      "Epoch 5, Batch 20500: Loss = 0.5345, Accuracy = 0.8125\n",
      "Epoch 5, Batch 20600: Loss = 0.5644, Accuracy = 0.6875\n",
      "Epoch 5, Batch 20700: Loss = 0.6220, Accuracy = 0.6875\n",
      "Epoch 5, Batch 20800: Loss = 0.5251, Accuracy = 0.7188\n",
      "Epoch 5, Batch 20900: Loss = 0.4902, Accuracy = 0.7812\n",
      "Epoch 5, Batch 21000: Loss = 0.5217, Accuracy = 0.7188\n",
      "Epoch 5, Batch 21100: Loss = 0.6924, Accuracy = 0.5938\n",
      "Epoch 5, Batch 21200: Loss = 0.6065, Accuracy = 0.6562\n",
      "Epoch 5, Batch 21300: Loss = 0.6931, Accuracy = 0.5312\n",
      "Epoch 5, Batch 21400: Loss = 0.5805, Accuracy = 0.7500\n",
      "Epoch 5, Batch 21500: Loss = 0.5668, Accuracy = 0.6562\n",
      "Epoch 5, Batch 21600: Loss = 0.6776, Accuracy = 0.5312\n",
      "Epoch 5, Batch 21700: Loss = 0.5543, Accuracy = 0.7188\n",
      "Epoch 5, Batch 21800: Loss = 0.6987, Accuracy = 0.5938\n",
      "Epoch 5: Train Loss = 0.5974, Train Accuracy = 0.6995, Time = 539.11s\n",
      "Validation Accuracy: 0.7052\n",
      "Epoch 6, Batch 100: Loss = 0.5521, Accuracy = 0.7500\n",
      "Epoch 6, Batch 200: Loss = 0.5751, Accuracy = 0.7188\n",
      "Epoch 6, Batch 300: Loss = 0.5115, Accuracy = 0.8750\n",
      "Epoch 6, Batch 400: Loss = 0.6361, Accuracy = 0.6875\n",
      "Epoch 6, Batch 500: Loss = 0.5848, Accuracy = 0.6875\n",
      "Epoch 6, Batch 600: Loss = 0.5644, Accuracy = 0.6875\n",
      "Epoch 6, Batch 700: Loss = 0.5935, Accuracy = 0.6562\n",
      "Epoch 6, Batch 800: Loss = 0.5401, Accuracy = 0.7500\n",
      "Epoch 6, Batch 900: Loss = 0.6451, Accuracy = 0.6562\n",
      "Epoch 6, Batch 1000: Loss = 0.5794, Accuracy = 0.6875\n",
      "Epoch 6, Batch 1100: Loss = 0.4598, Accuracy = 0.8438\n",
      "Epoch 6, Batch 1200: Loss = 0.5834, Accuracy = 0.7188\n",
      "Epoch 6, Batch 1300: Loss = 0.3845, Accuracy = 0.9062\n",
      "Epoch 6, Batch 1400: Loss = 0.5294, Accuracy = 0.8438\n",
      "Epoch 6, Batch 1500: Loss = 0.7397, Accuracy = 0.5938\n",
      "Epoch 6, Batch 1600: Loss = 0.5425, Accuracy = 0.7188\n",
      "Epoch 6, Batch 1700: Loss = 0.5534, Accuracy = 0.6250\n",
      "Epoch 6, Batch 1800: Loss = 0.4916, Accuracy = 0.8438\n",
      "Epoch 6, Batch 1900: Loss = 0.5367, Accuracy = 0.7812\n",
      "Epoch 6, Batch 2000: Loss = 0.6287, Accuracy = 0.6562\n",
      "Epoch 6, Batch 2100: Loss = 0.6231, Accuracy = 0.7500\n",
      "Epoch 6, Batch 2200: Loss = 0.6637, Accuracy = 0.7188\n",
      "Epoch 6, Batch 2300: Loss = 0.6091, Accuracy = 0.6875\n",
      "Epoch 6, Batch 2400: Loss = 0.6398, Accuracy = 0.5938\n",
      "Epoch 6, Batch 2500: Loss = 0.5610, Accuracy = 0.7500\n",
      "Epoch 6, Batch 2600: Loss = 0.6522, Accuracy = 0.7500\n",
      "Epoch 6, Batch 2700: Loss = 0.5818, Accuracy = 0.6875\n",
      "Epoch 6, Batch 2800: Loss = 0.5929, Accuracy = 0.6875\n",
      "Epoch 6, Batch 2900: Loss = 0.7182, Accuracy = 0.4688\n",
      "Epoch 6, Batch 3000: Loss = 0.4843, Accuracy = 0.8438\n",
      "Epoch 6, Batch 3100: Loss = 0.6761, Accuracy = 0.6250\n",
      "Epoch 6, Batch 3200: Loss = 0.6984, Accuracy = 0.5938\n",
      "Epoch 6, Batch 3300: Loss = 0.5490, Accuracy = 0.6875\n",
      "Epoch 6, Batch 3400: Loss = 0.5423, Accuracy = 0.6875\n",
      "Epoch 6, Batch 3500: Loss = 0.7079, Accuracy = 0.6562\n",
      "Epoch 6, Batch 3600: Loss = 0.5221, Accuracy = 0.7500\n",
      "Epoch 6, Batch 3700: Loss = 0.5598, Accuracy = 0.7188\n",
      "Epoch 6, Batch 3800: Loss = 0.5981, Accuracy = 0.7188\n",
      "Epoch 6, Batch 3900: Loss = 0.6288, Accuracy = 0.6250\n",
      "Epoch 6, Batch 4000: Loss = 0.5520, Accuracy = 0.6562\n",
      "Epoch 6, Batch 4100: Loss = 0.6220, Accuracy = 0.5938\n",
      "Epoch 6, Batch 4200: Loss = 0.5699, Accuracy = 0.6250\n",
      "Epoch 6, Batch 4300: Loss = 0.5815, Accuracy = 0.6875\n",
      "Epoch 6, Batch 4400: Loss = 0.6479, Accuracy = 0.6875\n",
      "Epoch 6, Batch 4500: Loss = 0.5391, Accuracy = 0.7812\n",
      "Epoch 6, Batch 4600: Loss = 0.6155, Accuracy = 0.6562\n",
      "Epoch 6, Batch 4700: Loss = 0.6338, Accuracy = 0.6875\n",
      "Epoch 6, Batch 4800: Loss = 0.5308, Accuracy = 0.8125\n",
      "Epoch 6, Batch 4900: Loss = 0.5899, Accuracy = 0.7812\n",
      "Epoch 6, Batch 5000: Loss = 0.5902, Accuracy = 0.7500\n",
      "Epoch 6, Batch 5100: Loss = 0.5724, Accuracy = 0.8125\n",
      "Epoch 6, Batch 5200: Loss = 0.6785, Accuracy = 0.5938\n",
      "Epoch 6, Batch 5300: Loss = 0.5430, Accuracy = 0.7500\n",
      "Epoch 6, Batch 5400: Loss = 0.6003, Accuracy = 0.6875\n",
      "Epoch 6, Batch 5500: Loss = 0.6118, Accuracy = 0.7188\n",
      "Epoch 6, Batch 5600: Loss = 0.6903, Accuracy = 0.6250\n",
      "Epoch 6, Batch 5700: Loss = 0.6868, Accuracy = 0.5625\n",
      "Epoch 6, Batch 5800: Loss = 0.6258, Accuracy = 0.6875\n",
      "Epoch 6, Batch 5900: Loss = 0.5392, Accuracy = 0.6250\n",
      "Epoch 6, Batch 6000: Loss = 0.4690, Accuracy = 0.7812\n",
      "Epoch 6, Batch 6100: Loss = 0.5311, Accuracy = 0.7812\n",
      "Epoch 6, Batch 6200: Loss = 0.5942, Accuracy = 0.7500\n",
      "Epoch 6, Batch 6300: Loss = 0.5437, Accuracy = 0.7188\n",
      "Epoch 6, Batch 6400: Loss = 0.6347, Accuracy = 0.7188\n",
      "Epoch 6, Batch 6500: Loss = 0.6045, Accuracy = 0.6250\n",
      "Epoch 6, Batch 6600: Loss = 0.5582, Accuracy = 0.6875\n",
      "Epoch 6, Batch 6700: Loss = 0.5332, Accuracy = 0.6875\n",
      "Epoch 6, Batch 6800: Loss = 0.4469, Accuracy = 0.9375\n",
      "Epoch 6, Batch 6900: Loss = 0.5356, Accuracy = 0.7188\n",
      "Epoch 6, Batch 7000: Loss = 0.6781, Accuracy = 0.6250\n",
      "Epoch 6, Batch 7100: Loss = 0.6671, Accuracy = 0.5938\n",
      "Epoch 6, Batch 7200: Loss = 0.7351, Accuracy = 0.5000\n",
      "Epoch 6, Batch 7300: Loss = 0.6798, Accuracy = 0.5312\n",
      "Epoch 6, Batch 7400: Loss = 0.6285, Accuracy = 0.6250\n",
      "Epoch 6, Batch 7500: Loss = 0.6327, Accuracy = 0.6875\n",
      "Epoch 6, Batch 7600: Loss = 0.6653, Accuracy = 0.6875\n",
      "Epoch 6, Batch 7700: Loss = 0.6385, Accuracy = 0.6562\n",
      "Epoch 6, Batch 7800: Loss = 0.5062, Accuracy = 0.7500\n",
      "Epoch 6, Batch 7900: Loss = 0.5677, Accuracy = 0.7188\n",
      "Epoch 6, Batch 8000: Loss = 0.6928, Accuracy = 0.7188\n",
      "Epoch 6, Batch 8100: Loss = 0.5219, Accuracy = 0.8125\n",
      "Epoch 6, Batch 8200: Loss = 0.5755, Accuracy = 0.7188\n",
      "Epoch 6, Batch 8300: Loss = 0.5051, Accuracy = 0.7188\n",
      "Epoch 6, Batch 8400: Loss = 0.5007, Accuracy = 0.8125\n",
      "Epoch 6, Batch 8500: Loss = 0.6867, Accuracy = 0.6250\n",
      "Epoch 6, Batch 8600: Loss = 0.6121, Accuracy = 0.6562\n",
      "Epoch 6, Batch 8700: Loss = 0.6439, Accuracy = 0.7188\n",
      "Epoch 6, Batch 8800: Loss = 0.6073, Accuracy = 0.7500\n",
      "Epoch 6, Batch 8900: Loss = 0.6767, Accuracy = 0.6562\n",
      "Epoch 6, Batch 9000: Loss = 0.6046, Accuracy = 0.5938\n",
      "Epoch 6, Batch 9100: Loss = 0.5349, Accuracy = 0.7500\n",
      "Epoch 6, Batch 9200: Loss = 0.4747, Accuracy = 0.7500\n",
      "Epoch 6, Batch 9300: Loss = 0.5237, Accuracy = 0.7812\n",
      "Epoch 6, Batch 9400: Loss = 0.5269, Accuracy = 0.7812\n",
      "Epoch 6, Batch 9500: Loss = 0.6669, Accuracy = 0.6250\n",
      "Epoch 6, Batch 9600: Loss = 0.5812, Accuracy = 0.6875\n",
      "Epoch 6, Batch 9700: Loss = 0.6307, Accuracy = 0.5625\n",
      "Epoch 6, Batch 9800: Loss = 0.5396, Accuracy = 0.7188\n",
      "Epoch 6, Batch 9900: Loss = 0.4728, Accuracy = 0.8750\n",
      "Epoch 6, Batch 10000: Loss = 0.6324, Accuracy = 0.6875\n",
      "Epoch 6, Batch 10100: Loss = 0.6009, Accuracy = 0.7188\n",
      "Epoch 6, Batch 10200: Loss = 0.6203, Accuracy = 0.6250\n",
      "Epoch 6, Batch 10300: Loss = 0.6662, Accuracy = 0.6250\n",
      "Epoch 6, Batch 10400: Loss = 0.6104, Accuracy = 0.7188\n",
      "Epoch 6, Batch 10500: Loss = 0.6759, Accuracy = 0.5000\n",
      "Epoch 6, Batch 10600: Loss = 0.5242, Accuracy = 0.8438\n",
      "Epoch 6, Batch 10700: Loss = 0.4661, Accuracy = 0.7812\n",
      "Epoch 6, Batch 10800: Loss = 0.5703, Accuracy = 0.6250\n",
      "Epoch 6, Batch 10900: Loss = 0.5046, Accuracy = 0.8125\n",
      "Epoch 6, Batch 11000: Loss = 0.4167, Accuracy = 0.8750\n",
      "Epoch 6, Batch 11100: Loss = 0.7051, Accuracy = 0.6250\n",
      "Epoch 6, Batch 11200: Loss = 0.7157, Accuracy = 0.5312\n",
      "Epoch 6, Batch 11300: Loss = 0.6310, Accuracy = 0.6562\n",
      "Epoch 6, Batch 11400: Loss = 0.6488, Accuracy = 0.6562\n",
      "Epoch 6, Batch 11500: Loss = 0.6270, Accuracy = 0.6562\n",
      "Epoch 6, Batch 11600: Loss = 0.6018, Accuracy = 0.6250\n",
      "Epoch 6, Batch 11700: Loss = 0.5812, Accuracy = 0.7500\n",
      "Epoch 6, Batch 11800: Loss = 0.6614, Accuracy = 0.5312\n",
      "Epoch 6, Batch 11900: Loss = 0.7257, Accuracy = 0.5312\n",
      "Epoch 6, Batch 12000: Loss = 0.6932, Accuracy = 0.5938\n",
      "Epoch 6, Batch 12100: Loss = 0.5710, Accuracy = 0.7812\n",
      "Epoch 6, Batch 12200: Loss = 0.6410, Accuracy = 0.5625\n",
      "Epoch 6, Batch 12300: Loss = 0.6694, Accuracy = 0.5938\n",
      "Epoch 6, Batch 12400: Loss = 0.4955, Accuracy = 0.8438\n",
      "Epoch 6, Batch 12500: Loss = 0.6011, Accuracy = 0.7500\n",
      "Epoch 6, Batch 12600: Loss = 0.5029, Accuracy = 0.7812\n",
      "Epoch 6, Batch 12700: Loss = 0.6394, Accuracy = 0.5938\n",
      "Epoch 6, Batch 12800: Loss = 0.5246, Accuracy = 0.7812\n",
      "Epoch 6, Batch 12900: Loss = 0.6279, Accuracy = 0.6562\n",
      "Epoch 6, Batch 13000: Loss = 0.6584, Accuracy = 0.5625\n",
      "Epoch 6, Batch 13100: Loss = 0.5027, Accuracy = 0.7812\n",
      "Epoch 6, Batch 13200: Loss = 0.6970, Accuracy = 0.6250\n",
      "Epoch 6, Batch 13300: Loss = 0.6519, Accuracy = 0.5938\n",
      "Epoch 6, Batch 13400: Loss = 0.4813, Accuracy = 0.8125\n",
      "Epoch 6, Batch 13500: Loss = 0.7081, Accuracy = 0.5625\n",
      "Epoch 6, Batch 13600: Loss = 0.5252, Accuracy = 0.7500\n",
      "Epoch 6, Batch 13700: Loss = 0.5593, Accuracy = 0.7500\n",
      "Epoch 6, Batch 13800: Loss = 0.5609, Accuracy = 0.7188\n",
      "Epoch 6, Batch 13900: Loss = 0.4935, Accuracy = 0.7500\n",
      "Epoch 6, Batch 14000: Loss = 0.6237, Accuracy = 0.6875\n",
      "Epoch 6, Batch 14100: Loss = 0.6162, Accuracy = 0.6875\n",
      "Epoch 6, Batch 14200: Loss = 0.7446, Accuracy = 0.6250\n",
      "Epoch 6, Batch 14300: Loss = 0.6415, Accuracy = 0.5625\n",
      "Epoch 6, Batch 14400: Loss = 0.5230, Accuracy = 0.7188\n",
      "Epoch 6, Batch 14500: Loss = 0.5110, Accuracy = 0.8125\n",
      "Epoch 6, Batch 14600: Loss = 0.5686, Accuracy = 0.7188\n",
      "Epoch 6, Batch 14700: Loss = 0.7882, Accuracy = 0.5625\n",
      "Epoch 6, Batch 14800: Loss = 0.5998, Accuracy = 0.7812\n",
      "Epoch 6, Batch 14900: Loss = 0.6325, Accuracy = 0.6875\n",
      "Epoch 6, Batch 15000: Loss = 0.5360, Accuracy = 0.7500\n",
      "Epoch 6, Batch 15100: Loss = 0.5172, Accuracy = 0.7500\n",
      "Epoch 6, Batch 15200: Loss = 0.6656, Accuracy = 0.6875\n",
      "Epoch 6, Batch 15300: Loss = 0.7233, Accuracy = 0.5938\n",
      "Epoch 6, Batch 15400: Loss = 0.6446, Accuracy = 0.7188\n",
      "Epoch 6, Batch 15500: Loss = 0.5763, Accuracy = 0.7188\n",
      "Epoch 6, Batch 15600: Loss = 0.6404, Accuracy = 0.6250\n",
      "Epoch 6, Batch 15700: Loss = 0.7663, Accuracy = 0.5312\n",
      "Epoch 6, Batch 15800: Loss = 0.6530, Accuracy = 0.5938\n",
      "Epoch 6, Batch 15900: Loss = 0.6277, Accuracy = 0.6875\n",
      "Epoch 6, Batch 16000: Loss = 0.5876, Accuracy = 0.6250\n",
      "Epoch 6, Batch 16100: Loss = 0.6516, Accuracy = 0.6875\n",
      "Epoch 6, Batch 16200: Loss = 0.6235, Accuracy = 0.7188\n",
      "Epoch 6, Batch 16300: Loss = 0.5901, Accuracy = 0.7188\n",
      "Epoch 6, Batch 16400: Loss = 0.7476, Accuracy = 0.5938\n",
      "Epoch 6, Batch 16500: Loss = 0.6875, Accuracy = 0.6562\n",
      "Epoch 6, Batch 16600: Loss = 0.6697, Accuracy = 0.6875\n",
      "Epoch 6, Batch 16700: Loss = 0.5433, Accuracy = 0.8125\n",
      "Epoch 6, Batch 16800: Loss = 0.5810, Accuracy = 0.7188\n",
      "Epoch 6, Batch 16900: Loss = 0.6483, Accuracy = 0.5938\n",
      "Epoch 6, Batch 17000: Loss = 0.6111, Accuracy = 0.7188\n",
      "Epoch 6, Batch 17100: Loss = 0.5478, Accuracy = 0.7812\n",
      "Epoch 6, Batch 17200: Loss = 0.6751, Accuracy = 0.5312\n",
      "Epoch 6, Batch 17300: Loss = 0.4965, Accuracy = 0.8438\n",
      "Epoch 6, Batch 17400: Loss = 0.4928, Accuracy = 0.7812\n",
      "Epoch 6, Batch 17500: Loss = 0.5614, Accuracy = 0.7188\n",
      "Epoch 6, Batch 17600: Loss = 0.5418, Accuracy = 0.7500\n",
      "Epoch 6, Batch 17700: Loss = 0.6116, Accuracy = 0.6562\n",
      "Epoch 6, Batch 17800: Loss = 0.7122, Accuracy = 0.4688\n",
      "Epoch 6, Batch 17900: Loss = 0.5070, Accuracy = 0.8125\n",
      "Epoch 6, Batch 18000: Loss = 0.4695, Accuracy = 0.8125\n",
      "Epoch 6, Batch 18100: Loss = 0.6016, Accuracy = 0.7500\n",
      "Epoch 6, Batch 18200: Loss = 0.6231, Accuracy = 0.7188\n",
      "Epoch 6, Batch 18300: Loss = 0.8355, Accuracy = 0.4062\n",
      "Epoch 6, Batch 18400: Loss = 0.5958, Accuracy = 0.6562\n",
      "Epoch 6, Batch 18500: Loss = 0.6260, Accuracy = 0.6250\n",
      "Epoch 6, Batch 18600: Loss = 0.7971, Accuracy = 0.4375\n",
      "Epoch 6, Batch 18700: Loss = 0.6805, Accuracy = 0.6562\n",
      "Epoch 6, Batch 18800: Loss = 0.5810, Accuracy = 0.7188\n",
      "Epoch 6, Batch 18900: Loss = 0.4919, Accuracy = 0.7500\n",
      "Epoch 6, Batch 19000: Loss = 0.5047, Accuracy = 0.7812\n",
      "Epoch 6, Batch 19100: Loss = 0.5886, Accuracy = 0.6875\n",
      "Epoch 6, Batch 19200: Loss = 0.5166, Accuracy = 0.7188\n",
      "Epoch 6, Batch 19300: Loss = 0.6479, Accuracy = 0.6875\n",
      "Epoch 6, Batch 19400: Loss = 0.6525, Accuracy = 0.5938\n",
      "Epoch 6, Batch 19500: Loss = 0.6703, Accuracy = 0.6250\n",
      "Epoch 6, Batch 19600: Loss = 0.6566, Accuracy = 0.6250\n",
      "Epoch 6, Batch 19700: Loss = 0.4896, Accuracy = 0.8125\n",
      "Epoch 6, Batch 19800: Loss = 0.4760, Accuracy = 0.8125\n",
      "Epoch 6, Batch 19900: Loss = 0.5308, Accuracy = 0.7500\n",
      "Epoch 6, Batch 20000: Loss = 0.6123, Accuracy = 0.6562\n",
      "Epoch 6, Batch 20100: Loss = 0.6543, Accuracy = 0.5938\n",
      "Epoch 6, Batch 20200: Loss = 0.5338, Accuracy = 0.7500\n",
      "Epoch 6, Batch 20300: Loss = 0.6324, Accuracy = 0.6875\n",
      "Epoch 6, Batch 20400: Loss = 0.4879, Accuracy = 0.8125\n",
      "Epoch 6, Batch 20500: Loss = 0.6377, Accuracy = 0.6250\n",
      "Epoch 6, Batch 20600: Loss = 0.6696, Accuracy = 0.6562\n",
      "Epoch 6, Batch 20700: Loss = 0.6270, Accuracy = 0.6562\n",
      "Epoch 6, Batch 20800: Loss = 0.6735, Accuracy = 0.5938\n",
      "Epoch 6, Batch 20900: Loss = 0.5851, Accuracy = 0.6875\n",
      "Epoch 6, Batch 21000: Loss = 0.6118, Accuracy = 0.6562\n",
      "Epoch 6, Batch 21100: Loss = 0.4968, Accuracy = 0.7188\n",
      "Epoch 6, Batch 21200: Loss = 0.6354, Accuracy = 0.6562\n",
      "Epoch 6, Batch 21300: Loss = 0.6182, Accuracy = 0.6875\n",
      "Epoch 6, Batch 21400: Loss = 0.4776, Accuracy = 0.8750\n",
      "Epoch 6, Batch 21500: Loss = 0.6651, Accuracy = 0.6875\n",
      "Epoch 6, Batch 21600: Loss = 0.4910, Accuracy = 0.7500\n",
      "Epoch 6, Batch 21700: Loss = 0.5910, Accuracy = 0.8125\n",
      "Epoch 6, Batch 21800: Loss = 0.7291, Accuracy = 0.5625\n",
      "Epoch 6: Train Loss = 0.5977, Train Accuracy = 0.6995, Time = 547.96s\n",
      "Validation Accuracy: 0.7071\n",
      "Epoch 7, Batch 100: Loss = 0.5887, Accuracy = 0.7500\n",
      "Epoch 7, Batch 200: Loss = 0.5860, Accuracy = 0.7500\n",
      "Epoch 7, Batch 300: Loss = 0.5725, Accuracy = 0.5938\n",
      "Epoch 7, Batch 400: Loss = 0.5782, Accuracy = 0.6250\n",
      "Epoch 7, Batch 500: Loss = 0.6307, Accuracy = 0.6250\n",
      "Epoch 7, Batch 600: Loss = 0.5473, Accuracy = 0.8438\n",
      "Epoch 7, Batch 700: Loss = 0.5231, Accuracy = 0.7812\n",
      "Epoch 7, Batch 800: Loss = 0.5443, Accuracy = 0.7812\n",
      "Epoch 7, Batch 900: Loss = 0.6563, Accuracy = 0.6250\n",
      "Epoch 7, Batch 1000: Loss = 0.6889, Accuracy = 0.6562\n",
      "Epoch 7, Batch 1100: Loss = 0.7113, Accuracy = 0.5625\n",
      "Epoch 7, Batch 1200: Loss = 0.5041, Accuracy = 0.8438\n",
      "Epoch 7, Batch 1300: Loss = 0.5504, Accuracy = 0.7188\n",
      "Epoch 7, Batch 1400: Loss = 0.7184, Accuracy = 0.5625\n",
      "Epoch 7, Batch 1500: Loss = 0.6650, Accuracy = 0.5938\n",
      "Epoch 7, Batch 1600: Loss = 0.6528, Accuracy = 0.7500\n",
      "Epoch 7, Batch 1700: Loss = 0.7611, Accuracy = 0.5312\n",
      "Epoch 7, Batch 1800: Loss = 0.5571, Accuracy = 0.7500\n",
      "Epoch 7, Batch 1900: Loss = 0.7337, Accuracy = 0.6875\n",
      "Epoch 7, Batch 2000: Loss = 0.4986, Accuracy = 0.8438\n",
      "Epoch 7, Batch 2100: Loss = 0.5642, Accuracy = 0.7500\n",
      "Epoch 7, Batch 2200: Loss = 0.7260, Accuracy = 0.6250\n",
      "Epoch 7, Batch 2300: Loss = 0.6067, Accuracy = 0.7188\n",
      "Epoch 7, Batch 2400: Loss = 0.6996, Accuracy = 0.6250\n",
      "Epoch 7, Batch 2500: Loss = 0.5404, Accuracy = 0.7812\n",
      "Epoch 7, Batch 2600: Loss = 0.5211, Accuracy = 0.7500\n",
      "Epoch 7, Batch 2700: Loss = 0.5972, Accuracy = 0.7188\n",
      "Epoch 7, Batch 2800: Loss = 0.6508, Accuracy = 0.6875\n",
      "Epoch 7, Batch 2900: Loss = 0.6311, Accuracy = 0.5938\n",
      "Epoch 7, Batch 3000: Loss = 0.5549, Accuracy = 0.7500\n",
      "Epoch 7, Batch 3100: Loss = 0.5031, Accuracy = 0.6875\n",
      "Epoch 7, Batch 3200: Loss = 0.7473, Accuracy = 0.5938\n",
      "Epoch 7, Batch 3300: Loss = 0.5213, Accuracy = 0.7500\n",
      "Epoch 7, Batch 3400: Loss = 0.5261, Accuracy = 0.7188\n",
      "Epoch 7, Batch 3500: Loss = 0.6912, Accuracy = 0.6875\n",
      "Epoch 7, Batch 3600: Loss = 0.6370, Accuracy = 0.7500\n",
      "Epoch 7, Batch 3700: Loss = 0.5860, Accuracy = 0.6250\n",
      "Epoch 7, Batch 3800: Loss = 0.5886, Accuracy = 0.6250\n",
      "Epoch 7, Batch 3900: Loss = 0.6391, Accuracy = 0.6562\n",
      "Epoch 7, Batch 4000: Loss = 0.7244, Accuracy = 0.5938\n",
      "Epoch 7, Batch 4100: Loss = 0.5287, Accuracy = 0.8125\n",
      "Epoch 7, Batch 4200: Loss = 0.5181, Accuracy = 0.8125\n",
      "Epoch 7, Batch 4300: Loss = 0.6214, Accuracy = 0.6250\n",
      "Epoch 7, Batch 4400: Loss = 0.6634, Accuracy = 0.6250\n",
      "Epoch 7, Batch 4500: Loss = 0.4683, Accuracy = 0.8438\n",
      "Epoch 7, Batch 4600: Loss = 0.5003, Accuracy = 0.8125\n",
      "Epoch 7, Batch 4700: Loss = 0.4466, Accuracy = 0.8125\n",
      "Epoch 7, Batch 4800: Loss = 0.5271, Accuracy = 0.7188\n",
      "Epoch 7, Batch 4900: Loss = 0.6816, Accuracy = 0.6250\n",
      "Epoch 7, Batch 5000: Loss = 0.6536, Accuracy = 0.6562\n",
      "Epoch 7, Batch 5100: Loss = 0.6224, Accuracy = 0.6250\n",
      "Epoch 7, Batch 5200: Loss = 0.5066, Accuracy = 0.7812\n",
      "Epoch 7, Batch 5300: Loss = 0.4537, Accuracy = 0.7812\n",
      "Epoch 7, Batch 5400: Loss = 0.6501, Accuracy = 0.6250\n",
      "Epoch 7, Batch 5500: Loss = 0.4431, Accuracy = 0.8750\n",
      "Epoch 7, Batch 5600: Loss = 0.5452, Accuracy = 0.7188\n",
      "Epoch 7, Batch 5700: Loss = 0.6278, Accuracy = 0.7500\n",
      "Epoch 7, Batch 5800: Loss = 0.5627, Accuracy = 0.6875\n",
      "Epoch 7, Batch 5900: Loss = 0.5879, Accuracy = 0.6562\n",
      "Epoch 7, Batch 6000: Loss = 0.5217, Accuracy = 0.8125\n",
      "Epoch 7, Batch 6100: Loss = 0.7309, Accuracy = 0.5938\n",
      "Epoch 7, Batch 6200: Loss = 0.6055, Accuracy = 0.5938\n",
      "Epoch 7, Batch 6300: Loss = 0.5596, Accuracy = 0.7188\n",
      "Epoch 7, Batch 6400: Loss = 0.6274, Accuracy = 0.6875\n",
      "Epoch 7, Batch 6500: Loss = 0.9001, Accuracy = 0.5625\n",
      "Epoch 7, Batch 6600: Loss = 0.6452, Accuracy = 0.6562\n",
      "Epoch 7, Batch 6700: Loss = 0.5016, Accuracy = 0.7500\n",
      "Epoch 7, Batch 6800: Loss = 0.6324, Accuracy = 0.6875\n",
      "Epoch 7, Batch 6900: Loss = 0.5975, Accuracy = 0.7188\n",
      "Epoch 7, Batch 7000: Loss = 0.5530, Accuracy = 0.7812\n",
      "Epoch 7, Batch 7100: Loss = 0.5321, Accuracy = 0.7500\n",
      "Epoch 7, Batch 7200: Loss = 0.6308, Accuracy = 0.6562\n",
      "Epoch 7, Batch 7300: Loss = 0.5668, Accuracy = 0.7188\n",
      "Epoch 7, Batch 7400: Loss = 0.6901, Accuracy = 0.6562\n",
      "Epoch 7, Batch 7500: Loss = 0.7533, Accuracy = 0.5625\n",
      "Epoch 7, Batch 7600: Loss = 0.6471, Accuracy = 0.5938\n",
      "Epoch 7, Batch 7700: Loss = 0.5306, Accuracy = 0.7188\n",
      "Epoch 7, Batch 7800: Loss = 0.6741, Accuracy = 0.6250\n",
      "Epoch 7, Batch 7900: Loss = 0.5617, Accuracy = 0.6875\n",
      "Epoch 7, Batch 8000: Loss = 0.5411, Accuracy = 0.6875\n",
      "Epoch 7, Batch 8100: Loss = 0.6066, Accuracy = 0.7500\n",
      "Epoch 7, Batch 8200: Loss = 0.6368, Accuracy = 0.7500\n",
      "Epoch 7, Batch 8300: Loss = 0.5152, Accuracy = 0.8125\n",
      "Epoch 7, Batch 8400: Loss = 0.5671, Accuracy = 0.8125\n",
      "Epoch 7, Batch 8500: Loss = 0.5821, Accuracy = 0.7812\n",
      "Epoch 7, Batch 8600: Loss = 0.6669, Accuracy = 0.6250\n",
      "Epoch 7, Batch 8700: Loss = 0.5943, Accuracy = 0.6875\n",
      "Epoch 7, Batch 8800: Loss = 0.5624, Accuracy = 0.6875\n",
      "Epoch 7, Batch 8900: Loss = 0.5419, Accuracy = 0.7500\n",
      "Epoch 7, Batch 9000: Loss = 0.6369, Accuracy = 0.6875\n",
      "Epoch 7, Batch 9100: Loss = 0.4921, Accuracy = 0.6875\n",
      "Epoch 7, Batch 9200: Loss = 0.5230, Accuracy = 0.7500\n",
      "Epoch 7, Batch 9300: Loss = 0.5365, Accuracy = 0.7500\n",
      "Epoch 7, Batch 9400: Loss = 0.5019, Accuracy = 0.7500\n",
      "Epoch 7, Batch 9500: Loss = 0.4790, Accuracy = 0.7812\n",
      "Epoch 7, Batch 9600: Loss = 0.5659, Accuracy = 0.6562\n",
      "Epoch 7, Batch 9700: Loss = 0.4954, Accuracy = 0.7812\n",
      "Epoch 7, Batch 9800: Loss = 0.6765, Accuracy = 0.6250\n",
      "Epoch 7, Batch 9900: Loss = 0.7105, Accuracy = 0.5312\n",
      "Epoch 7, Batch 10000: Loss = 0.5657, Accuracy = 0.7500\n",
      "Epoch 7, Batch 10100: Loss = 0.5480, Accuracy = 0.6250\n",
      "Epoch 7, Batch 10200: Loss = 0.6173, Accuracy = 0.6562\n",
      "Epoch 7, Batch 10300: Loss = 0.7165, Accuracy = 0.5938\n",
      "Epoch 7, Batch 10400: Loss = 0.6462, Accuracy = 0.6250\n",
      "Epoch 7, Batch 10500: Loss = 0.5041, Accuracy = 0.8125\n",
      "Epoch 7, Batch 10600: Loss = 0.4729, Accuracy = 0.8438\n",
      "Epoch 7, Batch 10700: Loss = 0.6571, Accuracy = 0.6875\n",
      "Epoch 7, Batch 10800: Loss = 0.5906, Accuracy = 0.6250\n",
      "Epoch 7, Batch 10900: Loss = 0.6822, Accuracy = 0.6250\n",
      "Epoch 7, Batch 11000: Loss = 0.5799, Accuracy = 0.6875\n",
      "Epoch 7, Batch 11100: Loss = 0.7016, Accuracy = 0.5938\n",
      "Epoch 7, Batch 11200: Loss = 0.7047, Accuracy = 0.5938\n",
      "Epoch 7, Batch 11300: Loss = 0.5791, Accuracy = 0.7812\n",
      "Epoch 7, Batch 11400: Loss = 0.5242, Accuracy = 0.8125\n",
      "Epoch 7, Batch 11500: Loss = 0.5178, Accuracy = 0.7500\n",
      "Epoch 7, Batch 11600: Loss = 0.6168, Accuracy = 0.6562\n",
      "Epoch 7, Batch 11700: Loss = 0.6387, Accuracy = 0.7188\n",
      "Epoch 7, Batch 11800: Loss = 0.5726, Accuracy = 0.6875\n",
      "Epoch 7, Batch 11900: Loss = 0.5263, Accuracy = 0.7188\n",
      "Epoch 7, Batch 12000: Loss = 0.5275, Accuracy = 0.6875\n",
      "Epoch 7, Batch 12100: Loss = 0.6226, Accuracy = 0.7500\n",
      "Epoch 7, Batch 12200: Loss = 0.5760, Accuracy = 0.7188\n",
      "Epoch 7, Batch 12300: Loss = 0.6853, Accuracy = 0.5625\n",
      "Epoch 7, Batch 12400: Loss = 0.5042, Accuracy = 0.8125\n",
      "Epoch 7, Batch 12500: Loss = 0.5325, Accuracy = 0.7500\n",
      "Epoch 7, Batch 12600: Loss = 0.5349, Accuracy = 0.8750\n",
      "Epoch 7, Batch 12700: Loss = 0.6146, Accuracy = 0.7188\n",
      "Epoch 7, Batch 12800: Loss = 0.5566, Accuracy = 0.8125\n",
      "Epoch 7, Batch 12900: Loss = 0.5283, Accuracy = 0.7812\n",
      "Epoch 7, Batch 13000: Loss = 0.6915, Accuracy = 0.5312\n",
      "Epoch 7, Batch 13100: Loss = 0.5118, Accuracy = 0.7500\n",
      "Epoch 7, Batch 13200: Loss = 0.7073, Accuracy = 0.5312\n",
      "Epoch 7, Batch 13300: Loss = 0.6859, Accuracy = 0.5938\n",
      "Epoch 7, Batch 13400: Loss = 0.6172, Accuracy = 0.7812\n",
      "Epoch 7, Batch 13500: Loss = 0.6685, Accuracy = 0.6562\n",
      "Epoch 7, Batch 13600: Loss = 0.5969, Accuracy = 0.7188\n",
      "Epoch 7, Batch 13700: Loss = 0.5856, Accuracy = 0.7500\n",
      "Epoch 7, Batch 13800: Loss = 0.6025, Accuracy = 0.5938\n",
      "Epoch 7, Batch 13900: Loss = 0.4916, Accuracy = 0.8438\n",
      "Epoch 7, Batch 14000: Loss = 0.6173, Accuracy = 0.5938\n",
      "Epoch 7, Batch 14100: Loss = 0.6705, Accuracy = 0.6250\n",
      "Epoch 7, Batch 14200: Loss = 0.6573, Accuracy = 0.6875\n",
      "Epoch 7, Batch 14300: Loss = 0.5874, Accuracy = 0.8125\n",
      "Epoch 7, Batch 14400: Loss = 0.5727, Accuracy = 0.6875\n",
      "Epoch 7, Batch 14500: Loss = 0.5006, Accuracy = 0.7188\n",
      "Epoch 7, Batch 14600: Loss = 0.7015, Accuracy = 0.5625\n",
      "Epoch 7, Batch 14700: Loss = 0.6091, Accuracy = 0.6875\n",
      "Epoch 7, Batch 14800: Loss = 0.7553, Accuracy = 0.4688\n",
      "Epoch 7, Batch 14900: Loss = 0.8028, Accuracy = 0.5625\n",
      "Epoch 7, Batch 15000: Loss = 0.7377, Accuracy = 0.6562\n",
      "Epoch 7, Batch 15100: Loss = 0.5272, Accuracy = 0.6875\n",
      "Epoch 7, Batch 15200: Loss = 0.6774, Accuracy = 0.7500\n",
      "Epoch 7, Batch 15300: Loss = 0.5722, Accuracy = 0.7188\n",
      "Epoch 7, Batch 15400: Loss = 0.6074, Accuracy = 0.6875\n",
      "Epoch 7, Batch 15500: Loss = 0.6262, Accuracy = 0.6562\n",
      "Epoch 7, Batch 15600: Loss = 0.6923, Accuracy = 0.6562\n",
      "Epoch 7, Batch 15700: Loss = 0.4943, Accuracy = 0.7500\n",
      "Epoch 7, Batch 15800: Loss = 0.6992, Accuracy = 0.6250\n",
      "Epoch 7, Batch 15900: Loss = 0.5222, Accuracy = 0.7500\n",
      "Epoch 7, Batch 16000: Loss = 0.5170, Accuracy = 0.7812\n",
      "Epoch 7, Batch 16100: Loss = 0.5460, Accuracy = 0.7500\n",
      "Epoch 7, Batch 16200: Loss = 0.5680, Accuracy = 0.7812\n",
      "Epoch 7, Batch 16300: Loss = 0.4832, Accuracy = 0.7812\n",
      "Epoch 7, Batch 16400: Loss = 0.4700, Accuracy = 0.8438\n",
      "Epoch 7, Batch 16500: Loss = 0.5360, Accuracy = 0.7500\n",
      "Epoch 7, Batch 16600: Loss = 0.6835, Accuracy = 0.6875\n",
      "Epoch 7, Batch 16700: Loss = 0.6000, Accuracy = 0.7188\n",
      "Epoch 7, Batch 16800: Loss = 0.6730, Accuracy = 0.5938\n",
      "Epoch 7, Batch 16900: Loss = 0.6048, Accuracy = 0.7188\n",
      "Epoch 7, Batch 17000: Loss = 0.5043, Accuracy = 0.8125\n",
      "Epoch 7, Batch 17100: Loss = 0.6003, Accuracy = 0.6875\n",
      "Epoch 7, Batch 17200: Loss = 0.6632, Accuracy = 0.6562\n",
      "Epoch 7, Batch 17300: Loss = 0.6163, Accuracy = 0.7188\n",
      "Epoch 7, Batch 17400: Loss = 0.6020, Accuracy = 0.6562\n",
      "Epoch 7, Batch 17500: Loss = 0.6041, Accuracy = 0.6562\n",
      "Epoch 7, Batch 17600: Loss = 0.4759, Accuracy = 0.8125\n",
      "Epoch 7, Batch 17700: Loss = 0.5954, Accuracy = 0.7188\n",
      "Epoch 7, Batch 17800: Loss = 0.6455, Accuracy = 0.6562\n",
      "Epoch 7, Batch 17900: Loss = 0.5462, Accuracy = 0.6250\n",
      "Epoch 7, Batch 18000: Loss = 0.4649, Accuracy = 0.8125\n",
      "Epoch 7, Batch 18100: Loss = 0.6030, Accuracy = 0.6875\n",
      "Epoch 7, Batch 18200: Loss = 0.5698, Accuracy = 0.7500\n",
      "Epoch 7, Batch 18300: Loss = 0.6614, Accuracy = 0.6250\n",
      "Epoch 7, Batch 18400: Loss = 0.4504, Accuracy = 0.8750\n",
      "Epoch 7, Batch 18500: Loss = 0.5387, Accuracy = 0.7188\n",
      "Epoch 7, Batch 18600: Loss = 0.6245, Accuracy = 0.6875\n",
      "Epoch 7, Batch 18700: Loss = 0.5961, Accuracy = 0.7812\n",
      "Epoch 7, Batch 18800: Loss = 0.5609, Accuracy = 0.6250\n",
      "Epoch 7, Batch 18900: Loss = 0.6109, Accuracy = 0.7188\n",
      "Epoch 7, Batch 19000: Loss = 0.6480, Accuracy = 0.6562\n",
      "Epoch 7, Batch 19100: Loss = 0.5780, Accuracy = 0.7188\n",
      "Epoch 7, Batch 19200: Loss = 0.7422, Accuracy = 0.5312\n",
      "Epoch 7, Batch 19300: Loss = 0.6968, Accuracy = 0.5938\n",
      "Epoch 7, Batch 19400: Loss = 0.5960, Accuracy = 0.7188\n",
      "Epoch 7, Batch 19500: Loss = 0.6310, Accuracy = 0.6875\n",
      "Epoch 7, Batch 19600: Loss = 0.4857, Accuracy = 0.6875\n",
      "Epoch 7, Batch 19700: Loss = 0.5099, Accuracy = 0.7812\n",
      "Epoch 7, Batch 19800: Loss = 0.4869, Accuracy = 0.8438\n",
      "Epoch 7, Batch 19900: Loss = 0.6517, Accuracy = 0.6875\n",
      "Epoch 7, Batch 20000: Loss = 0.7807, Accuracy = 0.5000\n",
      "Epoch 7, Batch 20100: Loss = 0.5981, Accuracy = 0.7500\n",
      "Epoch 7, Batch 20200: Loss = 0.6049, Accuracy = 0.7500\n",
      "Epoch 7, Batch 20300: Loss = 0.5437, Accuracy = 0.7812\n",
      "Epoch 7, Batch 20400: Loss = 0.5730, Accuracy = 0.7188\n",
      "Epoch 7, Batch 20500: Loss = 0.6387, Accuracy = 0.6250\n",
      "Epoch 7, Batch 20600: Loss = 0.6065, Accuracy = 0.7188\n",
      "Epoch 7, Batch 20700: Loss = 0.7000, Accuracy = 0.7188\n",
      "Epoch 7, Batch 20800: Loss = 0.6909, Accuracy = 0.5625\n",
      "Epoch 7, Batch 20900: Loss = 0.6348, Accuracy = 0.6250\n",
      "Epoch 7, Batch 21000: Loss = 0.4411, Accuracy = 0.8438\n",
      "Epoch 7, Batch 21100: Loss = 0.6605, Accuracy = 0.6562\n",
      "Epoch 7, Batch 21200: Loss = 0.6131, Accuracy = 0.6250\n",
      "Epoch 7, Batch 21300: Loss = 0.6474, Accuracy = 0.6250\n",
      "Epoch 7, Batch 21400: Loss = 0.6678, Accuracy = 0.5938\n",
      "Epoch 7, Batch 21500: Loss = 0.7117, Accuracy = 0.5938\n",
      "Epoch 7, Batch 21600: Loss = 0.4866, Accuracy = 0.8438\n",
      "Epoch 7, Batch 21700: Loss = 0.4932, Accuracy = 0.7500\n",
      "Epoch 7, Batch 21800: Loss = 0.5368, Accuracy = 0.6875\n",
      "Epoch 7: Train Loss = 0.5978, Train Accuracy = 0.6999, Time = 550.17s\n",
      "Validation Accuracy: 0.7039\n",
      "Epoch 8, Batch 100: Loss = 0.5256, Accuracy = 0.6562\n",
      "Epoch 8, Batch 200: Loss = 0.5702, Accuracy = 0.7188\n",
      "Epoch 8, Batch 300: Loss = 0.6163, Accuracy = 0.6562\n",
      "Epoch 8, Batch 400: Loss = 0.5727, Accuracy = 0.7500\n",
      "Epoch 8, Batch 500: Loss = 0.5607, Accuracy = 0.7500\n",
      "Epoch 8, Batch 600: Loss = 0.6763, Accuracy = 0.6562\n",
      "Epoch 8, Batch 700: Loss = 0.6127, Accuracy = 0.7188\n",
      "Epoch 8, Batch 800: Loss = 0.5522, Accuracy = 0.6875\n",
      "Epoch 8, Batch 900: Loss = 0.6645, Accuracy = 0.5938\n",
      "Epoch 8, Batch 1000: Loss = 0.5456, Accuracy = 0.7500\n",
      "Epoch 8, Batch 1100: Loss = 0.6025, Accuracy = 0.6875\n",
      "Epoch 8, Batch 1200: Loss = 0.6617, Accuracy = 0.6562\n",
      "Epoch 8, Batch 1300: Loss = 0.6204, Accuracy = 0.6250\n",
      "Epoch 8, Batch 1400: Loss = 0.5906, Accuracy = 0.6562\n",
      "Epoch 8, Batch 1500: Loss = 0.6462, Accuracy = 0.7188\n",
      "Epoch 8, Batch 1600: Loss = 0.5699, Accuracy = 0.6875\n",
      "Epoch 8, Batch 1700: Loss = 0.6267, Accuracy = 0.6875\n",
      "Epoch 8, Batch 1800: Loss = 0.5896, Accuracy = 0.6875\n",
      "Epoch 8, Batch 1900: Loss = 0.5370, Accuracy = 0.7812\n",
      "Epoch 8, Batch 2000: Loss = 0.6461, Accuracy = 0.6250\n",
      "Epoch 8, Batch 2100: Loss = 0.7131, Accuracy = 0.6250\n",
      "Epoch 8, Batch 2200: Loss = 0.6903, Accuracy = 0.6562\n",
      "Epoch 8, Batch 2300: Loss = 0.5536, Accuracy = 0.7188\n",
      "Epoch 8, Batch 2400: Loss = 0.6406, Accuracy = 0.6562\n",
      "Epoch 8, Batch 2500: Loss = 0.5415, Accuracy = 0.6562\n",
      "Epoch 8, Batch 2600: Loss = 0.5357, Accuracy = 0.7812\n",
      "Epoch 8, Batch 2700: Loss = 0.6219, Accuracy = 0.7500\n",
      "Epoch 8, Batch 2800: Loss = 0.7296, Accuracy = 0.5625\n",
      "Epoch 8, Batch 2900: Loss = 0.6140, Accuracy = 0.7500\n",
      "Epoch 8, Batch 3000: Loss = 0.5452, Accuracy = 0.7500\n",
      "Epoch 8, Batch 3100: Loss = 0.7862, Accuracy = 0.5312\n",
      "Epoch 8, Batch 3200: Loss = 0.5077, Accuracy = 0.7500\n",
      "Epoch 8, Batch 3300: Loss = 0.5844, Accuracy = 0.6875\n",
      "Epoch 8, Batch 3400: Loss = 0.5969, Accuracy = 0.6875\n",
      "Epoch 8, Batch 3500: Loss = 0.8300, Accuracy = 0.4688\n",
      "Epoch 8, Batch 3600: Loss = 0.6395, Accuracy = 0.6562\n",
      "Epoch 8, Batch 3700: Loss = 0.6307, Accuracy = 0.6875\n",
      "Epoch 8, Batch 3800: Loss = 0.5304, Accuracy = 0.7500\n",
      "Epoch 8, Batch 3900: Loss = 0.6012, Accuracy = 0.6562\n",
      "Epoch 8, Batch 4000: Loss = 0.5941, Accuracy = 0.6250\n",
      "Epoch 8, Batch 4100: Loss = 0.6101, Accuracy = 0.6875\n",
      "Epoch 8, Batch 4200: Loss = 0.6647, Accuracy = 0.6562\n",
      "Epoch 8, Batch 4300: Loss = 0.6080, Accuracy = 0.7188\n",
      "Epoch 8, Batch 4400: Loss = 0.5931, Accuracy = 0.7188\n",
      "Epoch 8, Batch 4500: Loss = 0.6235, Accuracy = 0.7188\n",
      "Epoch 8, Batch 4600: Loss = 0.7168, Accuracy = 0.5312\n",
      "Epoch 8, Batch 4700: Loss = 0.6219, Accuracy = 0.7188\n",
      "Epoch 8, Batch 4800: Loss = 0.5050, Accuracy = 0.8750\n",
      "Epoch 8, Batch 4900: Loss = 0.4584, Accuracy = 0.7500\n",
      "Epoch 8, Batch 5000: Loss = 0.5471, Accuracy = 0.7188\n",
      "Epoch 8, Batch 5100: Loss = 0.6275, Accuracy = 0.6875\n",
      "Epoch 8, Batch 5200: Loss = 0.4534, Accuracy = 0.7812\n",
      "Epoch 8, Batch 5300: Loss = 0.5857, Accuracy = 0.7188\n",
      "Epoch 8, Batch 5400: Loss = 0.6061, Accuracy = 0.6250\n",
      "Epoch 8, Batch 5500: Loss = 0.5595, Accuracy = 0.7500\n",
      "Epoch 8, Batch 5600: Loss = 0.5157, Accuracy = 0.8750\n",
      "Epoch 8, Batch 5700: Loss = 0.5722, Accuracy = 0.6875\n",
      "Epoch 8, Batch 5800: Loss = 0.5626, Accuracy = 0.6875\n",
      "Epoch 8, Batch 5900: Loss = 0.5032, Accuracy = 0.7500\n",
      "Epoch 8, Batch 6000: Loss = 0.5116, Accuracy = 0.8125\n",
      "Epoch 8, Batch 6100: Loss = 0.6340, Accuracy = 0.6562\n",
      "Epoch 8, Batch 6200: Loss = 0.5404, Accuracy = 0.7188\n",
      "Epoch 8, Batch 6300: Loss = 0.5548, Accuracy = 0.7500\n",
      "Epoch 8, Batch 6400: Loss = 0.5005, Accuracy = 0.7500\n",
      "Epoch 8, Batch 6500: Loss = 0.7683, Accuracy = 0.5938\n",
      "Epoch 8, Batch 6600: Loss = 0.6135, Accuracy = 0.7812\n",
      "Epoch 8, Batch 6700: Loss = 0.6922, Accuracy = 0.6250\n",
      "Epoch 8, Batch 6800: Loss = 0.5161, Accuracy = 0.7812\n",
      "Epoch 8, Batch 6900: Loss = 0.5521, Accuracy = 0.6875\n",
      "Epoch 8, Batch 7000: Loss = 0.6468, Accuracy = 0.6250\n",
      "Epoch 8, Batch 7100: Loss = 0.6511, Accuracy = 0.6562\n",
      "Epoch 8, Batch 7200: Loss = 0.6747, Accuracy = 0.5938\n",
      "Epoch 8, Batch 7300: Loss = 0.7915, Accuracy = 0.5938\n",
      "Epoch 8, Batch 7400: Loss = 0.6680, Accuracy = 0.5938\n",
      "Epoch 8, Batch 7500: Loss = 0.6249, Accuracy = 0.6562\n",
      "Epoch 8, Batch 7600: Loss = 0.5083, Accuracy = 0.8125\n",
      "Epoch 8, Batch 7700: Loss = 0.6857, Accuracy = 0.5938\n",
      "Epoch 8, Batch 7800: Loss = 0.5859, Accuracy = 0.7188\n",
      "Epoch 8, Batch 7900: Loss = 0.7081, Accuracy = 0.5312\n",
      "Epoch 8, Batch 8000: Loss = 0.6459, Accuracy = 0.5938\n",
      "Epoch 8, Batch 8100: Loss = 0.4849, Accuracy = 0.8125\n",
      "Epoch 8, Batch 8200: Loss = 0.6023, Accuracy = 0.7188\n",
      "Epoch 8, Batch 8300: Loss = 0.7260, Accuracy = 0.5000\n",
      "Epoch 8, Batch 8400: Loss = 0.5703, Accuracy = 0.7188\n",
      "Epoch 8, Batch 8500: Loss = 0.5794, Accuracy = 0.7188\n",
      "Epoch 8, Batch 8600: Loss = 0.5081, Accuracy = 0.8125\n",
      "Epoch 8, Batch 8700: Loss = 0.5633, Accuracy = 0.7188\n",
      "Epoch 8, Batch 8800: Loss = 0.6318, Accuracy = 0.7188\n",
      "Epoch 8, Batch 8900: Loss = 0.6275, Accuracy = 0.6250\n",
      "Epoch 8, Batch 9000: Loss = 0.5033, Accuracy = 0.8125\n",
      "Epoch 8, Batch 9100: Loss = 0.5881, Accuracy = 0.7188\n",
      "Epoch 8, Batch 9200: Loss = 0.6082, Accuracy = 0.7188\n",
      "Epoch 8, Batch 9300: Loss = 0.5818, Accuracy = 0.7188\n",
      "Epoch 8, Batch 9400: Loss = 0.6696, Accuracy = 0.7188\n",
      "Epoch 8, Batch 9500: Loss = 0.6668, Accuracy = 0.6250\n",
      "Epoch 8, Batch 9600: Loss = 0.5912, Accuracy = 0.7500\n",
      "Epoch 8, Batch 9700: Loss = 0.6124, Accuracy = 0.6875\n",
      "Epoch 8, Batch 9800: Loss = 0.6444, Accuracy = 0.5000\n",
      "Epoch 8, Batch 9900: Loss = 0.7449, Accuracy = 0.5625\n",
      "Epoch 8, Batch 10000: Loss = 0.5188, Accuracy = 0.7500\n",
      "Epoch 8, Batch 10100: Loss = 0.6414, Accuracy = 0.5938\n",
      "Epoch 8, Batch 10200: Loss = 0.6789, Accuracy = 0.5625\n",
      "Epoch 8, Batch 10300: Loss = 0.5554, Accuracy = 0.7188\n",
      "Epoch 8, Batch 10400: Loss = 0.5424, Accuracy = 0.7188\n",
      "Epoch 8, Batch 10500: Loss = 0.5891, Accuracy = 0.6875\n",
      "Epoch 8, Batch 10600: Loss = 0.5688, Accuracy = 0.6875\n",
      "Epoch 8, Batch 10700: Loss = 0.5379, Accuracy = 0.7812\n",
      "Epoch 8, Batch 10800: Loss = 0.5776, Accuracy = 0.7188\n",
      "Epoch 8, Batch 10900: Loss = 0.4683, Accuracy = 0.8125\n",
      "Epoch 8, Batch 11000: Loss = 0.4164, Accuracy = 0.8125\n",
      "Epoch 8, Batch 11100: Loss = 0.5224, Accuracy = 0.8438\n",
      "Epoch 8, Batch 11200: Loss = 0.6281, Accuracy = 0.6250\n",
      "Epoch 8, Batch 11300: Loss = 0.6685, Accuracy = 0.6250\n",
      "Epoch 8, Batch 11400: Loss = 0.5319, Accuracy = 0.8125\n",
      "Epoch 8, Batch 11500: Loss = 0.6620, Accuracy = 0.5312\n",
      "Epoch 8, Batch 11600: Loss = 0.5800, Accuracy = 0.7812\n",
      "Epoch 8, Batch 11700: Loss = 0.5045, Accuracy = 0.8125\n",
      "Epoch 8, Batch 11800: Loss = 0.6584, Accuracy = 0.6875\n",
      "Epoch 8, Batch 11900: Loss = 0.5104, Accuracy = 0.7500\n",
      "Epoch 8, Batch 12000: Loss = 0.5605, Accuracy = 0.6875\n",
      "Epoch 8, Batch 12100: Loss = 0.4533, Accuracy = 0.8125\n",
      "Epoch 8, Batch 12200: Loss = 0.4954, Accuracy = 0.7188\n",
      "Epoch 8, Batch 12300: Loss = 0.5557, Accuracy = 0.6875\n",
      "Epoch 8, Batch 12400: Loss = 0.6454, Accuracy = 0.6875\n",
      "Epoch 8, Batch 12500: Loss = 0.8142, Accuracy = 0.5312\n",
      "Epoch 8, Batch 12600: Loss = 0.4830, Accuracy = 0.8438\n",
      "Epoch 8, Batch 12700: Loss = 0.5922, Accuracy = 0.6562\n",
      "Epoch 8, Batch 12800: Loss = 0.5902, Accuracy = 0.6875\n",
      "Epoch 8, Batch 12900: Loss = 0.5018, Accuracy = 0.8438\n",
      "Epoch 8, Batch 13000: Loss = 0.6099, Accuracy = 0.6875\n",
      "Epoch 8, Batch 13100: Loss = 0.4846, Accuracy = 0.9062\n",
      "Epoch 8, Batch 13200: Loss = 0.6391, Accuracy = 0.6875\n",
      "Epoch 8, Batch 13300: Loss = 0.5247, Accuracy = 0.6875\n",
      "Epoch 8, Batch 13400: Loss = 0.6082, Accuracy = 0.6875\n",
      "Epoch 8, Batch 13500: Loss = 0.6246, Accuracy = 0.5938\n",
      "Epoch 8, Batch 13600: Loss = 0.5935, Accuracy = 0.6875\n",
      "Epoch 8, Batch 13700: Loss = 0.5186, Accuracy = 0.7812\n",
      "Epoch 8, Batch 13800: Loss = 0.6456, Accuracy = 0.6875\n",
      "Epoch 8, Batch 13900: Loss = 0.6562, Accuracy = 0.7188\n",
      "Epoch 8, Batch 14000: Loss = 0.5688, Accuracy = 0.6875\n",
      "Epoch 8, Batch 14100: Loss = 0.6494, Accuracy = 0.5938\n",
      "Epoch 8, Batch 14200: Loss = 0.6273, Accuracy = 0.6562\n",
      "Epoch 8, Batch 14300: Loss = 0.5962, Accuracy = 0.7188\n",
      "Epoch 8, Batch 14400: Loss = 0.5779, Accuracy = 0.6875\n",
      "Epoch 8, Batch 14500: Loss = 0.5462, Accuracy = 0.7188\n",
      "Epoch 8, Batch 14600: Loss = 0.6465, Accuracy = 0.6250\n",
      "Epoch 8, Batch 14700: Loss = 0.6496, Accuracy = 0.6250\n",
      "Epoch 8, Batch 14800: Loss = 0.6091, Accuracy = 0.7500\n",
      "Epoch 8, Batch 14900: Loss = 0.5492, Accuracy = 0.7500\n",
      "Epoch 8, Batch 15000: Loss = 0.6021, Accuracy = 0.6562\n",
      "Epoch 8, Batch 15100: Loss = 0.5608, Accuracy = 0.7188\n",
      "Epoch 8, Batch 15200: Loss = 0.6403, Accuracy = 0.6875\n",
      "Epoch 8, Batch 15300: Loss = 0.6202, Accuracy = 0.7188\n",
      "Epoch 8, Batch 15400: Loss = 0.5165, Accuracy = 0.7500\n",
      "Epoch 8, Batch 15500: Loss = 0.5201, Accuracy = 0.7188\n",
      "Epoch 8, Batch 15600: Loss = 0.6989, Accuracy = 0.6562\n",
      "Epoch 8, Batch 15700: Loss = 0.5362, Accuracy = 0.8438\n",
      "Epoch 8, Batch 15800: Loss = 0.5662, Accuracy = 0.6562\n",
      "Epoch 8, Batch 15900: Loss = 0.5269, Accuracy = 0.8125\n",
      "Epoch 8, Batch 16000: Loss = 0.6680, Accuracy = 0.6250\n",
      "Epoch 8, Batch 16100: Loss = 0.6309, Accuracy = 0.6562\n",
      "Epoch 8, Batch 16200: Loss = 0.5467, Accuracy = 0.8125\n",
      "Epoch 8, Batch 16300: Loss = 0.5810, Accuracy = 0.6875\n",
      "Epoch 8, Batch 16400: Loss = 0.5111, Accuracy = 0.8125\n",
      "Epoch 8, Batch 16500: Loss = 0.6697, Accuracy = 0.6562\n",
      "Epoch 8, Batch 16600: Loss = 0.5951, Accuracy = 0.6562\n",
      "Epoch 8, Batch 16700: Loss = 0.6361, Accuracy = 0.7500\n",
      "Epoch 8, Batch 16800: Loss = 0.5505, Accuracy = 0.7188\n",
      "Epoch 8, Batch 16900: Loss = 0.6868, Accuracy = 0.6250\n",
      "Epoch 8, Batch 17000: Loss = 0.6615, Accuracy = 0.6562\n",
      "Epoch 8, Batch 17100: Loss = 0.5727, Accuracy = 0.6875\n",
      "Epoch 8, Batch 17200: Loss = 0.5752, Accuracy = 0.7188\n",
      "Epoch 8, Batch 17300: Loss = 0.5787, Accuracy = 0.6875\n",
      "Epoch 8, Batch 17400: Loss = 0.5040, Accuracy = 0.7812\n",
      "Epoch 8, Batch 17500: Loss = 0.5889, Accuracy = 0.7500\n",
      "Epoch 8, Batch 17600: Loss = 0.7416, Accuracy = 0.6250\n",
      "Epoch 8, Batch 17700: Loss = 0.5386, Accuracy = 0.7500\n",
      "Epoch 8, Batch 17800: Loss = 0.6388, Accuracy = 0.6875\n",
      "Epoch 8, Batch 17900: Loss = 0.6338, Accuracy = 0.6875\n",
      "Epoch 8, Batch 18000: Loss = 0.5839, Accuracy = 0.6875\n",
      "Epoch 8, Batch 18100: Loss = 0.6615, Accuracy = 0.6250\n",
      "Epoch 8, Batch 18200: Loss = 0.5903, Accuracy = 0.6250\n",
      "Epoch 8, Batch 18300: Loss = 0.5717, Accuracy = 0.7188\n",
      "Epoch 8, Batch 18400: Loss = 0.6524, Accuracy = 0.5938\n",
      "Epoch 8, Batch 18500: Loss = 0.5302, Accuracy = 0.8125\n",
      "Epoch 8, Batch 18600: Loss = 0.5036, Accuracy = 0.8125\n",
      "Epoch 8, Batch 18700: Loss = 0.6547, Accuracy = 0.6250\n",
      "Epoch 8, Batch 18800: Loss = 0.4835, Accuracy = 0.8125\n",
      "Epoch 8, Batch 18900: Loss = 0.5770, Accuracy = 0.7188\n",
      "Epoch 8, Batch 19000: Loss = 0.5406, Accuracy = 0.7188\n",
      "Epoch 8, Batch 19100: Loss = 0.4700, Accuracy = 0.8125\n",
      "Epoch 8, Batch 19200: Loss = 0.5230, Accuracy = 0.7188\n",
      "Epoch 8, Batch 19300: Loss = 0.7507, Accuracy = 0.5938\n",
      "Epoch 8, Batch 19400: Loss = 0.6009, Accuracy = 0.7500\n",
      "Epoch 8, Batch 19500: Loss = 0.4307, Accuracy = 0.8125\n",
      "Epoch 8, Batch 19600: Loss = 0.5898, Accuracy = 0.7500\n",
      "Epoch 8, Batch 19700: Loss = 0.5031, Accuracy = 0.8438\n",
      "Epoch 8, Batch 19800: Loss = 0.6517, Accuracy = 0.5938\n",
      "Epoch 8, Batch 19900: Loss = 0.6625, Accuracy = 0.6250\n",
      "Epoch 8, Batch 20000: Loss = 0.5153, Accuracy = 0.7500\n",
      "Epoch 8, Batch 20100: Loss = 0.5641, Accuracy = 0.6875\n",
      "Epoch 8, Batch 20200: Loss = 0.5577, Accuracy = 0.8125\n",
      "Epoch 8, Batch 20300: Loss = 0.4915, Accuracy = 0.8125\n",
      "Epoch 8, Batch 20400: Loss = 0.6580, Accuracy = 0.6250\n",
      "Epoch 8, Batch 20500: Loss = 0.7154, Accuracy = 0.6250\n",
      "Epoch 8, Batch 20600: Loss = 0.5440, Accuracy = 0.7500\n",
      "Epoch 8, Batch 20700: Loss = 0.5888, Accuracy = 0.6562\n",
      "Epoch 8, Batch 20800: Loss = 0.5843, Accuracy = 0.7500\n",
      "Epoch 8, Batch 20900: Loss = 0.6946, Accuracy = 0.6875\n",
      "Epoch 8, Batch 21000: Loss = 0.5737, Accuracy = 0.7812\n",
      "Epoch 8, Batch 21100: Loss = 0.7094, Accuracy = 0.5938\n",
      "Epoch 8, Batch 21200: Loss = 0.7123, Accuracy = 0.6250\n",
      "Epoch 8, Batch 21300: Loss = 0.5761, Accuracy = 0.6562\n",
      "Epoch 8, Batch 21400: Loss = 0.4559, Accuracy = 0.7812\n",
      "Epoch 8, Batch 21500: Loss = 0.4851, Accuracy = 0.8125\n",
      "Epoch 8, Batch 21600: Loss = 0.6279, Accuracy = 0.7500\n",
      "Epoch 8, Batch 21700: Loss = 0.5757, Accuracy = 0.7188\n",
      "Epoch 8, Batch 21800: Loss = 0.5931, Accuracy = 0.8125\n",
      "Epoch 8: Train Loss = 0.5973, Train Accuracy = 0.7000, Time = 555.46s\n",
      "Validation Accuracy: 0.7022\n",
      "Epoch 9, Batch 100: Loss = 0.4316, Accuracy = 0.8438\n",
      "Epoch 9, Batch 200: Loss = 0.5863, Accuracy = 0.6562\n",
      "Epoch 9, Batch 300: Loss = 0.6129, Accuracy = 0.6875\n",
      "Epoch 9, Batch 400: Loss = 0.5925, Accuracy = 0.6562\n",
      "Epoch 9, Batch 500: Loss = 0.5922, Accuracy = 0.7500\n",
      "Epoch 9, Batch 600: Loss = 0.4765, Accuracy = 0.7188\n",
      "Epoch 9, Batch 700: Loss = 0.6742, Accuracy = 0.5938\n",
      "Epoch 9, Batch 800: Loss = 0.5554, Accuracy = 0.7188\n",
      "Epoch 9, Batch 900: Loss = 0.4418, Accuracy = 0.8125\n",
      "Epoch 9, Batch 1000: Loss = 0.5936, Accuracy = 0.6562\n",
      "Epoch 9, Batch 1100: Loss = 0.6954, Accuracy = 0.5625\n",
      "Epoch 9, Batch 1200: Loss = 0.6385, Accuracy = 0.5938\n",
      "Epoch 9, Batch 1300: Loss = 0.6192, Accuracy = 0.6562\n",
      "Epoch 9, Batch 1400: Loss = 0.5392, Accuracy = 0.7500\n",
      "Epoch 9, Batch 1500: Loss = 0.6705, Accuracy = 0.7188\n",
      "Epoch 9, Batch 1600: Loss = 0.6096, Accuracy = 0.6875\n",
      "Epoch 9, Batch 1700: Loss = 0.6261, Accuracy = 0.6875\n",
      "Epoch 9, Batch 1800: Loss = 0.7243, Accuracy = 0.5625\n",
      "Epoch 9, Batch 1900: Loss = 0.5917, Accuracy = 0.5625\n",
      "Epoch 9, Batch 2000: Loss = 0.6551, Accuracy = 0.6562\n",
      "Epoch 9, Batch 2100: Loss = 0.4720, Accuracy = 0.8438\n",
      "Epoch 9, Batch 2200: Loss = 0.6555, Accuracy = 0.6250\n",
      "Epoch 9, Batch 2300: Loss = 0.5659, Accuracy = 0.7500\n",
      "Epoch 9, Batch 2400: Loss = 0.5786, Accuracy = 0.6875\n",
      "Epoch 9, Batch 2500: Loss = 0.6534, Accuracy = 0.6562\n",
      "Epoch 9, Batch 2600: Loss = 0.7044, Accuracy = 0.5312\n",
      "Epoch 9, Batch 2700: Loss = 0.6485, Accuracy = 0.5938\n",
      "Epoch 9, Batch 2800: Loss = 0.7357, Accuracy = 0.6250\n",
      "Epoch 9, Batch 2900: Loss = 0.5326, Accuracy = 0.8438\n",
      "Epoch 9, Batch 3000: Loss = 0.5369, Accuracy = 0.7812\n",
      "Epoch 9, Batch 3100: Loss = 0.5524, Accuracy = 0.7500\n",
      "Epoch 9, Batch 3200: Loss = 0.6431, Accuracy = 0.6875\n",
      "Epoch 9, Batch 3300: Loss = 0.5552, Accuracy = 0.7188\n",
      "Epoch 9, Batch 3400: Loss = 0.5261, Accuracy = 0.7812\n",
      "Epoch 9, Batch 3500: Loss = 0.6337, Accuracy = 0.6875\n",
      "Epoch 9, Batch 3600: Loss = 0.6396, Accuracy = 0.6562\n",
      "Epoch 9, Batch 3700: Loss = 0.7011, Accuracy = 0.5625\n",
      "Epoch 9, Batch 3800: Loss = 0.7057, Accuracy = 0.5938\n",
      "Epoch 9, Batch 3900: Loss = 0.6309, Accuracy = 0.6875\n",
      "Epoch 9, Batch 4000: Loss = 0.4722, Accuracy = 0.8750\n",
      "Epoch 9, Batch 4100: Loss = 0.6861, Accuracy = 0.6562\n",
      "Epoch 9, Batch 4200: Loss = 0.5679, Accuracy = 0.7500\n",
      "Epoch 9, Batch 4300: Loss = 0.6500, Accuracy = 0.7500\n",
      "Epoch 9, Batch 4400: Loss = 0.7863, Accuracy = 0.5625\n",
      "Epoch 9, Batch 4500: Loss = 0.6807, Accuracy = 0.6250\n",
      "Epoch 9, Batch 4600: Loss = 0.5136, Accuracy = 0.8438\n",
      "Epoch 9, Batch 4700: Loss = 0.6166, Accuracy = 0.6562\n",
      "Epoch 9, Batch 4800: Loss = 0.4981, Accuracy = 0.7500\n",
      "Epoch 9, Batch 4900: Loss = 0.4496, Accuracy = 0.8125\n",
      "Epoch 9, Batch 5000: Loss = 0.5470, Accuracy = 0.8125\n",
      "Epoch 9, Batch 5100: Loss = 0.6541, Accuracy = 0.6562\n",
      "Epoch 9, Batch 5200: Loss = 0.6251, Accuracy = 0.6562\n",
      "Epoch 9, Batch 5300: Loss = 0.5805, Accuracy = 0.7812\n",
      "Epoch 9, Batch 5400: Loss = 0.6107, Accuracy = 0.7188\n",
      "Epoch 9, Batch 5500: Loss = 0.6372, Accuracy = 0.7188\n",
      "Epoch 9, Batch 5600: Loss = 0.4821, Accuracy = 0.8750\n",
      "Epoch 9, Batch 5700: Loss = 0.6592, Accuracy = 0.5625\n",
      "Epoch 9, Batch 5800: Loss = 0.6760, Accuracy = 0.5000\n",
      "Epoch 9, Batch 5900: Loss = 0.6442, Accuracy = 0.6250\n",
      "Epoch 9, Batch 6000: Loss = 0.5203, Accuracy = 0.7812\n",
      "Epoch 9, Batch 6100: Loss = 0.5315, Accuracy = 0.8438\n",
      "Epoch 9, Batch 6200: Loss = 0.5264, Accuracy = 0.7188\n",
      "Epoch 9, Batch 6300: Loss = 0.5513, Accuracy = 0.6562\n",
      "Epoch 9, Batch 6400: Loss = 0.5861, Accuracy = 0.7188\n",
      "Epoch 9, Batch 6500: Loss = 0.6557, Accuracy = 0.5625\n",
      "Epoch 9, Batch 6600: Loss = 0.6097, Accuracy = 0.6875\n",
      "Epoch 9, Batch 6700: Loss = 0.5175, Accuracy = 0.6562\n",
      "Epoch 9, Batch 6800: Loss = 0.6635, Accuracy = 0.5625\n",
      "Epoch 9, Batch 6900: Loss = 0.6819, Accuracy = 0.5938\n",
      "Epoch 9, Batch 7000: Loss = 0.6141, Accuracy = 0.7188\n",
      "Epoch 9, Batch 7100: Loss = 0.7310, Accuracy = 0.6562\n",
      "Epoch 9, Batch 7200: Loss = 0.6839, Accuracy = 0.6250\n",
      "Epoch 9, Batch 7300: Loss = 0.5720, Accuracy = 0.7500\n",
      "Epoch 9, Batch 7400: Loss = 0.6066, Accuracy = 0.7500\n",
      "Epoch 9, Batch 7500: Loss = 0.5430, Accuracy = 0.7812\n",
      "Epoch 9, Batch 7600: Loss = 0.5337, Accuracy = 0.7188\n",
      "Epoch 9, Batch 7700: Loss = 0.5715, Accuracy = 0.7188\n",
      "Epoch 9, Batch 7800: Loss = 0.6203, Accuracy = 0.7188\n",
      "Epoch 9, Batch 7900: Loss = 0.6595, Accuracy = 0.6875\n",
      "Epoch 9, Batch 8000: Loss = 0.7022, Accuracy = 0.6250\n",
      "Epoch 9, Batch 8100: Loss = 0.8736, Accuracy = 0.5625\n",
      "Epoch 9, Batch 8200: Loss = 0.6279, Accuracy = 0.5938\n",
      "Epoch 9, Batch 8300: Loss = 0.7210, Accuracy = 0.6250\n",
      "Epoch 9, Batch 8400: Loss = 0.7003, Accuracy = 0.7188\n",
      "Epoch 9, Batch 8500: Loss = 0.4899, Accuracy = 0.7812\n",
      "Epoch 9, Batch 8600: Loss = 0.5983, Accuracy = 0.7500\n",
      "Epoch 9, Batch 8700: Loss = 0.5180, Accuracy = 0.7188\n",
      "Epoch 9, Batch 8800: Loss = 0.5437, Accuracy = 0.7500\n",
      "Epoch 9, Batch 8900: Loss = 0.7423, Accuracy = 0.5000\n",
      "Epoch 9, Batch 9000: Loss = 0.5744, Accuracy = 0.7188\n",
      "Epoch 9, Batch 9100: Loss = 0.6809, Accuracy = 0.6875\n",
      "Epoch 9, Batch 9200: Loss = 0.5671, Accuracy = 0.7188\n",
      "Epoch 9, Batch 9300: Loss = 0.5548, Accuracy = 0.7500\n",
      "Epoch 9, Batch 9400: Loss = 0.6505, Accuracy = 0.6562\n",
      "Epoch 9, Batch 9500: Loss = 0.6232, Accuracy = 0.6875\n",
      "Epoch 9, Batch 9600: Loss = 0.6427, Accuracy = 0.5938\n",
      "Epoch 9, Batch 9700: Loss = 0.6614, Accuracy = 0.6250\n",
      "Epoch 9, Batch 9800: Loss = 0.6010, Accuracy = 0.6875\n",
      "Epoch 9, Batch 9900: Loss = 0.7129, Accuracy = 0.6250\n",
      "Epoch 9, Batch 10000: Loss = 0.7447, Accuracy = 0.5000\n",
      "Epoch 9, Batch 10100: Loss = 0.5754, Accuracy = 0.7188\n",
      "Epoch 9, Batch 10200: Loss = 0.5703, Accuracy = 0.7188\n",
      "Epoch 9, Batch 10300: Loss = 0.5194, Accuracy = 0.7812\n",
      "Epoch 9, Batch 10400: Loss = 0.5247, Accuracy = 0.8438\n",
      "Epoch 9, Batch 10500: Loss = 0.5892, Accuracy = 0.6562\n",
      "Epoch 9, Batch 10600: Loss = 0.6602, Accuracy = 0.5625\n",
      "Epoch 9, Batch 10700: Loss = 0.5184, Accuracy = 0.7812\n",
      "Epoch 9, Batch 10800: Loss = 0.7866, Accuracy = 0.5312\n",
      "Epoch 9, Batch 10900: Loss = 0.5560, Accuracy = 0.7500\n",
      "Epoch 9, Batch 11000: Loss = 0.5113, Accuracy = 0.7500\n",
      "Epoch 9, Batch 11100: Loss = 0.6221, Accuracy = 0.7188\n",
      "Epoch 9, Batch 11200: Loss = 0.5654, Accuracy = 0.7812\n",
      "Epoch 9, Batch 11300: Loss = 0.5449, Accuracy = 0.6875\n",
      "Epoch 9, Batch 11400: Loss = 0.4072, Accuracy = 0.9062\n",
      "Epoch 9, Batch 11500: Loss = 0.6123, Accuracy = 0.7188\n",
      "Epoch 9, Batch 11600: Loss = 0.5948, Accuracy = 0.6562\n",
      "Epoch 9, Batch 11700: Loss = 0.6632, Accuracy = 0.6562\n",
      "Epoch 9, Batch 11800: Loss = 0.5408, Accuracy = 0.7188\n",
      "Epoch 9, Batch 11900: Loss = 0.6478, Accuracy = 0.7500\n",
      "Epoch 9, Batch 12000: Loss = 0.5899, Accuracy = 0.7188\n",
      "Epoch 9, Batch 12100: Loss = 0.4982, Accuracy = 0.7812\n",
      "Epoch 9, Batch 12200: Loss = 0.6084, Accuracy = 0.6562\n",
      "Epoch 9, Batch 12300: Loss = 0.4757, Accuracy = 0.8750\n",
      "Epoch 9, Batch 12400: Loss = 0.4467, Accuracy = 0.8125\n",
      "Epoch 9, Batch 12500: Loss = 0.4979, Accuracy = 0.7812\n",
      "Epoch 9, Batch 12600: Loss = 0.6787, Accuracy = 0.6250\n",
      "Epoch 9, Batch 12700: Loss = 0.5585, Accuracy = 0.7500\n",
      "Epoch 9, Batch 12800: Loss = 0.6037, Accuracy = 0.7188\n",
      "Epoch 9, Batch 12900: Loss = 0.5182, Accuracy = 0.8125\n",
      "Epoch 9, Batch 13000: Loss = 0.5815, Accuracy = 0.6562\n",
      "Epoch 9, Batch 13100: Loss = 0.5387, Accuracy = 0.7812\n",
      "Epoch 9, Batch 13200: Loss = 0.5520, Accuracy = 0.7500\n",
      "Epoch 9, Batch 13300: Loss = 0.6069, Accuracy = 0.7500\n",
      "Epoch 9, Batch 13400: Loss = 0.5379, Accuracy = 0.7812\n",
      "Epoch 9, Batch 13500: Loss = 0.6783, Accuracy = 0.6875\n",
      "Epoch 9, Batch 13600: Loss = 0.6922, Accuracy = 0.5938\n",
      "Epoch 9, Batch 13700: Loss = 0.6107, Accuracy = 0.7188\n",
      "Epoch 9, Batch 13800: Loss = 0.6513, Accuracy = 0.6562\n",
      "Epoch 9, Batch 13900: Loss = 0.5743, Accuracy = 0.7500\n",
      "Epoch 9, Batch 14000: Loss = 0.5313, Accuracy = 0.7188\n",
      "Epoch 9, Batch 14100: Loss = 0.4726, Accuracy = 0.8750\n",
      "Epoch 9, Batch 14200: Loss = 0.5455, Accuracy = 0.6875\n",
      "Epoch 9, Batch 14300: Loss = 0.5813, Accuracy = 0.7500\n",
      "Epoch 9, Batch 14400: Loss = 0.6062, Accuracy = 0.6562\n",
      "Epoch 9, Batch 14500: Loss = 0.5903, Accuracy = 0.6875\n",
      "Epoch 9, Batch 14600: Loss = 0.5269, Accuracy = 0.7500\n",
      "Epoch 9, Batch 14700: Loss = 0.5086, Accuracy = 0.7812\n",
      "Epoch 9, Batch 14800: Loss = 0.5038, Accuracy = 0.7500\n",
      "Epoch 9, Batch 14900: Loss = 0.7373, Accuracy = 0.6875\n",
      "Epoch 9, Batch 15000: Loss = 0.6701, Accuracy = 0.6562\n",
      "Epoch 9, Batch 15100: Loss = 0.5221, Accuracy = 0.8750\n",
      "Epoch 9, Batch 15200: Loss = 0.5525, Accuracy = 0.7812\n",
      "Epoch 9, Batch 15300: Loss = 0.5682, Accuracy = 0.6562\n",
      "Epoch 9, Batch 15400: Loss = 0.5657, Accuracy = 0.7812\n",
      "Epoch 9, Batch 15500: Loss = 0.4935, Accuracy = 0.8438\n",
      "Epoch 9, Batch 15600: Loss = 0.5428, Accuracy = 0.6875\n",
      "Epoch 9, Batch 15700: Loss = 0.6530, Accuracy = 0.7188\n",
      "Epoch 9, Batch 15800: Loss = 0.5343, Accuracy = 0.7500\n",
      "Epoch 9, Batch 15900: Loss = 0.6387, Accuracy = 0.6562\n",
      "Epoch 9, Batch 16000: Loss = 0.5542, Accuracy = 0.6875\n",
      "Epoch 9, Batch 16100: Loss = 0.7353, Accuracy = 0.6250\n",
      "Epoch 9, Batch 16200: Loss = 0.5564, Accuracy = 0.6875\n",
      "Epoch 9, Batch 16300: Loss = 0.6558, Accuracy = 0.7188\n",
      "Epoch 9, Batch 16400: Loss = 0.6601, Accuracy = 0.6250\n",
      "Epoch 9, Batch 16500: Loss = 0.6706, Accuracy = 0.5938\n",
      "Epoch 9, Batch 16600: Loss = 0.6896, Accuracy = 0.6562\n",
      "Epoch 9, Batch 16700: Loss = 0.6858, Accuracy = 0.6250\n",
      "Epoch 9, Batch 16800: Loss = 0.5512, Accuracy = 0.7500\n",
      "Epoch 9, Batch 16900: Loss = 0.6606, Accuracy = 0.7188\n",
      "Epoch 9, Batch 17000: Loss = 0.5662, Accuracy = 0.8125\n",
      "Epoch 9, Batch 17100: Loss = 0.5263, Accuracy = 0.8125\n",
      "Epoch 9, Batch 17200: Loss = 0.4732, Accuracy = 0.8750\n",
      "Epoch 9, Batch 17300: Loss = 0.6767, Accuracy = 0.5938\n",
      "Epoch 9, Batch 17400: Loss = 0.7138, Accuracy = 0.6562\n",
      "Epoch 9, Batch 17500: Loss = 0.6018, Accuracy = 0.6875\n",
      "Epoch 9, Batch 17600: Loss = 0.7244, Accuracy = 0.6875\n",
      "Epoch 9, Batch 17700: Loss = 0.5245, Accuracy = 0.7500\n",
      "Epoch 9, Batch 17800: Loss = 0.7029, Accuracy = 0.6562\n",
      "Epoch 9, Batch 17900: Loss = 0.6024, Accuracy = 0.6875\n",
      "Epoch 9, Batch 18000: Loss = 0.5877, Accuracy = 0.7812\n",
      "Epoch 9, Batch 18100: Loss = 0.5925, Accuracy = 0.6875\n",
      "Epoch 9, Batch 18200: Loss = 0.4918, Accuracy = 0.8438\n",
      "Epoch 9, Batch 18300: Loss = 0.7210, Accuracy = 0.5938\n",
      "Epoch 9, Batch 18400: Loss = 0.5251, Accuracy = 0.7500\n",
      "Epoch 9, Batch 18500: Loss = 0.7211, Accuracy = 0.5625\n",
      "Epoch 9, Batch 18600: Loss = 0.5585, Accuracy = 0.6250\n",
      "Epoch 9, Batch 18700: Loss = 0.5637, Accuracy = 0.6875\n",
      "Epoch 9, Batch 18800: Loss = 0.6737, Accuracy = 0.6875\n",
      "Epoch 9, Batch 18900: Loss = 0.5923, Accuracy = 0.6250\n",
      "Epoch 9, Batch 19000: Loss = 0.5553, Accuracy = 0.7812\n",
      "Epoch 9, Batch 19100: Loss = 0.5998, Accuracy = 0.6562\n",
      "Epoch 9, Batch 19200: Loss = 0.8724, Accuracy = 0.4375\n",
      "Epoch 9, Batch 19300: Loss = 0.5491, Accuracy = 0.7188\n",
      "Epoch 9, Batch 19400: Loss = 0.5697, Accuracy = 0.7188\n",
      "Epoch 9, Batch 19500: Loss = 0.5704, Accuracy = 0.6875\n",
      "Epoch 9, Batch 19600: Loss = 0.7038, Accuracy = 0.6562\n",
      "Epoch 9, Batch 19700: Loss = 0.5793, Accuracy = 0.7500\n",
      "Epoch 9, Batch 19800: Loss = 0.7438, Accuracy = 0.5625\n",
      "Epoch 9, Batch 19900: Loss = 0.5472, Accuracy = 0.8125\n",
      "Epoch 9, Batch 20000: Loss = 0.6583, Accuracy = 0.6562\n",
      "Epoch 9, Batch 20100: Loss = 0.7564, Accuracy = 0.4375\n",
      "Epoch 9, Batch 20200: Loss = 0.5991, Accuracy = 0.7812\n",
      "Epoch 9, Batch 20300: Loss = 0.6376, Accuracy = 0.6875\n",
      "Epoch 9, Batch 20400: Loss = 0.6184, Accuracy = 0.6875\n",
      "Epoch 9, Batch 20500: Loss = 0.6204, Accuracy = 0.5938\n",
      "Epoch 9, Batch 20600: Loss = 0.5794, Accuracy = 0.6875\n",
      "Epoch 9, Batch 20700: Loss = 0.5180, Accuracy = 0.7812\n",
      "Epoch 9, Batch 20800: Loss = 0.6240, Accuracy = 0.7188\n",
      "Epoch 9, Batch 20900: Loss = 0.5978, Accuracy = 0.6875\n",
      "Epoch 9, Batch 21000: Loss = 0.4749, Accuracy = 0.8125\n",
      "Epoch 9, Batch 21100: Loss = 0.5903, Accuracy = 0.7188\n",
      "Epoch 9, Batch 21200: Loss = 0.5893, Accuracy = 0.6562\n",
      "Epoch 9, Batch 21300: Loss = 0.8363, Accuracy = 0.5000\n",
      "Epoch 9, Batch 21400: Loss = 0.6729, Accuracy = 0.7188\n",
      "Epoch 9, Batch 21500: Loss = 0.6092, Accuracy = 0.6875\n",
      "Epoch 9, Batch 21600: Loss = 0.6311, Accuracy = 0.6250\n",
      "Epoch 9, Batch 21700: Loss = 0.7701, Accuracy = 0.5312\n",
      "Epoch 9, Batch 21800: Loss = 0.5523, Accuracy = 0.7812\n",
      "Epoch 9: Train Loss = 0.5971, Train Accuracy = 0.7001, Time = 517.86s\n",
      "Validation Accuracy: 0.7057\n",
      "Epoch 10, Batch 100: Loss = 0.4870, Accuracy = 0.7812\n",
      "Epoch 10, Batch 200: Loss = 0.6957, Accuracy = 0.6562\n",
      "Epoch 10, Batch 300: Loss = 0.6089, Accuracy = 0.6875\n",
      "Epoch 10, Batch 400: Loss = 0.5807, Accuracy = 0.7188\n",
      "Epoch 10, Batch 500: Loss = 0.5171, Accuracy = 0.8125\n",
      "Epoch 10, Batch 600: Loss = 0.6553, Accuracy = 0.6250\n",
      "Epoch 10, Batch 700: Loss = 0.5527, Accuracy = 0.7188\n",
      "Epoch 10, Batch 800: Loss = 0.5712, Accuracy = 0.6875\n",
      "Epoch 10, Batch 900: Loss = 0.5969, Accuracy = 0.6562\n",
      "Epoch 10, Batch 1000: Loss = 0.6672, Accuracy = 0.6562\n",
      "Epoch 10, Batch 1100: Loss = 0.5739, Accuracy = 0.6250\n",
      "Epoch 10, Batch 1200: Loss = 0.5768, Accuracy = 0.7500\n",
      "Epoch 10, Batch 1300: Loss = 0.5735, Accuracy = 0.6875\n",
      "Epoch 10, Batch 1400: Loss = 0.5684, Accuracy = 0.7500\n",
      "Epoch 10, Batch 1500: Loss = 0.6211, Accuracy = 0.6562\n",
      "Epoch 10, Batch 1600: Loss = 0.5011, Accuracy = 0.8438\n",
      "Epoch 10, Batch 1700: Loss = 0.5119, Accuracy = 0.8125\n",
      "Epoch 10, Batch 1800: Loss = 0.4735, Accuracy = 0.8125\n",
      "Epoch 10, Batch 1900: Loss = 0.5312, Accuracy = 0.6562\n",
      "Epoch 10, Batch 2000: Loss = 0.5865, Accuracy = 0.7812\n",
      "Epoch 10, Batch 2100: Loss = 0.5390, Accuracy = 0.7188\n",
      "Epoch 10, Batch 2200: Loss = 0.6379, Accuracy = 0.6562\n",
      "Epoch 10, Batch 2300: Loss = 0.5321, Accuracy = 0.7500\n",
      "Epoch 10, Batch 2400: Loss = 0.6816, Accuracy = 0.5938\n",
      "Epoch 10, Batch 2500: Loss = 0.5815, Accuracy = 0.7188\n",
      "Epoch 10, Batch 2600: Loss = 0.5864, Accuracy = 0.6875\n",
      "Epoch 10, Batch 2700: Loss = 0.6139, Accuracy = 0.6562\n",
      "Epoch 10, Batch 2800: Loss = 0.5230, Accuracy = 0.7500\n",
      "Epoch 10, Batch 2900: Loss = 0.6889, Accuracy = 0.6250\n",
      "Epoch 10, Batch 3000: Loss = 0.6477, Accuracy = 0.5938\n",
      "Epoch 10, Batch 3100: Loss = 0.6005, Accuracy = 0.6875\n",
      "Epoch 10, Batch 3200: Loss = 0.5610, Accuracy = 0.7188\n",
      "Epoch 10, Batch 3300: Loss = 0.6497, Accuracy = 0.6875\n",
      "Epoch 10, Batch 3400: Loss = 0.6341, Accuracy = 0.5938\n",
      "Epoch 10, Batch 3500: Loss = 0.5988, Accuracy = 0.7812\n",
      "Epoch 10, Batch 3600: Loss = 0.6560, Accuracy = 0.6562\n",
      "Epoch 10, Batch 3700: Loss = 0.8086, Accuracy = 0.5625\n",
      "Epoch 10, Batch 3800: Loss = 0.5289, Accuracy = 0.7188\n",
      "Epoch 10, Batch 3900: Loss = 0.6494, Accuracy = 0.6875\n",
      "Epoch 10, Batch 4000: Loss = 0.5252, Accuracy = 0.8125\n",
      "Epoch 10, Batch 4100: Loss = 0.5848, Accuracy = 0.7188\n",
      "Epoch 10, Batch 4200: Loss = 0.6688, Accuracy = 0.6562\n",
      "Epoch 10, Batch 4300: Loss = 0.5343, Accuracy = 0.7188\n",
      "Epoch 10, Batch 4400: Loss = 0.6564, Accuracy = 0.5938\n",
      "Epoch 10, Batch 4500: Loss = 0.5058, Accuracy = 0.8438\n",
      "Epoch 10, Batch 4600: Loss = 0.4914, Accuracy = 0.8438\n",
      "Epoch 10, Batch 4700: Loss = 0.6179, Accuracy = 0.5938\n",
      "Epoch 10, Batch 4800: Loss = 0.5459, Accuracy = 0.7188\n",
      "Epoch 10, Batch 4900: Loss = 0.6849, Accuracy = 0.5938\n",
      "Epoch 10, Batch 5000: Loss = 0.5785, Accuracy = 0.6875\n",
      "Epoch 10, Batch 5100: Loss = 0.7556, Accuracy = 0.6250\n",
      "Epoch 10, Batch 5200: Loss = 0.5562, Accuracy = 0.7500\n",
      "Epoch 10, Batch 5300: Loss = 0.8163, Accuracy = 0.5938\n",
      "Epoch 10, Batch 5400: Loss = 0.5434, Accuracy = 0.7188\n",
      "Epoch 10, Batch 5500: Loss = 0.6527, Accuracy = 0.6562\n",
      "Epoch 10, Batch 5600: Loss = 0.6598, Accuracy = 0.5938\n",
      "Epoch 10, Batch 5700: Loss = 0.4707, Accuracy = 0.8438\n",
      "Epoch 10, Batch 5800: Loss = 0.5831, Accuracy = 0.7188\n",
      "Epoch 10, Batch 5900: Loss = 0.5483, Accuracy = 0.6875\n",
      "Epoch 10, Batch 6000: Loss = 0.7534, Accuracy = 0.6250\n",
      "Epoch 10, Batch 6100: Loss = 0.6910, Accuracy = 0.6875\n",
      "Epoch 10, Batch 6200: Loss = 0.5249, Accuracy = 0.7500\n",
      "Epoch 10, Batch 6300: Loss = 0.6096, Accuracy = 0.7188\n",
      "Epoch 10, Batch 6400: Loss = 0.6374, Accuracy = 0.5938\n",
      "Epoch 10, Batch 6500: Loss = 0.5359, Accuracy = 0.7500\n",
      "Epoch 10, Batch 6600: Loss = 0.7661, Accuracy = 0.5938\n",
      "Epoch 10, Batch 6700: Loss = 0.6204, Accuracy = 0.6875\n",
      "Epoch 10, Batch 6800: Loss = 0.5468, Accuracy = 0.6875\n",
      "Epoch 10, Batch 6900: Loss = 0.5885, Accuracy = 0.6562\n",
      "Epoch 10, Batch 7000: Loss = 0.5185, Accuracy = 0.7812\n",
      "Epoch 10, Batch 7100: Loss = 0.5371, Accuracy = 0.7188\n",
      "Epoch 10, Batch 7200: Loss = 0.6046, Accuracy = 0.6562\n",
      "Epoch 10, Batch 7300: Loss = 0.4137, Accuracy = 0.9062\n",
      "Epoch 10, Batch 7400: Loss = 0.6510, Accuracy = 0.6562\n",
      "Epoch 10, Batch 7500: Loss = 0.5580, Accuracy = 0.7500\n",
      "Epoch 10, Batch 7600: Loss = 0.5539, Accuracy = 0.7812\n",
      "Epoch 10, Batch 7700: Loss = 0.6288, Accuracy = 0.7500\n",
      "Epoch 10, Batch 7800: Loss = 0.5177, Accuracy = 0.7188\n",
      "Epoch 10, Batch 7900: Loss = 0.5697, Accuracy = 0.8125\n",
      "Epoch 10, Batch 8000: Loss = 0.4548, Accuracy = 0.9062\n",
      "Epoch 10, Batch 8100: Loss = 0.7035, Accuracy = 0.6250\n",
      "Epoch 10, Batch 8200: Loss = 0.4261, Accuracy = 0.8438\n",
      "Epoch 10, Batch 8300: Loss = 0.6457, Accuracy = 0.6562\n",
      "Epoch 10, Batch 8400: Loss = 0.4945, Accuracy = 0.8750\n",
      "Epoch 10, Batch 8500: Loss = 0.4821, Accuracy = 0.7812\n",
      "Epoch 10, Batch 8600: Loss = 0.6738, Accuracy = 0.5625\n",
      "Epoch 10, Batch 8700: Loss = 0.6744, Accuracy = 0.6562\n",
      "Epoch 10, Batch 8800: Loss = 0.5888, Accuracy = 0.6875\n",
      "Epoch 10, Batch 8900: Loss = 0.6273, Accuracy = 0.6250\n",
      "Epoch 10, Batch 9000: Loss = 0.6197, Accuracy = 0.6562\n",
      "Epoch 10, Batch 9100: Loss = 0.4491, Accuracy = 0.8750\n",
      "Epoch 10, Batch 9200: Loss = 0.5664, Accuracy = 0.8125\n",
      "Epoch 10, Batch 9300: Loss = 0.6350, Accuracy = 0.6250\n",
      "Epoch 10, Batch 9400: Loss = 0.5806, Accuracy = 0.6875\n",
      "Epoch 10, Batch 9500: Loss = 0.4752, Accuracy = 0.8438\n",
      "Epoch 10, Batch 9600: Loss = 0.6032, Accuracy = 0.6562\n",
      "Epoch 10, Batch 9700: Loss = 0.5824, Accuracy = 0.7812\n",
      "Epoch 10, Batch 9800: Loss = 0.5673, Accuracy = 0.7812\n",
      "Epoch 10, Batch 9900: Loss = 0.5875, Accuracy = 0.6562\n",
      "Epoch 10, Batch 10000: Loss = 0.7544, Accuracy = 0.5312\n",
      "Epoch 10, Batch 10100: Loss = 0.6221, Accuracy = 0.6562\n",
      "Epoch 10, Batch 10200: Loss = 0.5518, Accuracy = 0.7188\n",
      "Epoch 10, Batch 10300: Loss = 0.5551, Accuracy = 0.7188\n",
      "Epoch 10, Batch 10400: Loss = 0.6034, Accuracy = 0.6562\n",
      "Epoch 10, Batch 10500: Loss = 0.6944, Accuracy = 0.6875\n",
      "Epoch 10, Batch 10600: Loss = 0.6197, Accuracy = 0.6562\n",
      "Epoch 10, Batch 10700: Loss = 0.6040, Accuracy = 0.6875\n",
      "Epoch 10, Batch 10800: Loss = 0.5561, Accuracy = 0.6875\n",
      "Epoch 10, Batch 10900: Loss = 0.5568, Accuracy = 0.6875\n",
      "Epoch 10, Batch 11000: Loss = 0.6056, Accuracy = 0.8125\n",
      "Epoch 10, Batch 11100: Loss = 0.5229, Accuracy = 0.7812\n",
      "Epoch 10, Batch 11200: Loss = 0.6818, Accuracy = 0.6875\n",
      "Epoch 10, Batch 11300: Loss = 0.5547, Accuracy = 0.7812\n",
      "Epoch 10, Batch 11400: Loss = 0.6431, Accuracy = 0.6875\n",
      "Epoch 10, Batch 11500: Loss = 0.6203, Accuracy = 0.6875\n",
      "Epoch 10, Batch 11600: Loss = 0.5821, Accuracy = 0.6562\n",
      "Epoch 10, Batch 11700: Loss = 0.5374, Accuracy = 0.7188\n",
      "Epoch 10, Batch 11800: Loss = 0.4960, Accuracy = 0.8125\n",
      "Epoch 10, Batch 11900: Loss = 0.5962, Accuracy = 0.6875\n",
      "Epoch 10, Batch 12000: Loss = 0.6212, Accuracy = 0.7812\n",
      "Epoch 10, Batch 12100: Loss = 0.6757, Accuracy = 0.5938\n",
      "Epoch 10, Batch 12200: Loss = 0.5499, Accuracy = 0.7500\n",
      "Epoch 10, Batch 12300: Loss = 0.7044, Accuracy = 0.6562\n",
      "Epoch 10, Batch 12400: Loss = 0.6880, Accuracy = 0.6562\n",
      "Epoch 10, Batch 12500: Loss = 0.5973, Accuracy = 0.7812\n",
      "Epoch 10, Batch 12600: Loss = 0.6312, Accuracy = 0.5938\n",
      "Epoch 10, Batch 12700: Loss = 0.6320, Accuracy = 0.5625\n",
      "Epoch 10, Batch 12800: Loss = 0.5382, Accuracy = 0.7500\n",
      "Epoch 10, Batch 12900: Loss = 0.4289, Accuracy = 0.8125\n",
      "Epoch 10, Batch 13000: Loss = 0.5224, Accuracy = 0.8125\n",
      "Epoch 10, Batch 13100: Loss = 0.5701, Accuracy = 0.6875\n",
      "Epoch 10, Batch 13200: Loss = 0.5032, Accuracy = 0.8125\n",
      "Epoch 10, Batch 13300: Loss = 0.5001, Accuracy = 0.7500\n",
      "Epoch 10, Batch 13400: Loss = 0.6229, Accuracy = 0.7188\n",
      "Epoch 10, Batch 13500: Loss = 0.6050, Accuracy = 0.6875\n",
      "Epoch 10, Batch 13600: Loss = 0.6674, Accuracy = 0.6250\n",
      "Epoch 10, Batch 13700: Loss = 0.5519, Accuracy = 0.6875\n",
      "Epoch 10, Batch 13800: Loss = 0.6383, Accuracy = 0.6875\n",
      "Epoch 10, Batch 13900: Loss = 0.5296, Accuracy = 0.7500\n",
      "Epoch 10, Batch 14000: Loss = 0.5509, Accuracy = 0.7188\n",
      "Epoch 10, Batch 14100: Loss = 0.4530, Accuracy = 0.8125\n",
      "Epoch 10, Batch 14200: Loss = 0.7430, Accuracy = 0.6875\n",
      "Epoch 10, Batch 14300: Loss = 0.6544, Accuracy = 0.5938\n",
      "Epoch 10, Batch 14400: Loss = 0.5698, Accuracy = 0.7812\n",
      "Epoch 10, Batch 14500: Loss = 0.6423, Accuracy = 0.6562\n",
      "Epoch 10, Batch 14600: Loss = 0.6145, Accuracy = 0.5938\n",
      "Epoch 10, Batch 14700: Loss = 0.7128, Accuracy = 0.5938\n",
      "Epoch 10, Batch 14800: Loss = 0.6995, Accuracy = 0.6250\n",
      "Epoch 10, Batch 14900: Loss = 0.5825, Accuracy = 0.8750\n",
      "Epoch 10, Batch 15000: Loss = 0.4388, Accuracy = 0.8125\n",
      "Epoch 10, Batch 15100: Loss = 0.5950, Accuracy = 0.5625\n",
      "Epoch 10, Batch 15200: Loss = 0.4998, Accuracy = 0.7500\n",
      "Epoch 10, Batch 15300: Loss = 0.7313, Accuracy = 0.5312\n",
      "Epoch 10, Batch 15400: Loss = 0.5415, Accuracy = 0.7812\n",
      "Epoch 10, Batch 15500: Loss = 0.6582, Accuracy = 0.6250\n",
      "Epoch 10, Batch 15600: Loss = 0.5162, Accuracy = 0.8125\n",
      "Epoch 10, Batch 15700: Loss = 0.5729, Accuracy = 0.6875\n",
      "Epoch 10, Batch 15800: Loss = 0.4427, Accuracy = 0.8750\n",
      "Epoch 10, Batch 15900: Loss = 0.6640, Accuracy = 0.6562\n",
      "Epoch 10, Batch 16000: Loss = 0.4693, Accuracy = 0.8438\n",
      "Epoch 10, Batch 16100: Loss = 0.5802, Accuracy = 0.7188\n",
      "Epoch 10, Batch 16200: Loss = 0.6384, Accuracy = 0.6562\n",
      "Epoch 10, Batch 16300: Loss = 0.5969, Accuracy = 0.6250\n",
      "Epoch 10, Batch 16400: Loss = 0.6984, Accuracy = 0.6250\n",
      "Epoch 10, Batch 16500: Loss = 0.4949, Accuracy = 0.7812\n",
      "Epoch 10, Batch 16600: Loss = 0.5669, Accuracy = 0.6875\n",
      "Epoch 10, Batch 16700: Loss = 0.5702, Accuracy = 0.7188\n",
      "Epoch 10, Batch 16800: Loss = 0.5532, Accuracy = 0.7188\n",
      "Epoch 10, Batch 16900: Loss = 0.5519, Accuracy = 0.7812\n",
      "Epoch 10, Batch 17000: Loss = 0.5774, Accuracy = 0.7500\n",
      "Epoch 10, Batch 17100: Loss = 0.6133, Accuracy = 0.6250\n",
      "Epoch 10, Batch 17200: Loss = 0.6335, Accuracy = 0.6250\n",
      "Epoch 10, Batch 17300: Loss = 0.6606, Accuracy = 0.5938\n",
      "Epoch 10, Batch 17400: Loss = 0.6455, Accuracy = 0.7500\n",
      "Epoch 10, Batch 17500: Loss = 0.5423, Accuracy = 0.7812\n",
      "Epoch 10, Batch 17600: Loss = 0.6131, Accuracy = 0.7188\n",
      "Epoch 10, Batch 17700: Loss = 0.5215, Accuracy = 0.7812\n",
      "Epoch 10, Batch 17800: Loss = 0.5849, Accuracy = 0.7500\n",
      "Epoch 10, Batch 17900: Loss = 0.5731, Accuracy = 0.8125\n",
      "Epoch 10, Batch 18000: Loss = 0.4692, Accuracy = 0.8438\n",
      "Epoch 10, Batch 18100: Loss = 0.5748, Accuracy = 0.6875\n",
      "Epoch 10, Batch 18200: Loss = 0.6383, Accuracy = 0.6875\n",
      "Epoch 10, Batch 18300: Loss = 0.5338, Accuracy = 0.8125\n",
      "Epoch 10, Batch 18400: Loss = 0.4810, Accuracy = 0.7812\n",
      "Epoch 10, Batch 18500: Loss = 0.6686, Accuracy = 0.7188\n",
      "Epoch 10, Batch 18600: Loss = 0.7824, Accuracy = 0.5312\n",
      "Epoch 10, Batch 18700: Loss = 0.6610, Accuracy = 0.6562\n",
      "Epoch 10, Batch 18800: Loss = 0.5714, Accuracy = 0.7500\n",
      "Epoch 10, Batch 18900: Loss = 0.5560, Accuracy = 0.7188\n",
      "Epoch 10, Batch 19000: Loss = 0.5474, Accuracy = 0.7500\n",
      "Epoch 10, Batch 19100: Loss = 0.6384, Accuracy = 0.6875\n",
      "Epoch 10, Batch 19200: Loss = 0.4475, Accuracy = 0.8125\n",
      "Epoch 10, Batch 19300: Loss = 0.5011, Accuracy = 0.7500\n",
      "Epoch 10, Batch 19400: Loss = 0.6252, Accuracy = 0.6562\n",
      "Epoch 10, Batch 19500: Loss = 0.6327, Accuracy = 0.6562\n",
      "Epoch 10, Batch 19600: Loss = 0.5418, Accuracy = 0.6562\n",
      "Epoch 10, Batch 19700: Loss = 0.7843, Accuracy = 0.5312\n",
      "Epoch 10, Batch 19800: Loss = 0.6515, Accuracy = 0.6562\n",
      "Epoch 10, Batch 19900: Loss = 0.5567, Accuracy = 0.7500\n",
      "Epoch 10, Batch 20000: Loss = 0.5624, Accuracy = 0.7188\n",
      "Epoch 10, Batch 20100: Loss = 0.5379, Accuracy = 0.7812\n",
      "Epoch 10, Batch 20200: Loss = 0.6163, Accuracy = 0.7500\n",
      "Epoch 10, Batch 20300: Loss = 0.5722, Accuracy = 0.7500\n",
      "Epoch 10, Batch 20400: Loss = 0.6636, Accuracy = 0.5625\n",
      "Epoch 10, Batch 20500: Loss = 0.4775, Accuracy = 0.7500\n",
      "Epoch 10, Batch 20600: Loss = 0.5742, Accuracy = 0.6875\n",
      "Epoch 10, Batch 20700: Loss = 0.5610, Accuracy = 0.7812\n",
      "Epoch 10, Batch 20800: Loss = 0.6330, Accuracy = 0.6875\n",
      "Epoch 10, Batch 20900: Loss = 0.6986, Accuracy = 0.4688\n",
      "Epoch 10, Batch 21000: Loss = 0.5685, Accuracy = 0.8125\n",
      "Epoch 10, Batch 21100: Loss = 0.7487, Accuracy = 0.5312\n",
      "Epoch 10, Batch 21200: Loss = 0.5333, Accuracy = 0.7500\n",
      "Epoch 10, Batch 21300: Loss = 0.6478, Accuracy = 0.6562\n",
      "Epoch 10, Batch 21400: Loss = 0.5632, Accuracy = 0.7500\n",
      "Epoch 10, Batch 21500: Loss = 0.5866, Accuracy = 0.6875\n",
      "Epoch 10, Batch 21600: Loss = 0.6086, Accuracy = 0.7188\n",
      "Epoch 10, Batch 21700: Loss = 0.6134, Accuracy = 0.6562\n",
      "Epoch 10, Batch 21800: Loss = 0.6360, Accuracy = 0.5938\n",
      "Epoch 10: Train Loss = 0.5976, Train Accuracy = 0.6997, Time = 488.05s\n",
      "Validation Accuracy: 0.7032\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Batch</td><td>▃▄▄▅▆▂█▃▃▄▁▇▇▁▄▅▅▅▆▃▇▇█▂▃▃▆▂▄▄▂▅▂▃▄▇█▂▄▆</td></tr><tr><td>Batch Accuracy</td><td>▄▇▅▄▅▆▅▆▆▅▅▅▄▅▄▆▆▆▆▅▅▅▁▅▄▆▅▄▆▄▇▃▅▅▄▇▄▂█▄</td></tr><tr><td>Batch Loss</td><td>▂▅▅▄▆█▅▅▅▆▃▅▆▅▄▃▄▅▄▁▆▄▁▆▅█▁▄▁▅▄▄▅▆▆▇▃▅▃▅</td></tr><tr><td>Epoch</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>Epoch Time (s)</td><td>▄▁▇▃▄▇▇██▅▂</td></tr><tr><td>Train Accuracy</td><td>▂▁▇████████</td></tr><tr><td>Train Loss</td><td>▇█▂▁▁▁▂▂▁▁▂</td></tr><tr><td>Validation Accuracy</td><td>▁▂▁▃▃▅█▄▂▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Batch</td><td>21800</td></tr><tr><td>Batch Accuracy</td><td>0.59375</td></tr><tr><td>Batch Loss</td><td>0.63602</td></tr><tr><td>Epoch</td><td>10</td></tr><tr><td>Epoch Time (s)</td><td>488.05425</td></tr><tr><td>Train Accuracy</td><td>0.69972</td></tr><tr><td>Train Loss</td><td>0.59765</td></tr><tr><td>Validation Accuracy</td><td>0.70323</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gnn_training_final</strong> at: <a href='https://wandb.ai/praneetham/higgs_gnn/runs/3k9xjcwr' target=\"_blank\">https://wandb.ai/praneetham/higgs_gnn/runs/3k9xjcwr</a><br> View project at: <a href='https://wandb.ai/praneetham/higgs_gnn' target=\"_blank\">https://wandb.ai/praneetham/higgs_gnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250325_204831-3k9xjcwr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_directml\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing weights and biases and setting up the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Weights & Biases (W&B) for experiment tracking\n",
    "wandb.init(project=\"higgs_gnn\", name=\"gnn_training_final\", config={\"epochs\": 20, \"batch_size\": 32})\n",
    "\n",
    "# Set device to AMD GPU using DirectML\n",
    "device = torch_directml.device()\n",
    "print(f\"✅ Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the daaset and creating the geaph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load HDF5 dataset\n",
    "hdf5_file = r\"C:\\Users\\vudut\\OneDrive\\Desktop\\Python\\MINI Project\\Data Sets\\jet-images_Mass60-100_pT250-300_R1.25_Pix25.hdf5\"\n",
    "with h5py.File(hdf5_file, \"r\") as f:\n",
    "    jet_pt = np.array(f[\"jet_pt\"])\n",
    "    jet_eta = np.array(f[\"jet_eta\"])\n",
    "    jet_phi = np.array(f[\"jet_phi\"])\n",
    "    jet_mass = np.array(f[\"jet_mass\"])\n",
    "    signal = np.array(f[\"signal\"])  # Labels: 1 = Signal, 0 = Background\n",
    "\n",
    "# Normalize node features (jet_pt, jet_eta, jet_phi, jet_mass)\n",
    "features = np.stack([jet_pt, jet_eta, jet_phi, jet_mass], axis=1)  # Shape: [N, 4]\n",
    "features = (features - features.mean(axis=0)) / features.std(axis=0)  # Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create graph data with explicit self-loops\n",
    "graphs = []\n",
    "for i in tqdm(range(len(features)), desc=\"Creating Graphs\"):\n",
    "    x = torch.tensor(features[i], dtype=torch.float).unsqueeze(0)\n",
    "    edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    y = torch.tensor([int(signal[i])], dtype=torch.long)\n",
    "    graphs.append(Data(x=x, edge_index=edge_index, y=y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataLoaders for training and validation\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    graphs[:int(0.8 * len(graphs))],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    graphs[int(0.8 * len(graphs)):],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the GNN model\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(4, 16, add_self_loops=False)\n",
    "        self.conv2 = GCNConv(16, 32, add_self_loops=False)\n",
    "        self.fc = torch.nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = GNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop with epoch timing\n",
    "for epoch in range(10):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_counter = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch_counter += 1\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == batch.y).sum().item()\n",
    "        total += batch.y.size(0)\n",
    "\n",
    "        if batch_counter % 100 == 0:\n",
    "            batch_loss = loss.item()\n",
    "            batch_acc = (pred == batch.y).sum().item() / batch.y.size(0)\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_counter}: Loss = {batch_loss:.4f}, Accuracy = {batch_acc:.4f}\")\n",
    "            wandb.log({\"Batch Loss\": batch_loss, \"Batch Accuracy\": batch_acc, \"Epoch\": epoch+1, \"Batch\": batch_counter})\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {avg_loss:.4f}, Train Accuracy = {train_acc:.4f}, Time = {epoch_time:.2f}s\")\n",
    "    wandb.log({\n",
    "        \"Train Loss\": avg_loss,\n",
    "        \"Train Accuracy\": train_acc,\n",
    "        \"Epoch Time (s)\": epoch_time,\n",
    "        \"Epoch\": epoch+1\n",
    "    })\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == batch.y).sum().item()\n",
    "            total += batch.y.size(0)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "    wandb.log({\"Validation Accuracy\": val_acc, \"Epoch\": epoch+1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model and finish W&B\n",
    "torch.save(model.state_dict(), \"higgs_gnn_model_final.pth\")\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving graphs for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and Saving Graphs: 100%|██████████| 20/20 [00:00<00:00, 1155.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 20 graphs as JSON files to C:\\Users\\vudut\\OneDrive\\Desktop\\Python\\MINI Project\\test_graphs_json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load HDF5 dataset\n",
    "hdf5_file = r\"C:\\Users\\vudut\\OneDrive\\Desktop\\Python\\MINI Project\\Data Sets\\jet-images_Mass60-100_pT250-300_R1.25_Pix25.hdf5\"\n",
    "with h5py.File(hdf5_file, \"r\") as f:\n",
    "    jet_pt = np.array(f[\"jet_pt\"])\n",
    "    jet_eta = np.array(f[\"jet_eta\"])\n",
    "    jet_phi = np.array(f[\"jet_phi\"])\n",
    "    jet_mass = np.array(f[\"jet_mass\"])\n",
    "    signal = np.array(f[\"signal\"])  # Labels: 1 = Signal, 0 = Background\n",
    "\n",
    "# Normalize node features (jet_pt, jet_eta, jet_phi, jet_mass)\n",
    "features = np.stack([jet_pt, jet_eta, jet_phi, jet_mass], axis=1)  # Shape: [N, 4]\n",
    "features = (features - features.mean(axis=0)) / features.std(axis=0)  # Standardization\n",
    "\n",
    "# Create and save 20 graphs in JSON format\n",
    "output_dir = r\"C:\\Users\\vudut\\OneDrive\\Desktop\\Python\\MINI Project\\test_graphs_json\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in tqdm(range(20), desc=\"Creating and Saving Graphs\"):\n",
    "    x = torch.tensor(features[i], dtype=torch.float).unsqueeze(0)\n",
    "    edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    y = torch.tensor([int(signal[i])], dtype=torch.long)\n",
    "    \n",
    "    # Convert graph to dictionary\n",
    "    graph_dict = {\n",
    "        \"x\": x.tolist(),  # Node features as list\n",
    "        \"edge_index\": edge_index.tolist(),  # Edge indices as list\n",
    "        \"y\": y.tolist()  # Label as list\n",
    "    }\n",
    "    \n",
    "    # Save as JSON\n",
    "    output_path = os.path.join(output_dir, f'graph_{i}.json')\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(graph_dict, f)\n",
    "\n",
    "print(f\"Saved 20 graphs as JSON files to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval the model on those 20 sample graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (conv1): GCNConv(4, 16)\n",
       "  (conv2): GCNConv(16, 32)\n",
       "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_directml\n",
    "\n",
    "# Initialize DirectML device\n",
    "device = torch_directml.device()\n",
    "\n",
    "# Load model with DirectML\n",
    "model = GNN().to(device)\n",
    "model.load_state_dict(torch.load('higgs_gnn_model_final.pth', map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_directml\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. Define your GNN model class (same as during training)\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(4, 16, add_self_loops=False)\n",
    "        self.conv2 = GCNConv(16, 32, add_self_loops=False)\n",
    "        self.fc = torch.nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.fc(x)\n",
    "\n",
    "# 2. Initialize DirectML\n",
    "device = torch_directml.device()\n",
    "\n",
    "# 3. Load and convert the model\n",
    "model = GNN().to(device)\n",
    "model.load_state_dict(torch.load('higgs_gnn_model_final.pth'))\n",
    "\n",
    "# 4. Save as CPU-compatible version\n",
    "cpu_model = GNN().cpu()\n",
    "cpu_model.load_state_dict(model.state_dict())\n",
    "torch.save(cpu_model.state_dict(), 'higgs_gnn_model_cpu.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vudut\\anaconda3\\envs\\pytorchamd\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "c:\\Users\\vudut\\anaconda3\\envs\\pytorchamd\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n",
      "AUC-ROC: nan\n",
      "Confusion Matrix:\n",
      "[[ 0  0]\n",
      " [ 4 16]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Define the GNN model (same architecture)\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(4, 16, add_self_loops=False)\n",
    "        self.conv2 = GCNConv(16, 32, add_self_loops=False)\n",
    "        self.fc = torch.nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.fc(x)\n",
    "\n",
    "# 2. Load the CPU-converted model\n",
    "device = torch.device('cpu')\n",
    "model = GNN().to(device)\n",
    "model.load_state_dict(torch.load('higgs_gnn_model_cpu.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# 3. Function to load JSON graph files\n",
    "def load_json_graphs(directory):\n",
    "    graph_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
    "    test_graphs = []\n",
    "    \n",
    "    for file in graph_files:\n",
    "        with open(os.path.join(directory, file), 'r') as f:\n",
    "            graph_data = json.load(f)\n",
    "            \n",
    "            x = torch.tensor(graph_data['x'], dtype=torch.float).to(device)\n",
    "            edge_index = torch.tensor(graph_data['edge_index'], dtype=torch.long).to(device)\n",
    "            y = torch.tensor([graph_data['y']], dtype=torch.long).to(device)\n",
    "            \n",
    "            test_graphs.append(Data(x=x, edge_index=edge_index, y=y))\n",
    "    \n",
    "    return test_graphs\n",
    "\n",
    "# 4. Load and evaluate\n",
    "test_graphs_dir = r\"C:\\Users\\vudut\\OneDrive\\Desktop\\Python\\MINI Project\\test_graphs_json\"\n",
    "test_graphs = load_json_graphs(test_graphs_dir)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            probs = F.softmax(out, dim=1)\n",
    "            \n",
    "            _, preds = torch.max(out, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            all_labels.extend(batch.y.cpu().numpy())\n",
    "    \n",
    "    return all_labels, all_preds, all_probs\n",
    "\n",
    "# Run evaluation\n",
    "true_labels, predictions, probabilities = evaluate_model(model, test_loader)\n",
    "\n",
    "# Calculate and display metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "auc_roc = roc_auc_score(true_labels, probabilities)\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Background', 'Signal'],\n",
    "            yticklabels=['Background', 'Signal'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchamd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
